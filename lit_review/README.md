# Literature Review

Competition is regression based. So the following only focuses on regression based reference.

List of regression-based competitions:
- [House Prices: Advanced Regression Techniques (RMSE)](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
- [New York City Taxi Fare Prediction (RMSE)](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction)
- [Corporación Favorita Grocery Sales Forecasting (NWRMSLE)](https://www.kaggle.com/c/favorita-grocery-sales-forecasting)
- [Zillow Prize: Zillow’s Home Value Prediction (Zestimate)  (MAE)](https://www.kaggle.com/c/zillow-prize-1)
- [Mercedes-Benz Greener Manufacturing (R^2)](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing)
- [Allstate Claims Severity (MAE)](https://www.kaggle.com/c/allstate-claims-severity)
- [How Much Did It Rain? II (MAE)](https://www.kaggle.com/c/how-much-did-it-rain-ii)
- [Caterpillar Tube Pricing (RMSLE)](https://www.kaggle.com/c/caterpillar-tube-pricing)
- [Walmart Recruiting II: Sales in Stormy Weather (RMSLE)](https://www.kaggle.com/c/walmart-recruiting-sales-in-stormy-weather)
- [PUBG Finish Placement Prediction (Kernels Only)  (MAE)](https://www.kaggle.com/c/pubg-finish-placement-prediction)
- [Grupo Bimbo Inventory Demand (RMSLE)](https://www.kaggle.com/c/grupo-bimbo-inventory-demand)
- [The Winton Stock Market Challenge (WMAE)](https://www.kaggle.com/c/the-winton-stock-market-challenge)
- [ECML/PKDD 15: Taxi Trip Time Prediction (II)  (RMSLE)](https://www.kaggle.com/c/pkdd-15-taxi-trip-time-prediction-ii)
- [Bike Sharing Demand (RMSLE)](https://www.kaggle.com/c/bike-sharing-demand)
- [Avito Demand Prediction Challenge (RMSE)](https://www.kaggle.com/c/avito-demand-prediction)

## 1. Kernels and Discussion

### 1a. Kernels/Discussion in the competition
- [Elo Merchant Category Recommendation: Combining your model with a model without outlier](https://www.kaggle.com/waitingli/combining-your-model-with-a-model-without-outlier)
- [Elo Merchant Category Recommendation: LIghtGBM (GBDT + RF) Baysian Ridge Reg:[LB 3.61]](https://www.kaggle.com/ashishpatel26/lightgbm-gbdt-rf-baysian-ridge-reg-lb-3-61)
- [Elo Merchant Category Recommendation: Sharing of my experience so far](https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/75935)

### 1b. Kernels/Discussion in other competitions
- [* Summary: Winning solutions of kaggle competitions](https://www.kaggle.com/sudalairajkumar/winning-solutions-of-kaggle-competitions)
- [House Prices: Advanced Regression Techniques: Top 10 (0.10943): stacking, MICE and brutal force](https://www.kaggle.com/agehsbarg/top-10-0-10943-stacking-mice-and-brutal-force)
- [House Prices: Advanced Regression Techniques: Hybrid SVM Benchmark Approach [0.11180] LB: Top 2%](https://www.kaggle.com/couyang/hybrid-svm-benchmark-approach-0-11180-lb-top-2)
- [House Prices: Advanced Regression Techniques: Top 2% from Laurenstc on house price prediction](https://www.kaggle.com/hemingwei/top-2-from-laurenstc-on-house-price-prediction)
- [House Prices: Advanced Regression Techniques: Sharing my approach to motivate more discussions](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/23409)
- [House Prices: Advanced Regression Techniques: the secret to making good predictions](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/32381)
- [House Prices: Advanced Regression Techniques: Dealing with Missing Data in the Test Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/35968)
- [House Prices: Advanced Regression Techniques: Lessons learned from 1st Kaggle Compeitition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/40391)
- [New York City Taxi Fare Prediction: NYC Taxi Fare - Data Exploration](https://www.kaggle.com/breemen/nyc-taxi-fare-data-exploration)
- [New York City Taxi Fare Prediction: Python Version of Top Ten Rank R 22 M (2.88)](https://www.kaggle.com/jsylas/python-version-of-top-ten-rank-r-22-m-2-88)
- [New York City Taxi Fare Prediction: EDA+ Data Cleaning + XG Boost](https://www.kaggle.com/sandeepkumar121995/eda-data-cleaning-xg-boost)
- [New York City Taxi Fare Prediction: Ideas for Improvement](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/discussion/62393)
- [Corporación Favorita Grocery Sales Forecasting: 1st place solution](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47582#latest-360306)
- [Corporación Favorita Grocery Sales Forecasting: 2nd place solution overview](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47568)
- [Corporación Favorita Grocery Sales Forecasting: 3rd place solution overview](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47560#latest-302253)
- [Corporación Favorita Grocery Sales Forecasting: 4th-Place Solution Overview](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47529)
- [Corporación Favorita Grocery Sales Forecasting: 5th Place Solution](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47556)
- [Corporación Favorita Grocery Sales Forecasting: 8th solution](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47564)
- [Zillow Prize: Zillow’s Home Value Prediction (Zestimate): Exploratory Analysis Zillow](https://www.kaggle.com/philippsp/exploratory-analysis-zillow)
- [Zillow Prize: Zillow’s Home Value Prediction (Zestimate): Simple Exploration Notebook - Zillow Prize](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize)
- [Zillow Prize: Zillow’s Home Value Prediction (Zestimate): Only_Cat boost (LB : 0.0641 939)](https://www.kaggle.com/abdelwahedassklou/only-cat-boost-lb-0-0641-939)
- [Zillow Prize: Zillow’s Home Value Prediction (Zestimate): XGBoost, LightGBM, and OLS and NN](https://www.kaggle.com/aharless/xgboost-lightgbm-and-ols-and-nn)
- [Zillow Prize: Zillow’s Home Value Prediction (Zestimate): Boost your score with stacknet ( 0.06433 with another script)](https://www.kaggle.com/c/zillow-prize-1/discussion/39111)
- [Zillow Prize: Zillow’s Home Value Prediction (Zestimate): 17th Place Solution](https://www.kaggle.com/c/zillow-prize-1/discussion/47434)
- [Mercedes-Benz Greener Manufacturing: Simple Exploration Notebook - Mercedes](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-mercedes)
- [Mercedes-Benz Greener Manufacturing: MercEDAs - update2 - intrinsic noise](https://www.kaggle.com/headsortails/mercedas-update2-intrinsic-noise)
- [Mercedes-Benz Greener Manufacturing: Mercedes magic features (Private LB:0.54200)](https://www.kaggle.com/dmi3kno/mercedes-magic-features-private-lb-0-54200)
- [Mercedes-Benz Greener Manufacturing: stacked then averaged models [~ Private LB 0.554]](https://www.kaggle.com/adityakumarsinha/stacked-then-averaged-models-private-lb-0-554)
- [Mercedes-Benz Greener Manufacturing: 1st place solution](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/37700)
- [Mercedes-Benz Greener Manufacturing: A third place solution](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/36126)
- [Mercedes-Benz Greener Manufacturing: 6th Place solution](https://www.kaggle.com/tobikaggle/stacked-then-averaged-models-0-5697)
- [Mercedes-Benz Greener Manufacturing: 10th solution, average 4 predictions](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/36128)
 [Mercedes-Benz Greener Manufacturing: in CV you must trust](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/36136)
- [Allstate Claims Severity: Exploratory study on ML algorithms](https://www.kaggle.com/sharmasanthosh/exploratory-study-on-ml-algorithms)
- [Allstate Claims Severity: All-Trump-State](https://www.kaggle.com/vishallakha/all-trump-state)
- [Allstate Claims Severity: my test1](https://www.kaggle.com/pedram/my-test1)
- [Allstate Claims Severity: #1st Place Solution](https://www.kaggle.com/c/allstate-claims-severity/discussion/26416)
- [Allstate Claims Severity: #2nd Place Solution](https://www.kaggle.com/c/allstate-claims-severity/discussion/26427)
- [Allstate Claims Severity: Faron's 3rd Place Solution](https://www.kaggle.com/c/allstate-claims-severity/discussion/26447)
- [How Much Did It Rain? II: Beware of Outliers !!](https://www.kaggle.com/sudalairajkumar/rainfall-test)
- [How Much Did It Rain? II: 38% Missing Data](https://www.kaggle.com/c/how-much-did-it-rain-ii/discussion/16572)
- [How Much Did It Rain? II: Cross Validating](https://www.kaggle.com/c/how-much-did-it-rain-ii/discussion/16680)
- [How Much Did It Rain? II: How Much Did It Rain? II, Winner's Interview: 1st place, PuPa (aka Aaron Sim)](http://blog.kaggle.com/2016/01/04/how-much-did-it-rain-ii-winners-interview-1st-place-pupa-aka-aaron-sim/)
- [How Much Did It Rain? II: 1st solution writeup](http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/)
- [How Much Did It Rain? II: 1st solution github](https://github.com/simaaron/kaggle-Rain)
- [How Much Did It Rain? II: How Much Did It Rain? II: 2nd place, Luis Andre Dutra e Silva](http://blog.kaggle.com/2015/12/17/how-much-did-it-rain-ii-2nd-place-luis-andre-dutra-e-silva/)
- [How Much Did It Rain? II: 30th solution github](https://github.com/vopani/Kaggle_Rain2)
- [Caterpillar Tube Pricing: 0.2748 with RF and log transformation](https://www.kaggle.com/ademyttenaere/0-2748-with-rf-and-log-transformation)
- [Caterpillar Tube Pricing: How We Won the Caterpillar Machine Learning Competition at Kaggle](http://mariofilho.com/won-caterpillar-machine-learning-competition-kaggle/)
- [Caterpillar Tube Pricing: Caterpillar Winners' Interview: 1st place, Gilberto | Josef | Leustagos | Mario](http://blog.kaggle.com/2015/09/22/caterpillar-winners-interview-1st-place-gilberto-josef-leustagos-mario/)
- [Caterpillar Tube Pricing: 7th place writeup](https://weiminwang.blog/2015/09/02/caterpillar-tube-pricing-feature-engineering-and-ensemble-approach/)
- [Caterpillar Tube Pricing: 7th place github](https://github.com/aaxwaz/Caterpillar-Tube-Pricing-Kaggle)
- [Caterpillar Tube Pricing: Keras starter code](https://www.kaggle.com/fchollet/keras-starter-code)
- [Walmart Recruiting II: Sales in Stormy Weather: Simple writeup by first place](http://analyticscosm.com/secret-sauce-behind-15-kaggle-winning-ideas/)
- [Walmart Recruiting II: Sales in Stormy Weather: First Place Entry](https://www.kaggle.com/c/walmart-recruiting-sales-in-stormy-weather/discussion/14452#80451)
- [Walmart Recruiting II: Sales in Stormy Weather: ]()
- [Walmart Recruiting II: Sales in Stormy Weather: ]()
- [Walmart Recruiting II: Sales in Stormy Weather: ]()
- [Walmart Recruiting II: Sales in Stormy Weather: ]()
- [Walmart Recruiting II: Sales in Stormy Weather: ]()



- [Santander Value Prediction Challenge: Winner Solution - Giba & Lucasz](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/65272)
- [Santander Value Prediction Challenge: 21st place solution (bug fixed) [private: 0.52785]](https://www.kaggle.com/rsakata/21st-place-solution-bug-fixed-private-0-52785)
- [Santander Value Prediction Challenge: [0.49-PublicLB]Simple_Blend(Private_LB_rank_126th)](https://www.kaggle.com/khahuras/0-49-publiclb-simple-blend-private-lb-rank-126th)
- [Santander Value Prediction Challenge: 5 place mini write-up](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/63822)
- [Santander Value Prediction Challenge: 2nd place solution overview](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/63848)
- [Sberbank Russian Housing Market: A Very Extensive Sberbank Exploratory Analysis](https://www.kaggle.com/captcalculator/a-very-extensive-sberbank-exploratory-analysis)
- [Sberbank Russian Housing Market: Simple Exploration Notebook - Sberbank](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-sberbank)
- [Sberbank Russian Housing Market: 1st place solution](https://www.kaggle.com/c/sberbank-russian-housing-market/discussion/35684)
- [Sberbank Russian Housing Market: 15th place solution](https://www.kaggle.com/c/sberbank-russian-housing-market/discussion/35700)
- [Sberbank Russian Housing Market: 21st place submission](https://www.kaggle.com/c/sberbank-russian-housing-market/discussion/35570)
- [Restaurant Revenue Prediction: Winning Solution](https://www.kaggle.com/c/restaurant-revenue-prediction/discussion/14066)
- [Restaurant Revenue Prediction: Restaurant Revenue - 1st place solution](https://www.kaggle.com/jquesadar/restaurant-revenue-1st-place-solution)
- [Google Analytics Customer Revenue Prediction: Simple Exploration+Baseline - GA Customer Revenue](https://www.kaggle.com/sudalairajkumar/simple-exploration-baseline-ga-customer-revenue)
- [Google Analytics Customer Revenue Prediction: Group xgb for Gstore v2](https://www.kaggle.com/kailex/group-xgb-for-gstore-v2)
- [Kaggle Avito Demand Prediction Challenge: Analysis of Winning Submissions](http://mlexplained.com/2018/08/18/kaggle-avito-demand-prediction-challenge-analysis-of-winning-submissions/)


## 2. Papers and Hyperlinks

### 2a. EDA

### 2b. Feature Generation

### 2c. Feature Selection

### 2d. Performance Measures
- [Duke: What's the bottom line? How to compare models](https://people.duke.edu/~rnau/compare.htm)
- [7 Important Model Evaluation Error Metrics Everyone should know](https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/)
- [Medium: How to select the Right Evaluation Metric for Machine Learning Models: Part 1 Regression Metrics](https://towardsdatascience.com/how-to-select-the-right-evaluation-metric-for-machine-learning-models-part-1-regrression-metrics-3606e25beae0)
- [Machine Learning Mastery: Metrics To Evaluate Machine Learning Algorithms in Python](https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/)
- [Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance](http://climate.geog.udel.edu/~climate/publication_html/Pdf/WM_CR_05.pdf)

### 2e. Model

### 2f. Parameter Tuning
- [Analytics Vidhya: Complete Guide to Parameter Tuning in XGBoost (with codes in Python)](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)
- [How to Tuning XGboost in an efficient way](https://www.kaggle.com/general/17120)
- [yellowbrick: Model Selection Tutorial](http://www.scikit-yb.org/en/latest/tutorial.html)
- [XGBoost — Model to win Kaggle](https://medium.com/@gautam.karmakar/xgboost-model-to-win-kaggle-e12b35cd1aad)

### 2g. Ensemble

### 2h. Computational Performance
- [How to Work with BIG Datasets on Kaggle Kernels (16G RAM)](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask)
- [Real Python - Speed Up Your Python Program With Concurrency](https://realpython.com/python-concurrency/)
- [First Steps with numba](http://numba.pydata.org/numba-doc/0.12.2/tutorial_firststeps.html)

## 3. Other stuff
- [Profiling Top Kagglers: Bestfitting, Currently #1 in the World](http://blog.kaggle.com/2018/05/07/profiling-top-kagglers-bestfitting-currently-1-in-the-world/)
- [How to Win Kaggle Competitions](https://www.kaggle.com/getting-started/44997)
- [Medium: “Data Science A-Z from Zero to Kaggle Kernels Master”](https://towardsdatascience.com/data-science-from-zero-to-kaggle-kernels-master-f9115eadbb3)
- [Medium: My secret sauce to be in top 2% of a kaggle competition](https://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c)
- [Medium: Machine Learning Kaggle Competition Part One: Getting Started](https://towardsdatascience.com/machine-learning-kaggle-competition-part-one-getting-started-32fb9ff47426)
- [Medium: Machine Learning Kaggle Competition Part Two: Improving](https://towardsdatascience.com/machine-learning-kaggle-competition-part-two-improving-e5b4d61ab4b8)
- [Medium: Machine Learning Kaggle Competition: Part Three Optimization](https://towardsdatascience.com/machine-learning-kaggle-competition-part-three-optimization-db04ea415507)
- [Kaggle DDL(Winner Solutions)](https://finlayliu.com/kaggle/)
- [shujianliu - kaggle winning code](http://shujianliu.com/kaggle-winning-code.html)
- [ShuaiW - Kaggle - Regression](https://libraries.io/github/ShuaiW/kaggle-regression)
- [Secret Sauce Behind 9 Kaggle Winning Ideas](http://analyticscosm.com/secret-sauce-behind-15-kaggle-winning-ideas/)
- [threecourse on bitbucket: Past Competitions and Solutions](https://bitbucket.org/threecourse/kaggle-wiki/wiki/Past%20Competitions%20and%20Solutions%20(-%20June%202016))
