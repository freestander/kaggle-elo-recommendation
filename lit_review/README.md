# Literature Review

Competition is regression based. So the following only focuses on regression based reference.

List of regression-based competitions:
- [House Prices: Advanced Regression Techniques (RMSE)](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
- [New York City Taxi Fare Prediction (RMSE)](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction)
- [Corporación Favorita Grocery Sales Forecasting (NWRMSLE)](https://www.kaggle.com/c/favorita-grocery-sales-forecasting)
- [Zillow Prize: Zillow’s Home Value Prediction (Zestimate)  (MAE)](https://www.kaggle.com/c/zillow-prize-1)
- [Mercedes-Benz Greener Manufacturing (R^2)](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing)
- [Allstate Claims Severity (MAE)](https://www.kaggle.com/c/allstate-claims-severity)
- [How Much Did It Rain? II (MAE)](https://www.kaggle.com/c/how-much-did-it-rain-ii)
- [Caterpillar Tube Pricing (RMSLE)](https://www.kaggle.com/c/caterpillar-tube-pricing)
- [Walmart Recruiting II: Sales in Stormy Weather (RMSLE)](https://www.kaggle.com/c/walmart-recruiting-sales-in-stormy-weather)
- [PUBG Finish Placement Prediction (Kernels Only)  (MAE)](https://www.kaggle.com/c/pubg-finish-placement-prediction)
- [Grupo Bimbo Inventory Demand (RMSLE)](https://www.kaggle.com/c/grupo-bimbo-inventory-demand)
- [The Winton Stock Market Challenge (WMAE)](https://www.kaggle.com/c/the-winton-stock-market-challenge)
- [ECML/PKDD 15: Taxi Trip Time Prediction (II)  (RMSLE)](https://www.kaggle.com/c/pkdd-15-taxi-trip-time-prediction-ii)
- [Bike Sharing Demand (RMSLE)](https://www.kaggle.com/c/bike-sharing-demand)
- [Avito Demand Prediction Challenge (RMSE)](https://www.kaggle.com/c/avito-demand-prediction)
- [Santander Value Prediction Challenge (RMSLE)](https://www.kaggle.com/c/santander-value-prediction-challenge)
- [Sberbank Russian Housing Market (RMSLE)](https://www.kaggle.com/c/sberbank-russian-housing-market)
- [Restaurant Revenue Prediction (RMSE)](https://www.kaggle.com/c/restaurant-revenue-prediction)
- [Google Analytics Customer Revenue Prediction (RMSE)](https://www.kaggle.com/c/ga-customer-revenue-prediction)

## 1. Kernels and Discussion

### 1a. Kernels/Discussion in the competition
- [Elo Merchant Category Recommendation: Combining your model with a model without outlier](https://www.kaggle.com/waitingli/combining-your-model-with-a-model-without-outlier)
- [Elo Merchant Category Recommendation: LIghtGBM (GBDT + RF) Baysian Ridge Reg:[LB 3.61]](https://www.kaggle.com/ashishpatel26/lightgbm-gbdt-rf-baysian-ridge-reg-lb-3-61)
- [Elo Merchant Category Recommendation: Sharing of my experience so far](https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/75935)

### 1b. Kernels/Discussion in other competitions

#### House Prices: Advanced Regression Techniques (RMSE)
- [Top 10 (0.10943): stacking, MICE and brutal force](https://www.kaggle.com/agehsbarg/top-10-0-10943-stacking-mice-and-brutal-force)
- [Hybrid SVM Benchmark Approach [0.11180] LB: Top 2%](https://www.kaggle.com/couyang/hybrid-svm-benchmark-approach-0-11180-lb-top-2)
- [Top 2% from Laurenstc on house price prediction](https://www.kaggle.com/hemingwei/top-2-from-laurenstc-on-house-price-prediction)
- [Sharing my approach to motivate more discussions](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/23409)
- [the secret to making good predictions](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/32381)
- [Dealing with Missing Data in the Test Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/35968)
- [Lessons learned from 1st Kaggle Compeitition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/40391)

#### New York City Taxi Fare Prediction (RMSE)
- [NYC Taxi Fare - Data Exploration](https://www.kaggle.com/breemen/nyc-taxi-fare-data-exploration)
- [Python Version of Top Ten Rank R 22 M (2.88)](https://www.kaggle.com/jsylas/python-version-of-top-ten-rank-r-22-m-2-88)
- [EDA+ Data Cleaning + XG Boost](https://www.kaggle.com/sandeepkumar121995/eda-data-cleaning-xg-boost)
- [Ideas for Improvement](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/discussion/62393)

#### Corporación Favorita Grocery Sales Forecasting (NWRMSLE)
- [1st place solution](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47582#latest-360306)
- [2nd place solution overview](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47568)
- [3rd place solution overview](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47560#latest-302253)
- [4th-Place Solution Overview](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47529)
- [5th Place Solution](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47556)
- [8th solution](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47564)

#### Zillow Prize: Zillow’s Home Value Prediction (Zestimate) (MAE)
- [Exploratory Analysis Zillow](https://www.kaggle.com/philippsp/exploratory-analysis-zillow)
- [Simple Exploration Notebook - Zillow Prize](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize)
- [Only_Cat boost (LB : 0.0641 939)](https://www.kaggle.com/abdelwahedassklou/only-cat-boost-lb-0-0641-939)
- [XGBoost, LightGBM, and OLS and NN](https://www.kaggle.com/aharless/xgboost-lightgbm-and-ols-and-nn)
- [Boost your score with stacknet ( 0.06433 with another script)](https://www.kaggle.com/c/zillow-prize-1/discussion/39111)
- [17th Place Solution](https://www.kaggle.com/c/zillow-prize-1/discussion/47434)

#### Mercedes-Benz Greener Manufacturing (R^2)
- [Simple Exploration Notebook - Mercedes](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-mercedes)
- [MercEDAs - update2 - intrinsic noise](https://www.kaggle.com/headsortails/mercedas-update2-intrinsic-noise)
- [Mercedes magic features (Private LB:0.54200)](https://www.kaggle.com/dmi3kno/mercedes-magic-features-private-lb-0-54200)
- [stacked then averaged models [~ Private LB 0.554]](https://www.kaggle.com/adityakumarsinha/stacked-then-averaged-models-private-lb-0-554)
- [1st place solution](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/37700)
- [A third place solution](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/36126)
- [6th Place solution](https://www.kaggle.com/tobikaggle/stacked-then-averaged-models-0-5697)
- [10th solution, average 4 predictions](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/36128)
- [in CV you must trust](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/36136)
 
 #### Allstate Claims Severity (MAE)
- [Exploratory study on ML algorithms](https://www.kaggle.com/sharmasanthosh/exploratory-study-on-ml-algorithms)
- [All-Trump-State](https://www.kaggle.com/vishallakha/all-trump-state)
- [my test1](https://www.kaggle.com/pedram/my-test1)
- [#1st Place Solution](https://www.kaggle.com/c/allstate-claims-severity/discussion/26416)
- [#2nd Place Solution](https://www.kaggle.com/c/allstate-claims-severity/discussion/26427)
- [Faron's 3rd Place Solution](https://www.kaggle.com/c/allstate-claims-severity/discussion/26447)

#### How Much Did It Rain? II (MAE)
- [Beware of Outliers !!](https://www.kaggle.com/sudalairajkumar/rainfall-test)
- [38% Missing Data](https://www.kaggle.com/c/how-much-did-it-rain-ii/discussion/16572)
- [Cross Validating](https://www.kaggle.com/c/how-much-did-it-rain-ii/discussion/16680)
- [How Much Did It Rain? II, Winner's Interview: 1st place, PuPa (aka Aaron Sim)](http://blog.kaggle.com/2016/01/04/how-much-did-it-rain-ii-winners-interview-1st-place-pupa-aka-aaron-sim/)
- [1st solution writeup](http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/)
- [1st solution github](https://github.com/simaaron/kaggle-Rain)
- [2nd place, Luis Andre Dutra e Silva](http://blog.kaggle.com/2015/12/17/how-much-did-it-rain-ii-2nd-place-luis-andre-dutra-e-silva/)
- [30th solution github](https://github.com/vopani/Kaggle_Rain2)

#### Caterpillar Tube Pricing (RMSLE)
- [0.2748 with RF and log transformation](https://www.kaggle.com/ademyttenaere/0-2748-with-rf-and-log-transformation)
- [How We Won the Caterpillar Machine Learning Competition at Kaggle](http://mariofilho.com/won-caterpillar-machine-learning-competition-kaggle/)
- [Caterpillar Winners' Interview: 1st place, Gilberto | Josef | Leustagos | Mario](http://blog.kaggle.com/2015/09/22/caterpillar-winners-interview-1st-place-gilberto-josef-leustagos-mario/)
- [7th place writeup](https://weiminwang.blog/2015/09/02/caterpillar-tube-pricing-feature-engineering-and-ensemble-approach/)
- [7th place github](https://github.com/aaxwaz/Caterpillar-Tube-Pricing-Kaggle)
- [Keras starter code](https://www.kaggle.com/fchollet/keras-starter-code)

#### Walmart Recruiting II: Sales in Stormy Weather (RMSLE)
- [Sales in Stormy Weather: Simple writeup by first place](http://analyticscosm.com/secret-sauce-behind-15-kaggle-winning-ideas/)
- [Sales in Stormy Weather: First Place Entry](https://www.kaggle.com/c/walmart-recruiting-sales-in-stormy-weather/discussion/14452#80451)

#### PUBG Finish Placement Prediction (Kernels Only) (MAE)
- [EDA is Fun!](https://www.kaggle.com/deffro/eda-is-fun)
- [Effective Feature Engineering](https://www.kaggle.com/rejasupotaro/effective-feature-engineering)
- [A Simple Post-Processing Trick For NN Models](https://www.kaggle.com/c/pubg-finish-placement-prediction/discussion/70492)

#### Grupo Bimbo Inventory Demand (RMSLE)
- [Exploring products](https://www.kaggle.com/vykhand/exploring-products)
- [Grupo Bimbo data analysis](https://www.kaggle.com/fabienvs/grupo-bimbo-data-analysis)
- [Exploratory Data Analysis](https://www.kaggle.com/anokas/exploratory-data-analysis)
- [#1 Place Solution of The Slippery Appraisals team](https://www.kaggle.com/c/grupo-bimbo-inventory-demand/discussion/23863)
- [#6 Place Solution - Team Gilberto & Regis](https://www.kaggle.com/c/grupo-bimbo-inventory-demand/discussion/23232)
- [#19 place solution](https://www.kaggle.com/c/grupo-bimbo-inventory-demand/discussion/23208)
- [Low Memory Solution](https://www.kaggle.com/c/grupo-bimbo-inventory-demand/discussion/23202)

#### The Winton Stock Market Challenge (WMAE)
- [Winton Stock Market Challenge, Winner's Interview: 3rd place, Mendrika Ramarlina](http://blog.kaggle.com/2016/02/12/winton-stock-market-challenge-winners-interview-3rd-place-mendrika-ramarlina/)
- [Solutions Sharing](https://www.kaggle.com/c/the-winton-stock-market-challenge/discussion/18584#105945)
- [The Winton Stock Market Challenge - Predicting Future (Stock Returns)](http://blog.socratesk.com/kaggle/2016/01/27/Winton-Stock-Market-Challenge)
- [25-30th place solution github](https://github.com/ceshine/kaggle-winton-2016)

#### ECML/PKDD 15: Taxi Trip Time Prediction (II) (RMSLE)
- [Beat The Benchmark](https://www.kaggle.com/willieliao/beat-the-benchmark)
- [Speed visualization](https://www.kaggle.com/wikunia/speed-visualization)
- [Medium: Our Approach — Kaggle : Taxi Trip Time Prediction (II)](https://medium.com/@PrakhashS/our-approach-kaggle-taxi-trip-time-prediction-ii-f5e3e8f3db10)
- [Winning solution github](https://github.com/hochthom/kaggle-taxi-ii)
- [JULIEN PHALIP: Kaggle competition report. ECML PKDD 2015 Taxi Trajectory Prediction](https://www.julienphalip.com/blog/kaggle-competition-report-ecml-pkdd-2015-taxi/)
- [Alexandre de Brébisson: Winning the Kaggle Taxi destination prediction](http://adbrebs.github.io/Kaggle-Taxi-Destination-Prediction/)
- [An Ensemble Learning Approach for the Kaggle Taxi Travel Time Prediction Challenge](https://www.researchgate.net/publication/283123171_An_Ensemble_Learning_Approach_for_the_Kaggle_Taxi_Travel_Time_Prediction_Challenge)


#### Bike Sharing Demand (RMSLE)
- [EDA & Ensemble Model (Top 10 Percentile) ](https://www.kaggle.com/viveksrinivasan/eda-ensemble-model-top-10-percentile)
- [Medium: How to finish top 10 percentile in Bike Sharing Demand Competition In Kaggle? (part -1)](https://medium.com/@viveksrinivasan/how-to-finish-top-10-percentile-in-bike-sharing-demand-competition-in-kaggle-part-1-c816ea9c51e1)
- [Medium: How to finish top 10 percentile in Bike Sharing Demand Competition In Kaggle? (part -2)](https://medium.com/@viveksrinivasan/how-to-finish-top-10-percentile-in-bike-sharing-demand-competition-in-kaggle-part-2-29e854aaab7d)
- [Kaggle Bike Sharing Demand Prediction – How I got in top 5 percentile of participants?](https://www.analyticsvidhya.com/blog/2015/06/solution-kaggle-competition-bike-sharing-demand/)
- [Research paper: weather and DC bikeshare](https://www.kaggle.com/c/bike-sharing-demand/discussion/9457)

#### Avito Demand Prediction Challenge (RMSE)
- [Avito EDA, FE, Time Series, DT Visualization](https://www.kaggle.com/codename007/avito-eda-fe-time-series-dt-visualization)
- [Ideas for Image Features and Image Quality](https://www.kaggle.com/shivamb/ideas-for-image-features-and-image-quality)
- [In-Depth Exploratory Analysis and Visualizations - Avito](https://www.kaggle.com/shivamb/in-depth-analysis-visualisations-avito)
- [Simple Exploration + Baseline Notebook - Avito](https://www.kaggle.com/sudalairajkumar/simple-exploration-baseline-notebook-avito)
- [Kaggle Avito Demand Prediction Challenge: Analysis of Winning Submissions](http://mlexplained.com/2018/08/18/kaggle-avito-demand-prediction-challenge-analysis-of-winning-submissions/)
- [second place solution](https://www.kaggle.com/c/avito-demand-prediction/discussion/59871)
- [3 place solution](https://www.kaggle.com/c/avito-demand-prediction/discussion/59885)
- [4th Place Solution](https://www.kaggle.com/c/avito-demand-prediction/discussion/59881)
- [5th place solution](https://www.kaggle.com/c/avito-demand-prediction/discussion/59914)


#### Santander Value Prediction Challenge (RMSLE)
- [Winner Solution - Giba & Lucasz](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/65272)
- [21st place solution (bug fixed) [private: 0.52785]](https://www.kaggle.com/rsakata/21st-place-solution-bug-fixed-private-0-52785)
- [[0.49-PublicLB]Simple_Blend(Private_LB_rank_126th)](https://www.kaggle.com/khahuras/0-49-publiclb-simple-blend-private-lb-rank-126th)
- [#1 Solution: Leak Part](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/63931)
- [Winner #1 Position Mini Writeup](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/63907)
- [2nd place solution overview](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/63848)
- [5 place mini write-up](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/63822)
- [Special Sauce - the Santander Process is a Time Series](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61396)

#### Sberbank Russian Housing Market (RMSLE)
- [A Very Extensive Sberbank Exploratory Analysis](https://www.kaggle.com/captcalculator/a-very-extensive-sberbank-exploratory-analysis)
- [Simple Exploration Notebook - Sberbank](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-sberbank)
- [1st place solution](https://www.kaggle.com/c/sberbank-russian-housing-market/discussion/35684)
- [15th place solution](https://www.kaggle.com/c/sberbank-russian-housing-market/discussion/35700)
- [21st place submission](https://www.kaggle.com/c/sberbank-russian-housing-market/discussion/35570)

#### Restaurant Revenue Prediction (RMSE)
- [Winning Solution](https://www.kaggle.com/c/restaurant-revenue-prediction/discussion/14066)
- [Restaurant Revenue - 1st place solution](https://www.kaggle.com/jquesadar/restaurant-revenue-1st-place-solution)
- [Winning Solution](https://www.kaggle.com/c/restaurant-revenue-prediction/discussion/14066)
- [38th place github](https://github.com/WesleyyC/Restaurant-Revenue-Prediction)
- [Medium: Restaurant Revenue Prediction using Gradient Boosting Regression and Principal Component Analysis](https://medium.com/@paul90.hn/restaurant-revenue-prediction-using-gradient-boosting-regression-and-principal-component-analysis-346287c0fab)

#### Google Analytics Customer Revenue Prediction (RMSE)
- [Simple Exploration+Baseline - GA Customer Revenue](https://www.kaggle.com/sudalairajkumar/simple-exploration-baseline-ga-customer-revenue)
- [Group xgb for Gstore v2](https://www.kaggle.com/kailex/group-xgb-for-gstore-v2)
- [Google Analytics Customer Revenue Prediction -kaggle challenge (Part One)](https://medium.com/@jacky308082/this-time-i-would-try-to-use-english-to-explain-this-whole-project-4a26c9294ccf)

## 2. Papers and Hyperlinks

### 2a. EDA

### 2b. Feature Generation

### 2c. Feature Selection

### 2d. Performance Measures
- [Duke: What's the bottom line? How to compare models](https://people.duke.edu/~rnau/compare.htm)
- [7 Important Model Evaluation Error Metrics Everyone should know](https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/)
- [Medium: How to select the Right Evaluation Metric for Machine Learning Models: Part 1 Regression Metrics](https://towardsdatascience.com/how-to-select-the-right-evaluation-metric-for-machine-learning-models-part-1-regrression-metrics-3606e25beae0)
- [Machine Learning Mastery: Metrics To Evaluate Machine Learning Algorithms in Python](https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/)
- [Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance](http://climate.geog.udel.edu/~climate/publication_html/Pdf/WM_CR_05.pdf)

### 2e. Model

### 2f. Parameter Tuning
- [Analytics Vidhya: Complete Guide to Parameter Tuning in XGBoost (with codes in Python)](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)
- [How to Tuning XGboost in an efficient way](https://www.kaggle.com/general/17120)
- [yellowbrick: Model Selection Tutorial](http://www.scikit-yb.org/en/latest/tutorial.html)
- [XGBoost — Model to win Kaggle](https://medium.com/@gautam.karmakar/xgboost-model-to-win-kaggle-e12b35cd1aad)

### 2g. Ensemble

### 2h. Computational Performance
- [How to Work with BIG Datasets on Kaggle Kernels (16G RAM)](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask)
- [Real Python - Speed Up Your Python Program With Concurrency](https://realpython.com/python-concurrency/)
- [First Steps with numba](http://numba.pydata.org/numba-doc/0.12.2/tutorial_firststeps.html)

## 3. Domain Knowledge

### 7 reasons to view analytics provided by a credit card payment processor
- [Link](https://www.vantiv.com/vantage-point/smarter-payments/credit-card-processing-analytics)
- Summary:
   - **Understand your customers’ behavior**
   - Personalize offering based on data results
   - Use trends and patterns to get new customers
   - Benchmark your information against the competition
   - Uncover suspicious activity
   - Reduce chargebacks
   - Determine how to make improvements in the overall business

### How Retailers Can Use Data Analytics
to Revitalize Customer Loyalty Programs
- [Link](https://strategywise.com/retail-analytics-the-rise-of-big-data-in-customer-loyalty-programs/)
- Summary: 
   - **Identify and Recognize the Best Customers**
   - Increase Retention, Reduce Attrition
   - Targeted Product Recommendations
   - Well-Timed Promotions
   - Personalize Loyalty Rewards
   - Determine the Effectiveness of a Loyalty Program
   
## 4. Other stuff
- [Profiling Top Kagglers: Bestfitting, Currently #1 in the World](http://blog.kaggle.com/2018/05/07/profiling-top-kagglers-bestfitting-currently-1-in-the-world/)
- [How to Win Kaggle Competitions](https://www.kaggle.com/getting-started/44997)
- [Medium: “Data Science A-Z from Zero to Kaggle Kernels Master”](https://towardsdatascience.com/data-science-from-zero-to-kaggle-kernels-master-f9115eadbb3)
- [Medium: My secret sauce to be in top 2% of a kaggle competition](https://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c)
- [Medium: Machine Learning Kaggle Competition Part One: Getting Started](https://towardsdatascience.com/machine-learning-kaggle-competition-part-one-getting-started-32fb9ff47426)
- [Medium: Machine Learning Kaggle Competition Part Two: Improving](https://towardsdatascience.com/machine-learning-kaggle-competition-part-two-improving-e5b4d61ab4b8)
- [Medium: Machine Learning Kaggle Competition: Part Three Optimization](https://towardsdatascience.com/machine-learning-kaggle-competition-part-three-optimization-db04ea415507)
- [Kaggle DDL(Winner Solutions)](https://finlayliu.com/kaggle/)
- [shujianliu - kaggle winning code](http://shujianliu.com/kaggle-winning-code.html)
- [ShuaiW - Kaggle - Regression](https://libraries.io/github/ShuaiW/kaggle-regression)
- [Secret Sauce Behind 9 Kaggle Winning Ideas](http://analyticscosm.com/secret-sauce-behind-15-kaggle-winning-ideas/)
- [threecourse on bitbucket: Past Competitions and Solutions](https://bitbucket.org/threecourse/kaggle-wiki/wiki/Past%20Competitions%20and%20Solutions%20(-%20June%202016))
- [Summary: Winning solutions of kaggle competitions](https://www.kaggle.com/sudalairajkumar/winning-solutions-of-kaggle-competitions)
- [Kaggle Past Solutions](https://ndres.me/kaggle-past-solutions/)
