{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a9ef20fd4e6471fd2c9e3022edfdddc07a970aca"
   },
   "source": [
    "## P.S. The main idea behind this notebook is inspired from FabienDaniel Kernel Elo_world.\n",
    "https://www.kaggle.com/fabiendaniel/elo-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50e1f88df96b5e525237fe120650e679b7f60654"
   },
   "outputs": [],
   "source": [
    "# new_transactions = pd.read_csv('../input/elo-merchant-category-recommendation/new_merchant_transactions.csv', parse_dates=['purchase_date'])\n",
    "# historical_transactions = pd.read_csv('../input/elo-merchant-category-recommendation/historical_transactions.csv', parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_parquet('../input/hist_trans_df.parquet.gzip')\n",
    "new_transactions = pd.read_parquet('../input/new_trans_df.parquet.gzip')\n",
    "\n",
    "def binarize(df):\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y':1, 'N':0})\n",
    "    return df\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a940a9ce940fa489a5a5255f6d4523c9b7c3ffdc"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# def read_data(input_file):\n",
    "#     df = pd.read_csv(input_file)\n",
    "#     df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "#     df['elapsed_time'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days\n",
    "#     return df\n",
    "\n",
    "# train = read_data('../input/elo-merchant-category-recommendation/train.csv')\n",
    "# test = read_data('../input/elo-merchant-category-recommendation/test.csv')\n",
    "\n",
    "def read_data_v2(input_file):\n",
    "    df = pd.read_parquet(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days\n",
    "    return df\n",
    "\n",
    "train = read_data_v2('../input/train_df.parquet.gzip')\n",
    "test = read_data_v2('../input/test_df.parquet.gzip')\n",
    "\n",
    "target = train['target']\n",
    "del train['target']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd9f71f39664eef55e0b3ec3e6172e84a8e1a963"
   },
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_opt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_1\"] += 1\n",
    "historical_transactions[\"category_1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_1\"] += 1\n",
    "new_transactions[\"category_1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_2\"] = historical_transactions[\"category_2\"].fillna(0)\n",
    "historical_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_2\"] = new_transactions[\"category_2\"].fillna(0)\n",
    "new_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_3\"] = historical_transactions[\"category_3\"].replace({'A': 1, 'B': 2, 'C': 3, None: 0})\n",
    "historical_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_3\"] = new_transactions[\"category_3\"].replace({'A': 1, 'B': 2, 'C': 3, None: 0})\n",
    "new_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions[\"category_1_2_cross\"] = historical_transactions[\"category_1\"]*2 + historical_transactions[\"category_2\"]\n",
    "# np.sort(historical_transactions[\"category_1_2_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(new_transactions[\"category_1\"], new_transactions[\"category_2\"])\n",
    "#     plt.xlabel(\"category_1\")\n",
    "#     plt.ylabel(\"category_2\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_transactions[\"category_1_2_cross\"] = new_transactions[\"category_1\"]*2 + new_transactions[\"category_2\"]\n",
    "# np.sort(new_transactions[\"category_1_2_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(historical_transactions[\"category_1\"]+2, historical_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_1\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions[\"category_1_3_cross\"] = (historical_transactions[\"category_1\"]+2) * historical_transactions[\"category_3\"]\n",
    "# np.sort(historical_transactions[\"category_1_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(new_transactions[\"category_1\"], new_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_1\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_transactions[\"category_1_3_cross\"] = (new_transactions[\"category_1\"]+2) * new_transactions[\"category_3\"]\n",
    "# np.sort(new_transactions[\"category_1_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(historical_transactions[\"category_2\"]+6, historical_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_2\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions[\"category_2_3_cross\"] = (historical_transactions[\"category_2\"]+6) * historical_transactions[\"category_3\"]\n",
    "# np.sort(historical_transactions[\"category_2_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(new_transactions[\"category_2\"]+6, new_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_2\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_transactions[\"category_2_3_cross\"] = (new_transactions[\"category_2\"]+6) * new_transactions[\"category_3\"]\n",
    "# np.sort(new_transactions[\"category_2_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def category_make_cross_feat(df):\n",
    "    df[\"category_1_3_cross\"] = (df[\"category_1\"]+2) * df[\"category_3\"]\n",
    "    df[\"category_2_3_cross\"] = (df[\"category_2\"]+6) * df[\"category_3\"]\n",
    "    return df\n",
    "\n",
    "historical_transactions = category_make_cross_feat(historical_transactions)\n",
    "new_transactions = category_make_cross_feat(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "170f0e959ba5250b191b7cee6b586bdabd347018"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "historical_transactions = pd.get_dummies(historical_transactions, columns=['category_2', \n",
    "                                                                           'category_3',\n",
    "                                                                           'category_1_3_cross',\n",
    "                                                                           'category_2_3_cross'])\n",
    "new_transactions = pd.get_dummies(new_transactions, columns=['category_2', \n",
    "                                                             'category_3',\n",
    "                                                             'category_1_3_cross',\n",
    "                                                             'category_2_3_cross'])\n",
    "\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)\n",
    "\n",
    "agg_fun = {'authorized_flag': ['sum', 'mean', 'min', 'std', 'count']} # max is all 1's, useless\n",
    "auth_mean = historical_transactions.groupby(['card_id']).agg(agg_fun)\n",
    "auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns.values]\n",
    "auth_mean.reset_index(inplace=True)\n",
    "\n",
    "authorized_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 0]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90536f89e81fc4bb7f45a17f47e4b627f53e69b4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "historical_transactions['purchase_month'] = historical_transactions['purchase_date'].dt.month\n",
    "authorized_transactions['purchase_month'] = authorized_transactions['purchase_date'].dt.month\n",
    "new_transactions['purchase_month'] = new_transactions['purchase_date'].dt.month\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5de9c3bcc2ad2dfeb943e1b02fef3e433c91af3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def aggregate_transactions(history):\n",
    "    \n",
    "    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).\\\n",
    "                                      astype(np.int64) * 1e-9\n",
    "    \n",
    "    agg_func = {\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'category_2_1.0': ['mean'],\n",
    "        'category_2_2.0': ['mean'],\n",
    "        'category_2_3.0': ['mean'],\n",
    "        'category_2_4.0': ['mean'],\n",
    "        'category_2_5.0': ['mean'],\n",
    "        'category_3_1': ['mean'],\n",
    "        'category_3_2': ['mean'],\n",
    "        'category_3_3': ['mean'],\n",
    "        'category_1_3_cross_3': ['mean'],\n",
    "        'category_1_3_cross_4': ['mean'],\n",
    "        'category_1_3_cross_6': ['mean'],\n",
    "        'category_1_3_cross_8': ['mean'],\n",
    "        'category_1_3_cross_9': ['mean'],\n",
    "        'category_1_3_cross_12': ['mean'],\n",
    "        'category_2_3_cross_7.0': ['mean'],\n",
    "        'category_2_3_cross_8.0': ['mean'],\n",
    "        'category_2_3_cross_9.0': ['mean'],\n",
    "        'category_2_3_cross_10.0': ['mean'],\n",
    "        'category_2_3_cross_11.0': ['mean'],\n",
    "        'category_2_3_cross_12.0': ['mean'],\n",
    "        'category_2_3_cross_14.0': ['mean'],\n",
    "        'category_2_3_cross_16.0': ['mean'],\n",
    "        'category_2_3_cross_20.0': ['mean'],\n",
    "        'category_2_3_cross_21.0': ['mean'],\n",
    "        'category_2_3_cross_22.0': ['mean'],\n",
    "        'category_2_3_cross_24.0': ['mean'],\n",
    "        'category_2_3_cross_27.0': ['mean'],\n",
    "        'category_2_3_cross_30.0': ['mean'],\n",
    "        'category_2_3_cross_33.0': ['mean'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'state_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std', 'count'], #one count is enough, others are just the same\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'purchase_month': ['mean', 'max', 'min', 'std'],\n",
    "        'purchase_date': [np.ptp, 'min', 'max'],\n",
    "        'month_lag': ['min', 'max']\n",
    "        }\n",
    "    \n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "    \n",
    "    df = (history.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='transactions_count'))\n",
    "    \n",
    "    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n",
    "    \n",
    "    return agg_history\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf1f963f61841ef34f79fd16364bbf59b7f4e8a4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = aggregate_transactions(historical_transactions)\n",
    "history.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n",
    "history[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # history[[\"hist_purchase_amount_count\", \"hist_installments_count\", \"hist_purchase_month_count\"]].head(500)\n",
    "# history.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c1bdbaa7c16e22436893354b31d47e1846330ab"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "authorized = aggregate_transactions(authorized_transactions)\n",
    "authorized.columns = ['auth_' + c if c != 'card_id' else c for c in authorized.columns]\n",
    "authorized[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cc2775c29c17cb7438f3f5c45777b894afa94fc"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "new = aggregate_transactions(new_transactions)\n",
    "new.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n",
    "new[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb443fb1e2a47f5a0bef02921a2cba1d4e95e673"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def aggregate_per_month(history):\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "\n",
    "    agg_func = {\n",
    "#             'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "#             'installments': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "            'purchase_amount': ['count', 'sum'],\n",
    "            'installments': ['count', 'sum'],\n",
    "            }\n",
    "\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True)\n",
    "    \n",
    "    return final_group\n",
    "#___________________________________________________________\n",
    "final_group =  aggregate_per_month(historical_transactions) \n",
    "final_group[:10]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e5e313f605160783127a6f0798f176eaf6a55a4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.merge(train, history, on='card_id', how='left')\n",
    "test = pd.merge(test, history, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, authorized, on='card_id', how='left')\n",
    "test = pd.merge(test, authorized, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, new, on='card_id', how='left')\n",
    "test = pd.merge(test, new, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, final_group, on='card_id', how='left')\n",
    "test = pd.merge(test, final_group, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, auth_mean, on='card_id', how='left')\n",
    "test = pd.merge(test, auth_mean, on='card_id', how='left')\n",
    "\n",
    "print(\"Train Shape:\", train.shape)\n",
    "print(\"Test Shape:\", test.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feat(df):\n",
    "    # Feature crosses\n",
    "    df[\"feature_1_2_cross\"] = df[\"feature_1\"] + (df[\"feature_2\"]-1)*5\n",
    "    df[\"feature_1_3_cross\"] = df[\"feature_1\"] + df[\"feature_3\"]*3\n",
    "    df[\"feature_2_3_cross\"] = df[\"feature_2\"] + df[\"feature_3\"]*3\n",
    "    df = pd.get_dummies(df, columns=[\"feature_1_2_cross\", \"feature_1_3_cross\", \"feature_2_3_cross\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = generate_feat(train)\n",
    "test = generate_feat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_2_3_feat(df, feat_list):\n",
    "    for feat in feat_list:\n",
    "        df[feat+\"_power2\"] = df[feat]**2\n",
    "#         df[feat+\"_power3\"] = df[feat]**3\n",
    "    return df\n",
    "\n",
    "feat_list = [\"elapsed_time\", \"hist_purchase_date_ptp\"]\n",
    "train = power_2_3_feat(train, feat_list)\n",
    "test = power_2_3_feat(test, feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_feat(df, feat_list):\n",
    "    for feat in feat_list:\n",
    "        df[feat+\"_log\"] = np.log(df[feat])\n",
    "#         df[feat+\"_power3\"] = df[feat]**3\n",
    "    return df\n",
    "\n",
    "feat_list = [\"elapsed_time\"]\n",
    "train = log_feat(train, feat_list)\n",
    "test = log_feat(test, feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(100, 100))\n",
    "sns.heatmap(corrmat, vmax=1.0, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig(\"../img/corr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_feat_list = ['authorized_flag_min', \n",
    "                    'hist_purchase_amount_sum',\n",
    "                    'hist_purchase_amount_max',\n",
    "                    'hist_purchase_amount_min',\n",
    "                    'hist_purchase_amount_std',\n",
    "                    'hist_installments_sum',\n",
    "                    'hist_installments_max',\n",
    "                    'hist_installments_min',\n",
    "                    'hist_installments_std',\n",
    "                   ]\n",
    "train = train.drop(remove_feat_list, axis=1)\n",
    "test = test.drop(remove_feat_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(100, 100))\n",
    "sns.heatmap(corrmat, vmax=1.0, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig(\"../img/corr_after_feat_removal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../input/feat_list.pkl', 'rb') as f:\n",
    "#     feat_list = pickle.load(f)\n",
    "\n",
    "# train = train[feat_list]\n",
    "# test = test[feat_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target.pkl', 'wb') as f:\n",
    "    pickle.dump([train, target, test], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target.pkl', 'rb') as f:\n",
    "    [train, target, test] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n",
    "# saleprice correlation matrix\n",
    "\n",
    "# k = train.shape[1] #number of variables for heatmap\n",
    "# cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "# cm = np.corrcoef(df_train[cols].values.T)\n",
    "# sns.set(font_scale=1.25)\n",
    "# hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #scatterplot\n",
    "# sns.set()\n",
    "# # cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "# # sns.pairplot(df_train[cols], size = 2.5)\n",
    "# sns.pairplot(train, size = 2.5)\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,160))\n",
    "sns.distplot(target.values, bins=50, kde=False, color='blue')\n",
    "plt.title('Histogram of Loyalty Score before removal')\n",
    "plt.xlabel('Loyalty score', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "sns.distplot(target, fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(target, plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n",
    "print(\"Skewness: %f\" % pd.DataFrame(target).skew())\n",
    "print(\"Kurtosis: %f\" % pd.DataFrame(target).kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_target = min(value for value in target if value > -20)\n",
    "min_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_between_20_30 = [value for value in target if value >= -30 and value <=-20]\n",
    "len(idx_between_20_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_lessThan_30 = [value for value in target if value < -30]\n",
    "len(idx_lessThan_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/nottold/naive-ensemble-model-ridge-lasso\n",
    "class OutlierDetection(BaseEstimator):\n",
    "    def __init__(self, alpha, dims, std, mean, median):\n",
    "        self.alpha = alpha\n",
    "        self.dims = dims\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        self.median = median\n",
    "    def fit(self, X):\n",
    "        # std, mean, median = X.std(), X.mean(), X.median()\n",
    "        X[\"outliers\"] = 0\n",
    "        for col in X.columns:\n",
    "#             print(col)\n",
    "            if not col == \"outliers\":\n",
    "                # outlier_idx = (abs(X[col]) > (self.alpha * std[col] + mean[col]))\n",
    "                outlier_idx = (np.abs(X[col]) > (self.alpha * self.std[col] + self.mean[col]))\n",
    "                X.set_value(outlier_idx, \"outliers\", X[outlier_idx][\"outliers\"] + 1)\n",
    "        outliers = X[X[\"outliers\"] > self.dims]\n",
    "        X.drop(\"outliers\", axis=1, inplace=True)\n",
    "        outlier_idx = outliers.index.tolist()\n",
    "        # return outliers.index\n",
    "        return set(list(range(X.shape[0]))) - set(outlier_idx), outlier_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.DataFrame(target)\n",
    "\n",
    "outlier_removal = OutlierDetection(alpha=3, \n",
    "                                   dims=0, \n",
    "                                   std=target_df.std().astype('float'), \n",
    "                                   mean=target_df.mean().astype('float'), \n",
    "                                   median=target_df.median().astype('float'))\n",
    "normal_idx, outlier_idx = outlier_removal.fit(target_df)\n",
    "# samples = target_df.shape[0] - len(outlier)\n",
    "# xtrain = xtrain.drop(outlier_index).reset_index(drop=True)\n",
    "# y = y.drop(outlier_index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "796d4e17b4c4cc3121fc833669fc2eaf07bf4fba"
   },
   "outputs": [],
   "source": [
    "train[\"outliers\"] = 0\n",
    "train.at[outlier_idx, \"outliers\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"outliers\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'wb') as f:\n",
    "    pickle.dump([train, target, test, normal_idx, outlier_idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Model Without Outliers for 5 fold (n_repeats = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train[train['outliers'] == 0]\n",
    "df_target = target[normal_idx]\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199644, 212), (199644,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_regression_train(train, target, test, param, features, categorical_feats):\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))\n",
    "    return predictions, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.5885\tvalid_1's rmse: 1.6088\n",
      "[200]\ttraining's rmse: 1.55768\tvalid_1's rmse: 1.58216\n",
      "[300]\ttraining's rmse: 1.54258\tvalid_1's rmse: 1.57098\n",
      "[400]\ttraining's rmse: 1.53261\tvalid_1's rmse: 1.56486\n",
      "[500]\ttraining's rmse: 1.52505\tvalid_1's rmse: 1.56149\n",
      "[600]\ttraining's rmse: 1.51892\tvalid_1's rmse: 1.55916\n",
      "[700]\ttraining's rmse: 1.51377\tvalid_1's rmse: 1.5577\n",
      "[800]\ttraining's rmse: 1.50921\tvalid_1's rmse: 1.55672\n",
      "[900]\ttraining's rmse: 1.50498\tvalid_1's rmse: 1.55607\n",
      "[1000]\ttraining's rmse: 1.50102\tvalid_1's rmse: 1.55558\n",
      "[1100]\ttraining's rmse: 1.49723\tvalid_1's rmse: 1.55517\n",
      "[1200]\ttraining's rmse: 1.49361\tvalid_1's rmse: 1.5549\n",
      "[1300]\ttraining's rmse: 1.49009\tvalid_1's rmse: 1.55471\n",
      "[1400]\ttraining's rmse: 1.48662\tvalid_1's rmse: 1.55447\n",
      "[1500]\ttraining's rmse: 1.48328\tvalid_1's rmse: 1.55427\n",
      "[1600]\ttraining's rmse: 1.47998\tvalid_1's rmse: 1.55411\n",
      "[1700]\ttraining's rmse: 1.47671\tvalid_1's rmse: 1.55401\n",
      "[1800]\ttraining's rmse: 1.47344\tvalid_1's rmse: 1.55386\n",
      "[1900]\ttraining's rmse: 1.47029\tvalid_1's rmse: 1.55375\n",
      "[2000]\ttraining's rmse: 1.46719\tvalid_1's rmse: 1.55363\n",
      "[2100]\ttraining's rmse: 1.46418\tvalid_1's rmse: 1.55357\n",
      "[2200]\ttraining's rmse: 1.46127\tvalid_1's rmse: 1.55355\n",
      "[2300]\ttraining's rmse: 1.45826\tvalid_1's rmse: 1.55344\n",
      "[2400]\ttraining's rmse: 1.45528\tvalid_1's rmse: 1.55343\n",
      "[2500]\ttraining's rmse: 1.45235\tvalid_1's rmse: 1.5534\n",
      "[2600]\ttraining's rmse: 1.4494\tvalid_1's rmse: 1.55332\n",
      "[2700]\ttraining's rmse: 1.44665\tvalid_1's rmse: 1.55332\n",
      "[2800]\ttraining's rmse: 1.44386\tvalid_1's rmse: 1.55325\n",
      "[2900]\ttraining's rmse: 1.44117\tvalid_1's rmse: 1.55325\n",
      "[3000]\ttraining's rmse: 1.43846\tvalid_1's rmse: 1.55323\n",
      "[3100]\ttraining's rmse: 1.43562\tvalid_1's rmse: 1.55318\n",
      "[3200]\ttraining's rmse: 1.43285\tvalid_1's rmse: 1.55324\n",
      "Early stopping, best iteration is:\n",
      "[3072]\ttraining's rmse: 1.43642\tvalid_1's rmse: 1.55316\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.59281\tvalid_1's rmse: 1.59353\n",
      "[200]\ttraining's rmse: 1.56239\tvalid_1's rmse: 1.56642\n",
      "[300]\ttraining's rmse: 1.54728\tvalid_1's rmse: 1.55437\n",
      "[400]\ttraining's rmse: 1.53734\tvalid_1's rmse: 1.54791\n",
      "[500]\ttraining's rmse: 1.52983\tvalid_1's rmse: 1.544\n",
      "[600]\ttraining's rmse: 1.52384\tvalid_1's rmse: 1.54173\n",
      "[700]\ttraining's rmse: 1.5186\tvalid_1's rmse: 1.54031\n",
      "[800]\ttraining's rmse: 1.51391\tvalid_1's rmse: 1.5394\n",
      "[900]\ttraining's rmse: 1.5096\tvalid_1's rmse: 1.53871\n",
      "[1000]\ttraining's rmse: 1.50555\tvalid_1's rmse: 1.53825\n",
      "[1100]\ttraining's rmse: 1.50178\tvalid_1's rmse: 1.53796\n",
      "[1200]\ttraining's rmse: 1.49817\tvalid_1's rmse: 1.53779\n",
      "[1300]\ttraining's rmse: 1.49455\tvalid_1's rmse: 1.53767\n",
      "[1400]\ttraining's rmse: 1.49116\tvalid_1's rmse: 1.5375\n",
      "[1500]\ttraining's rmse: 1.48784\tvalid_1's rmse: 1.53733\n",
      "[1600]\ttraining's rmse: 1.48453\tvalid_1's rmse: 1.53718\n",
      "[1700]\ttraining's rmse: 1.48124\tvalid_1's rmse: 1.53703\n",
      "[1800]\ttraining's rmse: 1.47808\tvalid_1's rmse: 1.5369\n",
      "[1900]\ttraining's rmse: 1.47489\tvalid_1's rmse: 1.53678\n",
      "[2000]\ttraining's rmse: 1.47181\tvalid_1's rmse: 1.53662\n",
      "[2100]\ttraining's rmse: 1.46883\tvalid_1's rmse: 1.5366\n",
      "[2200]\ttraining's rmse: 1.46583\tvalid_1's rmse: 1.53657\n",
      "[2300]\ttraining's rmse: 1.46275\tvalid_1's rmse: 1.53652\n",
      "[2400]\ttraining's rmse: 1.45988\tvalid_1's rmse: 1.53645\n",
      "[2500]\ttraining's rmse: 1.45691\tvalid_1's rmse: 1.53635\n",
      "[2600]\ttraining's rmse: 1.45385\tvalid_1's rmse: 1.53633\n",
      "[2700]\ttraining's rmse: 1.45098\tvalid_1's rmse: 1.5363\n",
      "[2800]\ttraining's rmse: 1.44809\tvalid_1's rmse: 1.53637\n",
      "[2900]\ttraining's rmse: 1.44522\tvalid_1's rmse: 1.53637\n",
      "Early stopping, best iteration is:\n",
      "[2725]\ttraining's rmse: 1.45026\tvalid_1's rmse: 1.53628\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.59057\tvalid_1's rmse: 1.60131\n",
      "[200]\ttraining's rmse: 1.56017\tvalid_1's rmse: 1.57376\n",
      "[300]\ttraining's rmse: 1.5451\tvalid_1's rmse: 1.56178\n",
      "[400]\ttraining's rmse: 1.53514\tvalid_1's rmse: 1.55538\n",
      "[500]\ttraining's rmse: 1.5276\tvalid_1's rmse: 1.55181\n",
      "[600]\ttraining's rmse: 1.52153\tvalid_1's rmse: 1.5497\n",
      "[700]\ttraining's rmse: 1.51629\tvalid_1's rmse: 1.54831\n",
      "[800]\ttraining's rmse: 1.51163\tvalid_1's rmse: 1.54745\n",
      "[900]\ttraining's rmse: 1.50741\tvalid_1's rmse: 1.54693\n",
      "[1000]\ttraining's rmse: 1.50338\tvalid_1's rmse: 1.54645\n",
      "[1100]\ttraining's rmse: 1.49948\tvalid_1's rmse: 1.54613\n",
      "[1200]\ttraining's rmse: 1.49583\tvalid_1's rmse: 1.54581\n",
      "[1300]\ttraining's rmse: 1.49223\tvalid_1's rmse: 1.54562\n",
      "[1400]\ttraining's rmse: 1.48873\tvalid_1's rmse: 1.54546\n",
      "[1500]\ttraining's rmse: 1.4853\tvalid_1's rmse: 1.54531\n",
      "[1600]\ttraining's rmse: 1.48199\tvalid_1's rmse: 1.54519\n",
      "[1700]\ttraining's rmse: 1.47869\tvalid_1's rmse: 1.54508\n",
      "[1800]\ttraining's rmse: 1.47538\tvalid_1's rmse: 1.545\n",
      "[1900]\ttraining's rmse: 1.47216\tvalid_1's rmse: 1.54495\n",
      "[2000]\ttraining's rmse: 1.46909\tvalid_1's rmse: 1.54487\n",
      "[2100]\ttraining's rmse: 1.46605\tvalid_1's rmse: 1.54485\n",
      "[2200]\ttraining's rmse: 1.46294\tvalid_1's rmse: 1.5448\n",
      "[2300]\ttraining's rmse: 1.45992\tvalid_1's rmse: 1.5448\n",
      "[2400]\ttraining's rmse: 1.45694\tvalid_1's rmse: 1.5447\n",
      "[2500]\ttraining's rmse: 1.45392\tvalid_1's rmse: 1.54472\n",
      "[2600]\ttraining's rmse: 1.45105\tvalid_1's rmse: 1.54472\n",
      "[2700]\ttraining's rmse: 1.44819\tvalid_1's rmse: 1.54467\n",
      "[2800]\ttraining's rmse: 1.44532\tvalid_1's rmse: 1.54463\n",
      "[2900]\ttraining's rmse: 1.44239\tvalid_1's rmse: 1.54466\n",
      "Early stopping, best iteration is:\n",
      "[2795]\ttraining's rmse: 1.44545\tvalid_1's rmse: 1.54462\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.59246\tvalid_1's rmse: 1.59516\n",
      "[200]\ttraining's rmse: 1.56159\tvalid_1's rmse: 1.56842\n",
      "[300]\ttraining's rmse: 1.54625\tvalid_1's rmse: 1.55746\n",
      "[400]\ttraining's rmse: 1.53626\tvalid_1's rmse: 1.55166\n",
      "[500]\ttraining's rmse: 1.52865\tvalid_1's rmse: 1.54807\n",
      "[600]\ttraining's rmse: 1.52249\tvalid_1's rmse: 1.54599\n",
      "[700]\ttraining's rmse: 1.51728\tvalid_1's rmse: 1.54488\n",
      "[800]\ttraining's rmse: 1.51254\tvalid_1's rmse: 1.54409\n",
      "[900]\ttraining's rmse: 1.5082\tvalid_1's rmse: 1.54368\n",
      "[1000]\ttraining's rmse: 1.50426\tvalid_1's rmse: 1.54323\n",
      "[1100]\ttraining's rmse: 1.50045\tvalid_1's rmse: 1.54299\n",
      "[1200]\ttraining's rmse: 1.4968\tvalid_1's rmse: 1.54286\n",
      "[1300]\ttraining's rmse: 1.49318\tvalid_1's rmse: 1.54265\n",
      "[1400]\ttraining's rmse: 1.48978\tvalid_1's rmse: 1.54256\n",
      "[1500]\ttraining's rmse: 1.48638\tvalid_1's rmse: 1.54241\n",
      "[1600]\ttraining's rmse: 1.48302\tvalid_1's rmse: 1.54232\n",
      "[1700]\ttraining's rmse: 1.47974\tvalid_1's rmse: 1.54222\n",
      "[1800]\ttraining's rmse: 1.47657\tvalid_1's rmse: 1.54223\n",
      "[1900]\ttraining's rmse: 1.4735\tvalid_1's rmse: 1.54217\n",
      "[2000]\ttraining's rmse: 1.47035\tvalid_1's rmse: 1.54204\n",
      "[2100]\ttraining's rmse: 1.46724\tvalid_1's rmse: 1.54202\n",
      "[2200]\ttraining's rmse: 1.46409\tvalid_1's rmse: 1.5419\n",
      "[2300]\ttraining's rmse: 1.46109\tvalid_1's rmse: 1.54182\n",
      "[2400]\ttraining's rmse: 1.45802\tvalid_1's rmse: 1.54176\n",
      "[2500]\ttraining's rmse: 1.45503\tvalid_1's rmse: 1.5418\n",
      "Early stopping, best iteration is:\n",
      "[2397]\ttraining's rmse: 1.4581\tvalid_1's rmse: 1.54175\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.59561\tvalid_1's rmse: 1.58115\n",
      "[200]\ttraining's rmse: 1.56465\tvalid_1's rmse: 1.5557\n",
      "[300]\ttraining's rmse: 1.54937\tvalid_1's rmse: 1.54485\n",
      "[400]\ttraining's rmse: 1.53944\tvalid_1's rmse: 1.53897\n",
      "[500]\ttraining's rmse: 1.53196\tvalid_1's rmse: 1.53554\n",
      "[600]\ttraining's rmse: 1.52591\tvalid_1's rmse: 1.53356\n",
      "[700]\ttraining's rmse: 1.52072\tvalid_1's rmse: 1.5323\n",
      "[800]\ttraining's rmse: 1.51612\tvalid_1's rmse: 1.53154\n",
      "[900]\ttraining's rmse: 1.51194\tvalid_1's rmse: 1.53109\n",
      "[1000]\ttraining's rmse: 1.50788\tvalid_1's rmse: 1.53074\n",
      "[1100]\ttraining's rmse: 1.50405\tvalid_1's rmse: 1.53046\n",
      "[1200]\ttraining's rmse: 1.50032\tvalid_1's rmse: 1.53013\n",
      "[1300]\ttraining's rmse: 1.49666\tvalid_1's rmse: 1.52991\n",
      "[1400]\ttraining's rmse: 1.49305\tvalid_1's rmse: 1.52968\n",
      "[1500]\ttraining's rmse: 1.48975\tvalid_1's rmse: 1.52954\n",
      "[1600]\ttraining's rmse: 1.4864\tvalid_1's rmse: 1.52936\n",
      "[1700]\ttraining's rmse: 1.48309\tvalid_1's rmse: 1.52934\n",
      "[1800]\ttraining's rmse: 1.47982\tvalid_1's rmse: 1.52923\n",
      "[1900]\ttraining's rmse: 1.47657\tvalid_1's rmse: 1.5292\n",
      "[2000]\ttraining's rmse: 1.47333\tvalid_1's rmse: 1.52905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2100]\ttraining's rmse: 1.47022\tvalid_1's rmse: 1.52895\n",
      "[2200]\ttraining's rmse: 1.46725\tvalid_1's rmse: 1.529\n",
      "[2300]\ttraining's rmse: 1.46424\tvalid_1's rmse: 1.52885\n",
      "[2400]\ttraining's rmse: 1.46125\tvalid_1's rmse: 1.52874\n",
      "[2500]\ttraining's rmse: 1.45826\tvalid_1's rmse: 1.52871\n",
      "[2600]\ttraining's rmse: 1.45523\tvalid_1's rmse: 1.52875\n",
      "[2700]\ttraining's rmse: 1.45225\tvalid_1's rmse: 1.52875\n",
      "Early stopping, best iteration is:\n",
      "[2522]\ttraining's rmse: 1.45755\tvalid_1's rmse: 1.5287\n",
      "CV score: 1.54092 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01, #default: 0.005 (3.66940)   /   0.005(3.67032), 0.01 (3.67152), 0.05 ()\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"nthread\": -1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "normal_predictions, oof = lgbm_regression_train(df_train, \n",
    "                                                df_target, \n",
    "                                                test, \n",
    "                                                param, \n",
    "                                                features, \n",
    "                                                categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "model_without_outliers[\"target\"] = normal_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Training Model For Outliers Classification for 5 fold (n_repeats = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_classification_train(df_train, target, df_test, param, features, categorical_feats):\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(len(df_train))\n",
    "    predictions = np.zeros(len(df_test))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    start = time.time()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "        \n",
    "    print(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))\n",
    "\n",
    "    return predictions, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0462539\tvalid_1's binary_logloss: 0.0483859\n",
      "[200]\ttraining's binary_logloss: 0.0462506\tvalid_1's binary_logloss: 0.0483834\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0462377\tvalid_1's binary_logloss: 0.0482944\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0466662\tvalid_1's binary_logloss: 0.0470919\n",
      "[200]\ttraining's binary_logloss: 0.0466763\tvalid_1's binary_logloss: 0.047128\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0466228\tvalid_1's binary_logloss: 0.0470608\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0465256\tvalid_1's binary_logloss: 0.0466832\n",
      "[200]\ttraining's binary_logloss: 0.0464995\tvalid_1's binary_logloss: 0.0466729\n",
      "[300]\ttraining's binary_logloss: 0.0465142\tvalid_1's binary_logloss: 0.0466902\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's binary_logloss: 0.0464978\tvalid_1's binary_logloss: 0.046675\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0455144\tvalid_1's binary_logloss: 0.051521\n",
      "[200]\ttraining's binary_logloss: 0.0455096\tvalid_1's binary_logloss: 0.0515042\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.0455032\tvalid_1's binary_logloss: 0.0514879\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0464147\tvalid_1's binary_logloss: 0.0470045\n",
      "[200]\ttraining's binary_logloss: 0.0464242\tvalid_1's binary_logloss: 0.0470161\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0463755\tvalid_1's binary_logloss: 0.046915\n",
      "CV score: 0.04809 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333}\n",
    "\n",
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "\n",
    "target = train['outliers']\n",
    "del train['outliers']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]\n",
    "outlier_label, oof_class = lgbm_classification_train(train, target, test, param, features, categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>0.022946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>0.010461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab  0.022946\n",
       "1  C_ID_130fd0cbdd  0.001735\n",
       "2  C_ID_b709037bc5  0.010461\n",
       "3  C_ID_d27d835a9f  0.001735\n",
       "4  C_ID_2b5e3df5c2  0.001735"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlier_prob = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "df_outlier_prob[\"target\"] = outlier_label\n",
    "df_outlier_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Combining Submission for 5 fold (n_repeats = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_id = pd.DataFrame(\\\n",
    "                          df_outlier_prob.sort_values(by='target',\n",
    "                                                      ascending = False)\n",
    "                          .head(25000)['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv('../result/Blend2_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.346967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.354020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.148607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.090599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.346967\n",
       "1  C_ID_130fd0cbdd -0.354020\n",
       "2  C_ID_b709037bc5 -0.932773\n",
       "3  C_ID_d27d835a9f -0.148607\n",
       "4  C_ID_2b5e3df5c2 -1.090599"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_submission.shape[0])\n",
    "best_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.346967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_6d8dba8475</td>\n",
       "      <td>-0.881375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_4859ac9ed5</td>\n",
       "      <td>-0.641561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_7f1041e8e1</td>\n",
       "      <td>-5.193301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_22e4a47c72</td>\n",
       "      <td>0.341024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.346967\n",
       "1  C_ID_6d8dba8475 -0.881375\n",
       "2  C_ID_4859ac9ed5 -0.641561\n",
       "3  C_ID_7f1041e8e1 -5.193301\n",
       "4  C_ID_22e4a47c72  0.341024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outlier_id.shape[0])\n",
    "most_likely_liers = best_submission.merge(outlier_id,how='right')\n",
    "most_likely_liers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 16s, sys: 20.2 ms, total: 4min 16s\n",
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for card_id in most_likely_liers['card_id']:\n",
    "    model_without_outliers.loc[model_without_outliers['card_id']==card_id,'target']\\\n",
    "    = most_likely_liers.loc[most_likely_liers['card_id']==card_id,'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_without_outliers.to_csv(\"../result/Blend2_v3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(normal_predictions.shape)\n",
    "# normal_predictions[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_without_outliers.shape)\n",
    "# model_without_outliers[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training Model Without Outliers for 5 fold (n_repeats = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_regression_train_n_repeats_2(train, target, test, param, features, categorical_feats):\n",
    "    folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4520)\n",
    "    oof_lgb = np.zeros(len(train))\n",
    "    predictions_lgb = np.zeros(len(test))\n",
    "    start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 11000\n",
    "        clf = lgb.train(lgbparam, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "        oof_lgb[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions_lgb += clf.predict(test[features], num_iteration=clf.best_iteration) / (5 * 2)\n",
    "\n",
    "    print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_lgb, target)**0.5))\n",
    "    return predictions_lgb, oof_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62477\tvalid_1's rmse: 1.63771\n",
      "[200]\ttraining's rmse: 1.5903\tvalid_1's rmse: 1.60438\n",
      "[300]\ttraining's rmse: 1.57167\tvalid_1's rmse: 1.58714\n",
      "[400]\ttraining's rmse: 1.55985\tvalid_1's rmse: 1.57689\n",
      "[500]\ttraining's rmse: 1.55142\tvalid_1's rmse: 1.56994\n",
      "[600]\ttraining's rmse: 1.5449\tvalid_1's rmse: 1.56478\n",
      "[700]\ttraining's rmse: 1.53956\tvalid_1's rmse: 1.56081\n",
      "[800]\ttraining's rmse: 1.5351\tvalid_1's rmse: 1.55798\n",
      "[900]\ttraining's rmse: 1.53117\tvalid_1's rmse: 1.55579\n",
      "[1000]\ttraining's rmse: 1.52765\tvalid_1's rmse: 1.55407\n",
      "[1100]\ttraining's rmse: 1.52442\tvalid_1's rmse: 1.55264\n",
      "[1200]\ttraining's rmse: 1.52149\tvalid_1's rmse: 1.55151\n",
      "[1300]\ttraining's rmse: 1.51883\tvalid_1's rmse: 1.55073\n",
      "[1400]\ttraining's rmse: 1.51629\tvalid_1's rmse: 1.55009\n",
      "[1500]\ttraining's rmse: 1.51387\tvalid_1's rmse: 1.54955\n",
      "[1600]\ttraining's rmse: 1.5116\tvalid_1's rmse: 1.54909\n",
      "[1700]\ttraining's rmse: 1.50942\tvalid_1's rmse: 1.54871\n",
      "[1800]\ttraining's rmse: 1.50729\tvalid_1's rmse: 1.5484\n",
      "[1900]\ttraining's rmse: 1.50525\tvalid_1's rmse: 1.54817\n",
      "[2000]\ttraining's rmse: 1.50329\tvalid_1's rmse: 1.54797\n",
      "[2100]\ttraining's rmse: 1.50137\tvalid_1's rmse: 1.5478\n",
      "[2200]\ttraining's rmse: 1.49951\tvalid_1's rmse: 1.54764\n",
      "[2300]\ttraining's rmse: 1.49765\tvalid_1's rmse: 1.54747\n",
      "[2400]\ttraining's rmse: 1.49585\tvalid_1's rmse: 1.54728\n",
      "[2500]\ttraining's rmse: 1.49401\tvalid_1's rmse: 1.54718\n",
      "[2600]\ttraining's rmse: 1.49226\tvalid_1's rmse: 1.5471\n",
      "[2700]\ttraining's rmse: 1.49051\tvalid_1's rmse: 1.54696\n",
      "[2800]\ttraining's rmse: 1.48876\tvalid_1's rmse: 1.54683\n",
      "[2900]\ttraining's rmse: 1.48707\tvalid_1's rmse: 1.54673\n",
      "[3000]\ttraining's rmse: 1.48539\tvalid_1's rmse: 1.54663\n",
      "[3100]\ttraining's rmse: 1.48372\tvalid_1's rmse: 1.54657\n",
      "[3200]\ttraining's rmse: 1.48211\tvalid_1's rmse: 1.54645\n",
      "[3300]\ttraining's rmse: 1.48044\tvalid_1's rmse: 1.54637\n",
      "[3400]\ttraining's rmse: 1.47881\tvalid_1's rmse: 1.54629\n",
      "[3500]\ttraining's rmse: 1.47728\tvalid_1's rmse: 1.54621\n",
      "[3600]\ttraining's rmse: 1.47566\tvalid_1's rmse: 1.5461\n",
      "[3700]\ttraining's rmse: 1.47409\tvalid_1's rmse: 1.54607\n",
      "[3800]\ttraining's rmse: 1.47249\tvalid_1's rmse: 1.54601\n",
      "[3900]\ttraining's rmse: 1.47093\tvalid_1's rmse: 1.54594\n",
      "[4000]\ttraining's rmse: 1.46936\tvalid_1's rmse: 1.54587\n",
      "[4100]\ttraining's rmse: 1.46784\tvalid_1's rmse: 1.54585\n",
      "[4200]\ttraining's rmse: 1.46631\tvalid_1's rmse: 1.54579\n",
      "[4300]\ttraining's rmse: 1.46482\tvalid_1's rmse: 1.54574\n",
      "[4400]\ttraining's rmse: 1.46331\tvalid_1's rmse: 1.54572\n",
      "[4500]\ttraining's rmse: 1.46182\tvalid_1's rmse: 1.54567\n",
      "[4600]\ttraining's rmse: 1.46032\tvalid_1's rmse: 1.54567\n",
      "[4700]\ttraining's rmse: 1.45883\tvalid_1's rmse: 1.54563\n",
      "Early stopping, best iteration is:\n",
      "[4693]\ttraining's rmse: 1.45893\tvalid_1's rmse: 1.54562\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62607\tvalid_1's rmse: 1.63036\n",
      "[200]\ttraining's rmse: 1.59147\tvalid_1's rmse: 1.59813\n",
      "[300]\ttraining's rmse: 1.57271\tvalid_1's rmse: 1.58167\n",
      "[400]\ttraining's rmse: 1.56057\tvalid_1's rmse: 1.57169\n",
      "[500]\ttraining's rmse: 1.55198\tvalid_1's rmse: 1.56508\n",
      "[600]\ttraining's rmse: 1.54522\tvalid_1's rmse: 1.56032\n",
      "[700]\ttraining's rmse: 1.53969\tvalid_1's rmse: 1.55676\n",
      "[800]\ttraining's rmse: 1.53512\tvalid_1's rmse: 1.55417\n",
      "[900]\ttraining's rmse: 1.53108\tvalid_1's rmse: 1.55214\n",
      "[1000]\ttraining's rmse: 1.52753\tvalid_1's rmse: 1.5507\n",
      "[1100]\ttraining's rmse: 1.52432\tvalid_1's rmse: 1.54948\n",
      "[1200]\ttraining's rmse: 1.52136\tvalid_1's rmse: 1.54856\n",
      "[1300]\ttraining's rmse: 1.51865\tvalid_1's rmse: 1.54785\n",
      "[1400]\ttraining's rmse: 1.51612\tvalid_1's rmse: 1.54732\n",
      "[1500]\ttraining's rmse: 1.51376\tvalid_1's rmse: 1.54688\n",
      "[1600]\ttraining's rmse: 1.51146\tvalid_1's rmse: 1.54652\n",
      "[1700]\ttraining's rmse: 1.5093\tvalid_1's rmse: 1.54633\n",
      "[1800]\ttraining's rmse: 1.5072\tvalid_1's rmse: 1.54608\n",
      "[1900]\ttraining's rmse: 1.50514\tvalid_1's rmse: 1.5459\n",
      "[2000]\ttraining's rmse: 1.50316\tvalid_1's rmse: 1.54574\n",
      "[2100]\ttraining's rmse: 1.50121\tvalid_1's rmse: 1.54561\n",
      "[2200]\ttraining's rmse: 1.49929\tvalid_1's rmse: 1.54553\n",
      "[2300]\ttraining's rmse: 1.49737\tvalid_1's rmse: 1.54538\n",
      "[2400]\ttraining's rmse: 1.49556\tvalid_1's rmse: 1.54525\n",
      "[2500]\ttraining's rmse: 1.49375\tvalid_1's rmse: 1.54515\n",
      "[2600]\ttraining's rmse: 1.49191\tvalid_1's rmse: 1.54505\n",
      "[2700]\ttraining's rmse: 1.49015\tvalid_1's rmse: 1.54499\n",
      "[2800]\ttraining's rmse: 1.48843\tvalid_1's rmse: 1.54492\n",
      "[2900]\ttraining's rmse: 1.48671\tvalid_1's rmse: 1.54489\n",
      "[3000]\ttraining's rmse: 1.48497\tvalid_1's rmse: 1.54479\n",
      "[3100]\ttraining's rmse: 1.48332\tvalid_1's rmse: 1.54476\n",
      "[3200]\ttraining's rmse: 1.48168\tvalid_1's rmse: 1.5447\n",
      "[3300]\ttraining's rmse: 1.47997\tvalid_1's rmse: 1.54465\n",
      "[3400]\ttraining's rmse: 1.47835\tvalid_1's rmse: 1.54462\n",
      "[3500]\ttraining's rmse: 1.4767\tvalid_1's rmse: 1.54456\n",
      "[3600]\ttraining's rmse: 1.47508\tvalid_1's rmse: 1.54448\n",
      "[3700]\ttraining's rmse: 1.47348\tvalid_1's rmse: 1.54445\n",
      "[3800]\ttraining's rmse: 1.47182\tvalid_1's rmse: 1.54438\n",
      "[3900]\ttraining's rmse: 1.47023\tvalid_1's rmse: 1.54435\n",
      "Early stopping, best iteration is:\n",
      "[3885]\ttraining's rmse: 1.47046\tvalid_1's rmse: 1.54433\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62665\tvalid_1's rmse: 1.62828\n",
      "[200]\ttraining's rmse: 1.59196\tvalid_1's rmse: 1.59592\n",
      "[300]\ttraining's rmse: 1.57313\tvalid_1's rmse: 1.57945\n",
      "[400]\ttraining's rmse: 1.5612\tvalid_1's rmse: 1.56981\n",
      "[500]\ttraining's rmse: 1.55257\tvalid_1's rmse: 1.56343\n",
      "[600]\ttraining's rmse: 1.54574\tvalid_1's rmse: 1.5588\n",
      "[700]\ttraining's rmse: 1.5403\tvalid_1's rmse: 1.55553\n",
      "[800]\ttraining's rmse: 1.53576\tvalid_1's rmse: 1.5531\n",
      "[900]\ttraining's rmse: 1.53176\tvalid_1's rmse: 1.55122\n",
      "[1000]\ttraining's rmse: 1.52824\tvalid_1's rmse: 1.54981\n",
      "[1100]\ttraining's rmse: 1.52502\tvalid_1's rmse: 1.54862\n",
      "[1200]\ttraining's rmse: 1.52211\tvalid_1's rmse: 1.54769\n",
      "[1300]\ttraining's rmse: 1.51942\tvalid_1's rmse: 1.54692\n",
      "[1400]\ttraining's rmse: 1.51686\tvalid_1's rmse: 1.54639\n",
      "[1500]\ttraining's rmse: 1.51445\tvalid_1's rmse: 1.54589\n",
      "[1600]\ttraining's rmse: 1.51219\tvalid_1's rmse: 1.54546\n",
      "[1700]\ttraining's rmse: 1.51004\tvalid_1's rmse: 1.54514\n",
      "[1800]\ttraining's rmse: 1.50796\tvalid_1's rmse: 1.54494\n",
      "[1900]\ttraining's rmse: 1.50592\tvalid_1's rmse: 1.54476\n",
      "[2000]\ttraining's rmse: 1.50395\tvalid_1's rmse: 1.54452\n",
      "[2100]\ttraining's rmse: 1.50199\tvalid_1's rmse: 1.54436\n",
      "[2200]\ttraining's rmse: 1.50014\tvalid_1's rmse: 1.54418\n",
      "[2300]\ttraining's rmse: 1.49826\tvalid_1's rmse: 1.544\n",
      "[2400]\ttraining's rmse: 1.49643\tvalid_1's rmse: 1.54382\n",
      "[2500]\ttraining's rmse: 1.49467\tvalid_1's rmse: 1.5437\n",
      "[2600]\ttraining's rmse: 1.49296\tvalid_1's rmse: 1.5436\n",
      "[2700]\ttraining's rmse: 1.49125\tvalid_1's rmse: 1.54354\n",
      "[2800]\ttraining's rmse: 1.48954\tvalid_1's rmse: 1.54346\n",
      "[2900]\ttraining's rmse: 1.48784\tvalid_1's rmse: 1.54342\n",
      "[3000]\ttraining's rmse: 1.48617\tvalid_1's rmse: 1.54337\n",
      "[3100]\ttraining's rmse: 1.4845\tvalid_1's rmse: 1.54328\n",
      "[3200]\ttraining's rmse: 1.48284\tvalid_1's rmse: 1.54318\n",
      "[3300]\ttraining's rmse: 1.48118\tvalid_1's rmse: 1.54312\n",
      "[3400]\ttraining's rmse: 1.47957\tvalid_1's rmse: 1.54305\n",
      "[3500]\ttraining's rmse: 1.47796\tvalid_1's rmse: 1.54299\n",
      "[3600]\ttraining's rmse: 1.47635\tvalid_1's rmse: 1.54296\n",
      "[3700]\ttraining's rmse: 1.47475\tvalid_1's rmse: 1.54293\n",
      "[3800]\ttraining's rmse: 1.47319\tvalid_1's rmse: 1.54287\n",
      "[3900]\ttraining's rmse: 1.47163\tvalid_1's rmse: 1.54282\n",
      "[4000]\ttraining's rmse: 1.47007\tvalid_1's rmse: 1.54278\n",
      "[4100]\ttraining's rmse: 1.46855\tvalid_1's rmse: 1.54272\n",
      "[4200]\ttraining's rmse: 1.46704\tvalid_1's rmse: 1.54272\n",
      "[4300]\ttraining's rmse: 1.46551\tvalid_1's rmse: 1.54268\n",
      "[4400]\ttraining's rmse: 1.46397\tvalid_1's rmse: 1.54266\n",
      "[4500]\ttraining's rmse: 1.46244\tvalid_1's rmse: 1.54261\n",
      "[4600]\ttraining's rmse: 1.46095\tvalid_1's rmse: 1.54255\n",
      "[4700]\ttraining's rmse: 1.45943\tvalid_1's rmse: 1.54254\n",
      "[4800]\ttraining's rmse: 1.45791\tvalid_1's rmse: 1.54253\n",
      "[4900]\ttraining's rmse: 1.45641\tvalid_1's rmse: 1.54254\n",
      "Early stopping, best iteration is:\n",
      "[4816]\ttraining's rmse: 1.45768\tvalid_1's rmse: 1.54253\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62778\tvalid_1's rmse: 1.62402\n",
      "[200]\ttraining's rmse: 1.59317\tvalid_1's rmse: 1.59128\n",
      "[300]\ttraining's rmse: 1.57432\tvalid_1's rmse: 1.57442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 1.56235\tvalid_1's rmse: 1.56446\n",
      "[500]\ttraining's rmse: 1.55383\tvalid_1's rmse: 1.55786\n",
      "[600]\ttraining's rmse: 1.54713\tvalid_1's rmse: 1.55296\n",
      "[700]\ttraining's rmse: 1.54173\tvalid_1's rmse: 1.54953\n",
      "[800]\ttraining's rmse: 1.53719\tvalid_1's rmse: 1.54705\n",
      "[900]\ttraining's rmse: 1.53323\tvalid_1's rmse: 1.54513\n",
      "[1000]\ttraining's rmse: 1.52971\tvalid_1's rmse: 1.54358\n",
      "[1100]\ttraining's rmse: 1.52651\tvalid_1's rmse: 1.54236\n",
      "[1200]\ttraining's rmse: 1.52358\tvalid_1's rmse: 1.54143\n",
      "[1300]\ttraining's rmse: 1.52085\tvalid_1's rmse: 1.54068\n",
      "[1400]\ttraining's rmse: 1.5183\tvalid_1's rmse: 1.54009\n",
      "[1500]\ttraining's rmse: 1.51589\tvalid_1's rmse: 1.53961\n",
      "[1600]\ttraining's rmse: 1.51362\tvalid_1's rmse: 1.53919\n",
      "[1700]\ttraining's rmse: 1.51143\tvalid_1's rmse: 1.53883\n",
      "[1800]\ttraining's rmse: 1.50937\tvalid_1's rmse: 1.5386\n",
      "[1900]\ttraining's rmse: 1.50736\tvalid_1's rmse: 1.53841\n",
      "[2000]\ttraining's rmse: 1.50537\tvalid_1's rmse: 1.53815\n",
      "[2100]\ttraining's rmse: 1.50346\tvalid_1's rmse: 1.53801\n",
      "[2200]\ttraining's rmse: 1.50153\tvalid_1's rmse: 1.53787\n",
      "[2300]\ttraining's rmse: 1.49972\tvalid_1's rmse: 1.53772\n",
      "[2400]\ttraining's rmse: 1.49784\tvalid_1's rmse: 1.53755\n",
      "[2500]\ttraining's rmse: 1.49603\tvalid_1's rmse: 1.53742\n",
      "[2600]\ttraining's rmse: 1.49427\tvalid_1's rmse: 1.53731\n",
      "[2700]\ttraining's rmse: 1.4926\tvalid_1's rmse: 1.53716\n",
      "[2800]\ttraining's rmse: 1.49087\tvalid_1's rmse: 1.53703\n",
      "[2900]\ttraining's rmse: 1.48911\tvalid_1's rmse: 1.53695\n",
      "[3000]\ttraining's rmse: 1.48741\tvalid_1's rmse: 1.53687\n",
      "[3100]\ttraining's rmse: 1.48572\tvalid_1's rmse: 1.53678\n",
      "[3200]\ttraining's rmse: 1.48407\tvalid_1's rmse: 1.53666\n",
      "[3300]\ttraining's rmse: 1.48247\tvalid_1's rmse: 1.53657\n",
      "[3400]\ttraining's rmse: 1.4808\tvalid_1's rmse: 1.5365\n",
      "[3500]\ttraining's rmse: 1.47909\tvalid_1's rmse: 1.53643\n",
      "[3600]\ttraining's rmse: 1.47748\tvalid_1's rmse: 1.53638\n",
      "[3700]\ttraining's rmse: 1.47591\tvalid_1's rmse: 1.5363\n",
      "[3800]\ttraining's rmse: 1.4743\tvalid_1's rmse: 1.53625\n",
      "[3900]\ttraining's rmse: 1.4727\tvalid_1's rmse: 1.53623\n",
      "[4000]\ttraining's rmse: 1.47108\tvalid_1's rmse: 1.53619\n",
      "[4100]\ttraining's rmse: 1.46952\tvalid_1's rmse: 1.53619\n",
      "[4200]\ttraining's rmse: 1.46795\tvalid_1's rmse: 1.53614\n",
      "[4300]\ttraining's rmse: 1.4664\tvalid_1's rmse: 1.53613\n",
      "Early stopping, best iteration is:\n",
      "[4255]\ttraining's rmse: 1.4671\tvalid_1's rmse: 1.5361\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62834\tvalid_1's rmse: 1.62297\n",
      "[200]\ttraining's rmse: 1.59379\tvalid_1's rmse: 1.59013\n",
      "[300]\ttraining's rmse: 1.575\tvalid_1's rmse: 1.57312\n",
      "[400]\ttraining's rmse: 1.56305\tvalid_1's rmse: 1.56296\n",
      "[500]\ttraining's rmse: 1.55449\tvalid_1's rmse: 1.55619\n",
      "[600]\ttraining's rmse: 1.54776\tvalid_1's rmse: 1.55145\n",
      "[700]\ttraining's rmse: 1.54231\tvalid_1's rmse: 1.54792\n",
      "[800]\ttraining's rmse: 1.53775\tvalid_1's rmse: 1.54526\n",
      "[900]\ttraining's rmse: 1.5337\tvalid_1's rmse: 1.54322\n",
      "[1000]\ttraining's rmse: 1.53013\tvalid_1's rmse: 1.54167\n",
      "[1100]\ttraining's rmse: 1.52694\tvalid_1's rmse: 1.54043\n",
      "[1200]\ttraining's rmse: 1.52399\tvalid_1's rmse: 1.5395\n",
      "[1300]\ttraining's rmse: 1.52129\tvalid_1's rmse: 1.53879\n",
      "[1400]\ttraining's rmse: 1.51872\tvalid_1's rmse: 1.5382\n",
      "[1500]\ttraining's rmse: 1.51633\tvalid_1's rmse: 1.53775\n",
      "[1600]\ttraining's rmse: 1.51404\tvalid_1's rmse: 1.53736\n",
      "[1700]\ttraining's rmse: 1.51189\tvalid_1's rmse: 1.53707\n",
      "[1800]\ttraining's rmse: 1.5098\tvalid_1's rmse: 1.53686\n",
      "[1900]\ttraining's rmse: 1.50774\tvalid_1's rmse: 1.5366\n",
      "[2000]\ttraining's rmse: 1.50577\tvalid_1's rmse: 1.53644\n",
      "[2100]\ttraining's rmse: 1.5039\tvalid_1's rmse: 1.5363\n",
      "[2200]\ttraining's rmse: 1.50197\tvalid_1's rmse: 1.53616\n",
      "[2300]\ttraining's rmse: 1.50016\tvalid_1's rmse: 1.53604\n",
      "[2400]\ttraining's rmse: 1.49836\tvalid_1's rmse: 1.53596\n",
      "[2500]\ttraining's rmse: 1.49651\tvalid_1's rmse: 1.53585\n",
      "[2600]\ttraining's rmse: 1.49476\tvalid_1's rmse: 1.53578\n",
      "[2700]\ttraining's rmse: 1.49298\tvalid_1's rmse: 1.53566\n",
      "[2800]\ttraining's rmse: 1.49116\tvalid_1's rmse: 1.5356\n",
      "[2900]\ttraining's rmse: 1.48949\tvalid_1's rmse: 1.53549\n",
      "[3000]\ttraining's rmse: 1.48779\tvalid_1's rmse: 1.53546\n",
      "[3100]\ttraining's rmse: 1.48609\tvalid_1's rmse: 1.53538\n",
      "[3200]\ttraining's rmse: 1.48448\tvalid_1's rmse: 1.53533\n",
      "Early stopping, best iteration is:\n",
      "[3192]\ttraining's rmse: 1.4846\tvalid_1's rmse: 1.53532\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62473\tvalid_1's rmse: 1.63728\n",
      "[200]\ttraining's rmse: 1.59039\tvalid_1's rmse: 1.60403\n",
      "[300]\ttraining's rmse: 1.57168\tvalid_1's rmse: 1.5866\n",
      "[400]\ttraining's rmse: 1.55982\tvalid_1's rmse: 1.57613\n",
      "[500]\ttraining's rmse: 1.55146\tvalid_1's rmse: 1.56923\n",
      "[600]\ttraining's rmse: 1.54486\tvalid_1's rmse: 1.56419\n",
      "[700]\ttraining's rmse: 1.5395\tvalid_1's rmse: 1.56043\n",
      "[800]\ttraining's rmse: 1.53493\tvalid_1's rmse: 1.55753\n",
      "[900]\ttraining's rmse: 1.5309\tvalid_1's rmse: 1.55528\n",
      "[1000]\ttraining's rmse: 1.52739\tvalid_1's rmse: 1.55358\n",
      "[1100]\ttraining's rmse: 1.5242\tvalid_1's rmse: 1.55223\n",
      "[1200]\ttraining's rmse: 1.52135\tvalid_1's rmse: 1.55115\n",
      "[1300]\ttraining's rmse: 1.51862\tvalid_1's rmse: 1.55033\n",
      "[1400]\ttraining's rmse: 1.51606\tvalid_1's rmse: 1.5497\n",
      "[1500]\ttraining's rmse: 1.51365\tvalid_1's rmse: 1.54915\n",
      "[1600]\ttraining's rmse: 1.51137\tvalid_1's rmse: 1.54874\n",
      "[1700]\ttraining's rmse: 1.50918\tvalid_1's rmse: 1.54842\n",
      "[1800]\ttraining's rmse: 1.50707\tvalid_1's rmse: 1.54812\n",
      "[1900]\ttraining's rmse: 1.50505\tvalid_1's rmse: 1.5479\n",
      "[2000]\ttraining's rmse: 1.50305\tvalid_1's rmse: 1.54774\n",
      "[2100]\ttraining's rmse: 1.50112\tvalid_1's rmse: 1.54755\n",
      "[2200]\ttraining's rmse: 1.49922\tvalid_1's rmse: 1.54744\n",
      "[2300]\ttraining's rmse: 1.4974\tvalid_1's rmse: 1.5473\n",
      "[2400]\ttraining's rmse: 1.49557\tvalid_1's rmse: 1.54715\n",
      "[2500]\ttraining's rmse: 1.49376\tvalid_1's rmse: 1.54702\n",
      "[2600]\ttraining's rmse: 1.49199\tvalid_1's rmse: 1.54696\n",
      "[2700]\ttraining's rmse: 1.49025\tvalid_1's rmse: 1.54686\n",
      "[2800]\ttraining's rmse: 1.48855\tvalid_1's rmse: 1.54677\n",
      "[2900]\ttraining's rmse: 1.48684\tvalid_1's rmse: 1.54669\n",
      "[3000]\ttraining's rmse: 1.48515\tvalid_1's rmse: 1.54665\n",
      "[3100]\ttraining's rmse: 1.48352\tvalid_1's rmse: 1.54658\n",
      "[3200]\ttraining's rmse: 1.48183\tvalid_1's rmse: 1.54647\n",
      "[3300]\ttraining's rmse: 1.48016\tvalid_1's rmse: 1.54646\n",
      "[3400]\ttraining's rmse: 1.47851\tvalid_1's rmse: 1.54639\n",
      "[3500]\ttraining's rmse: 1.47688\tvalid_1's rmse: 1.54638\n",
      "[3600]\ttraining's rmse: 1.47528\tvalid_1's rmse: 1.54633\n",
      "[3700]\ttraining's rmse: 1.47374\tvalid_1's rmse: 1.54631\n",
      "[3800]\ttraining's rmse: 1.47216\tvalid_1's rmse: 1.54627\n",
      "[3900]\ttraining's rmse: 1.47061\tvalid_1's rmse: 1.54621\n",
      "[4000]\ttraining's rmse: 1.46907\tvalid_1's rmse: 1.54614\n",
      "[4100]\ttraining's rmse: 1.46751\tvalid_1's rmse: 1.54608\n",
      "[4200]\ttraining's rmse: 1.46598\tvalid_1's rmse: 1.54607\n",
      "Early stopping, best iteration is:\n",
      "[4135]\ttraining's rmse: 1.46697\tvalid_1's rmse: 1.54605\n",
      "fold n°6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62783\tvalid_1's rmse: 1.62212\n",
      "[200]\ttraining's rmse: 1.59288\tvalid_1's rmse: 1.59057\n",
      "[300]\ttraining's rmse: 1.57398\tvalid_1's rmse: 1.57486\n",
      "[400]\ttraining's rmse: 1.56191\tvalid_1's rmse: 1.56562\n",
      "[500]\ttraining's rmse: 1.55328\tvalid_1's rmse: 1.55952\n",
      "[600]\ttraining's rmse: 1.54656\tvalid_1's rmse: 1.55519\n",
      "[700]\ttraining's rmse: 1.54112\tvalid_1's rmse: 1.55199\n",
      "[800]\ttraining's rmse: 1.53656\tvalid_1's rmse: 1.54953\n",
      "[900]\ttraining's rmse: 1.53259\tvalid_1's rmse: 1.54773\n",
      "[1000]\ttraining's rmse: 1.52901\tvalid_1's rmse: 1.54626\n",
      "[1100]\ttraining's rmse: 1.52581\tvalid_1's rmse: 1.54517\n",
      "[1200]\ttraining's rmse: 1.52288\tvalid_1's rmse: 1.54433\n",
      "[1300]\ttraining's rmse: 1.52014\tvalid_1's rmse: 1.54358\n",
      "[1400]\ttraining's rmse: 1.51761\tvalid_1's rmse: 1.54303\n",
      "[1500]\ttraining's rmse: 1.5152\tvalid_1's rmse: 1.5426\n",
      "[1600]\ttraining's rmse: 1.51293\tvalid_1's rmse: 1.54225\n",
      "[1700]\ttraining's rmse: 1.51073\tvalid_1's rmse: 1.54193\n",
      "[1800]\ttraining's rmse: 1.50871\tvalid_1's rmse: 1.54162\n",
      "[1900]\ttraining's rmse: 1.5067\tvalid_1's rmse: 1.54133\n",
      "[2000]\ttraining's rmse: 1.50473\tvalid_1's rmse: 1.54115\n",
      "[2100]\ttraining's rmse: 1.50284\tvalid_1's rmse: 1.54099\n",
      "[2200]\ttraining's rmse: 1.50095\tvalid_1's rmse: 1.54085\n",
      "[2300]\ttraining's rmse: 1.49907\tvalid_1's rmse: 1.54075\n",
      "[2400]\ttraining's rmse: 1.49722\tvalid_1's rmse: 1.54058\n",
      "[2500]\ttraining's rmse: 1.49541\tvalid_1's rmse: 1.54051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2600]\ttraining's rmse: 1.49359\tvalid_1's rmse: 1.54037\n",
      "[2700]\ttraining's rmse: 1.49172\tvalid_1's rmse: 1.54028\n",
      "[2800]\ttraining's rmse: 1.48998\tvalid_1's rmse: 1.54018\n",
      "[2900]\ttraining's rmse: 1.48825\tvalid_1's rmse: 1.54008\n",
      "[3000]\ttraining's rmse: 1.48658\tvalid_1's rmse: 1.53999\n",
      "[3100]\ttraining's rmse: 1.48491\tvalid_1's rmse: 1.53993\n",
      "[3200]\ttraining's rmse: 1.48325\tvalid_1's rmse: 1.53986\n",
      "[3300]\ttraining's rmse: 1.48162\tvalid_1's rmse: 1.53978\n",
      "[3400]\ttraining's rmse: 1.48\tvalid_1's rmse: 1.53975\n",
      "[3500]\ttraining's rmse: 1.47836\tvalid_1's rmse: 1.5397\n",
      "[3600]\ttraining's rmse: 1.4767\tvalid_1's rmse: 1.53967\n",
      "[3700]\ttraining's rmse: 1.47507\tvalid_1's rmse: 1.53963\n",
      "[3800]\ttraining's rmse: 1.47346\tvalid_1's rmse: 1.53962\n",
      "[3900]\ttraining's rmse: 1.47187\tvalid_1's rmse: 1.53959\n",
      "[4000]\ttraining's rmse: 1.4703\tvalid_1's rmse: 1.53954\n",
      "[4100]\ttraining's rmse: 1.46875\tvalid_1's rmse: 1.53948\n",
      "[4200]\ttraining's rmse: 1.46718\tvalid_1's rmse: 1.53942\n",
      "[4300]\ttraining's rmse: 1.46572\tvalid_1's rmse: 1.53937\n",
      "[4400]\ttraining's rmse: 1.46422\tvalid_1's rmse: 1.53933\n",
      "[4500]\ttraining's rmse: 1.46264\tvalid_1's rmse: 1.53931\n",
      "[4600]\ttraining's rmse: 1.46115\tvalid_1's rmse: 1.53933\n",
      "Early stopping, best iteration is:\n",
      "[4532]\ttraining's rmse: 1.46216\tvalid_1's rmse: 1.53931\n",
      "fold n°7\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62699\tvalid_1's rmse: 1.62914\n",
      "[200]\ttraining's rmse: 1.59259\tvalid_1's rmse: 1.59532\n",
      "[300]\ttraining's rmse: 1.57392\tvalid_1's rmse: 1.57788\n",
      "[400]\ttraining's rmse: 1.56189\tvalid_1's rmse: 1.56736\n",
      "[500]\ttraining's rmse: 1.55343\tvalid_1's rmse: 1.56054\n",
      "[600]\ttraining's rmse: 1.54667\tvalid_1's rmse: 1.55565\n",
      "[700]\ttraining's rmse: 1.54121\tvalid_1's rmse: 1.55207\n",
      "[800]\ttraining's rmse: 1.53663\tvalid_1's rmse: 1.54947\n",
      "[900]\ttraining's rmse: 1.53265\tvalid_1's rmse: 1.54746\n",
      "[1000]\ttraining's rmse: 1.52905\tvalid_1's rmse: 1.54589\n",
      "[1100]\ttraining's rmse: 1.52586\tvalid_1's rmse: 1.54473\n",
      "[1200]\ttraining's rmse: 1.52294\tvalid_1's rmse: 1.54381\n",
      "[1300]\ttraining's rmse: 1.52026\tvalid_1's rmse: 1.54312\n",
      "[1400]\ttraining's rmse: 1.51773\tvalid_1's rmse: 1.5426\n",
      "[1500]\ttraining's rmse: 1.51526\tvalid_1's rmse: 1.5422\n",
      "[1600]\ttraining's rmse: 1.51294\tvalid_1's rmse: 1.54185\n",
      "[1700]\ttraining's rmse: 1.51071\tvalid_1's rmse: 1.54156\n",
      "[1800]\ttraining's rmse: 1.50859\tvalid_1's rmse: 1.54133\n",
      "[1900]\ttraining's rmse: 1.50659\tvalid_1's rmse: 1.5412\n",
      "[2000]\ttraining's rmse: 1.50459\tvalid_1's rmse: 1.54103\n",
      "[2100]\ttraining's rmse: 1.50265\tvalid_1's rmse: 1.54088\n",
      "[2200]\ttraining's rmse: 1.50069\tvalid_1's rmse: 1.54079\n",
      "[2300]\ttraining's rmse: 1.49883\tvalid_1's rmse: 1.54064\n",
      "[2400]\ttraining's rmse: 1.497\tvalid_1's rmse: 1.54057\n",
      "[2500]\ttraining's rmse: 1.49515\tvalid_1's rmse: 1.54049\n",
      "[2600]\ttraining's rmse: 1.49338\tvalid_1's rmse: 1.54043\n",
      "[2700]\ttraining's rmse: 1.49162\tvalid_1's rmse: 1.54039\n",
      "[2800]\ttraining's rmse: 1.48992\tvalid_1's rmse: 1.54031\n",
      "[2900]\ttraining's rmse: 1.48818\tvalid_1's rmse: 1.54025\n",
      "[3000]\ttraining's rmse: 1.48647\tvalid_1's rmse: 1.54018\n",
      "[3100]\ttraining's rmse: 1.48479\tvalid_1's rmse: 1.5401\n",
      "[3200]\ttraining's rmse: 1.48311\tvalid_1's rmse: 1.54008\n",
      "[3300]\ttraining's rmse: 1.4815\tvalid_1's rmse: 1.54004\n",
      "[3400]\ttraining's rmse: 1.47989\tvalid_1's rmse: 1.53998\n",
      "[3500]\ttraining's rmse: 1.47827\tvalid_1's rmse: 1.53993\n",
      "[3600]\ttraining's rmse: 1.47668\tvalid_1's rmse: 1.53989\n",
      "[3700]\ttraining's rmse: 1.47502\tvalid_1's rmse: 1.53987\n",
      "[3800]\ttraining's rmse: 1.47348\tvalid_1's rmse: 1.53983\n",
      "[3900]\ttraining's rmse: 1.47183\tvalid_1's rmse: 1.53977\n",
      "[4000]\ttraining's rmse: 1.47023\tvalid_1's rmse: 1.53969\n",
      "[4100]\ttraining's rmse: 1.46869\tvalid_1's rmse: 1.5397\n",
      "[4200]\ttraining's rmse: 1.46707\tvalid_1's rmse: 1.53967\n",
      "[4300]\ttraining's rmse: 1.46558\tvalid_1's rmse: 1.53962\n",
      "[4400]\ttraining's rmse: 1.46408\tvalid_1's rmse: 1.53955\n",
      "[4500]\ttraining's rmse: 1.46254\tvalid_1's rmse: 1.53954\n",
      "[4600]\ttraining's rmse: 1.46101\tvalid_1's rmse: 1.53951\n",
      "Early stopping, best iteration is:\n",
      "[4581]\ttraining's rmse: 1.4613\tvalid_1's rmse: 1.5395\n",
      "fold n°8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62649\tvalid_1's rmse: 1.62916\n",
      "[200]\ttraining's rmse: 1.59178\tvalid_1's rmse: 1.59651\n",
      "[300]\ttraining's rmse: 1.57304\tvalid_1's rmse: 1.57971\n",
      "[400]\ttraining's rmse: 1.56114\tvalid_1's rmse: 1.56974\n",
      "[500]\ttraining's rmse: 1.55259\tvalid_1's rmse: 1.56308\n",
      "[600]\ttraining's rmse: 1.5459\tvalid_1's rmse: 1.55826\n",
      "[700]\ttraining's rmse: 1.54053\tvalid_1's rmse: 1.55473\n",
      "[800]\ttraining's rmse: 1.53596\tvalid_1's rmse: 1.55218\n",
      "[900]\ttraining's rmse: 1.53196\tvalid_1's rmse: 1.55018\n",
      "[1000]\ttraining's rmse: 1.52847\tvalid_1's rmse: 1.54868\n",
      "[1100]\ttraining's rmse: 1.52531\tvalid_1's rmse: 1.54748\n",
      "[1200]\ttraining's rmse: 1.52245\tvalid_1's rmse: 1.54656\n",
      "[1300]\ttraining's rmse: 1.51979\tvalid_1's rmse: 1.5458\n",
      "[1400]\ttraining's rmse: 1.51726\tvalid_1's rmse: 1.54518\n",
      "[1500]\ttraining's rmse: 1.51487\tvalid_1's rmse: 1.54467\n",
      "[1600]\ttraining's rmse: 1.51257\tvalid_1's rmse: 1.54423\n",
      "[1700]\ttraining's rmse: 1.5104\tvalid_1's rmse: 1.54385\n",
      "[1800]\ttraining's rmse: 1.50837\tvalid_1's rmse: 1.54364\n",
      "[1900]\ttraining's rmse: 1.50637\tvalid_1's rmse: 1.54339\n",
      "[2000]\ttraining's rmse: 1.50446\tvalid_1's rmse: 1.54321\n",
      "[2100]\ttraining's rmse: 1.50256\tvalid_1's rmse: 1.54303\n",
      "[2200]\ttraining's rmse: 1.50066\tvalid_1's rmse: 1.54281\n",
      "[2300]\ttraining's rmse: 1.49879\tvalid_1's rmse: 1.54261\n",
      "[2400]\ttraining's rmse: 1.49695\tvalid_1's rmse: 1.54247\n",
      "[2500]\ttraining's rmse: 1.49518\tvalid_1's rmse: 1.54233\n",
      "[2600]\ttraining's rmse: 1.49345\tvalid_1's rmse: 1.54221\n",
      "[2700]\ttraining's rmse: 1.4917\tvalid_1's rmse: 1.5421\n",
      "[2800]\ttraining's rmse: 1.48999\tvalid_1's rmse: 1.54199\n",
      "[2900]\ttraining's rmse: 1.48828\tvalid_1's rmse: 1.54193\n",
      "[3000]\ttraining's rmse: 1.48658\tvalid_1's rmse: 1.54182\n",
      "[3100]\ttraining's rmse: 1.48486\tvalid_1's rmse: 1.54173\n",
      "[3200]\ttraining's rmse: 1.48321\tvalid_1's rmse: 1.54165\n",
      "[3300]\ttraining's rmse: 1.48158\tvalid_1's rmse: 1.5416\n",
      "[3400]\ttraining's rmse: 1.47994\tvalid_1's rmse: 1.54155\n",
      "[3500]\ttraining's rmse: 1.47838\tvalid_1's rmse: 1.5415\n",
      "[3600]\ttraining's rmse: 1.47676\tvalid_1's rmse: 1.54143\n",
      "[3700]\ttraining's rmse: 1.47514\tvalid_1's rmse: 1.54141\n",
      "[3800]\ttraining's rmse: 1.47356\tvalid_1's rmse: 1.54137\n",
      "[3900]\ttraining's rmse: 1.47202\tvalid_1's rmse: 1.54136\n",
      "Early stopping, best iteration is:\n",
      "[3838]\ttraining's rmse: 1.47296\tvalid_1's rmse: 1.54135\n",
      "fold n°9\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.6275\tvalid_1's rmse: 1.62579\n",
      "[200]\ttraining's rmse: 1.5928\tvalid_1's rmse: 1.59359\n",
      "[300]\ttraining's rmse: 1.57409\tvalid_1's rmse: 1.57688\n",
      "[400]\ttraining's rmse: 1.5622\tvalid_1's rmse: 1.56688\n",
      "[500]\ttraining's rmse: 1.55368\tvalid_1's rmse: 1.56014\n",
      "[600]\ttraining's rmse: 1.54688\tvalid_1's rmse: 1.55519\n",
      "[700]\ttraining's rmse: 1.54145\tvalid_1's rmse: 1.55157\n",
      "[800]\ttraining's rmse: 1.53685\tvalid_1's rmse: 1.54883\n",
      "[900]\ttraining's rmse: 1.53277\tvalid_1's rmse: 1.54676\n",
      "[1000]\ttraining's rmse: 1.52918\tvalid_1's rmse: 1.54515\n",
      "[1100]\ttraining's rmse: 1.52592\tvalid_1's rmse: 1.54389\n",
      "[1200]\ttraining's rmse: 1.52297\tvalid_1's rmse: 1.5429\n",
      "[1300]\ttraining's rmse: 1.52021\tvalid_1's rmse: 1.5421\n",
      "[1400]\ttraining's rmse: 1.51762\tvalid_1's rmse: 1.54145\n",
      "[1500]\ttraining's rmse: 1.51521\tvalid_1's rmse: 1.54094\n",
      "[1600]\ttraining's rmse: 1.51296\tvalid_1's rmse: 1.54053\n",
      "[1700]\ttraining's rmse: 1.51079\tvalid_1's rmse: 1.54021\n",
      "[1800]\ttraining's rmse: 1.50869\tvalid_1's rmse: 1.53992\n",
      "[1900]\ttraining's rmse: 1.50666\tvalid_1's rmse: 1.5397\n",
      "[2000]\ttraining's rmse: 1.50474\tvalid_1's rmse: 1.53945\n",
      "[2100]\ttraining's rmse: 1.50282\tvalid_1's rmse: 1.5393\n",
      "[2200]\ttraining's rmse: 1.50091\tvalid_1's rmse: 1.5392\n",
      "[2300]\ttraining's rmse: 1.49902\tvalid_1's rmse: 1.53905\n",
      "[2400]\ttraining's rmse: 1.49716\tvalid_1's rmse: 1.53887\n",
      "[2500]\ttraining's rmse: 1.49533\tvalid_1's rmse: 1.53872\n",
      "[2600]\ttraining's rmse: 1.49347\tvalid_1's rmse: 1.53859\n",
      "[2700]\ttraining's rmse: 1.49167\tvalid_1's rmse: 1.53847\n",
      "[2800]\ttraining's rmse: 1.48995\tvalid_1's rmse: 1.53837\n",
      "[2900]\ttraining's rmse: 1.48821\tvalid_1's rmse: 1.53825\n",
      "[3000]\ttraining's rmse: 1.48647\tvalid_1's rmse: 1.53816\n",
      "[3100]\ttraining's rmse: 1.48475\tvalid_1's rmse: 1.53808\n",
      "[3200]\ttraining's rmse: 1.48299\tvalid_1's rmse: 1.53799\n",
      "[3300]\ttraining's rmse: 1.48133\tvalid_1's rmse: 1.53792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3400]\ttraining's rmse: 1.47967\tvalid_1's rmse: 1.53786\n",
      "[3500]\ttraining's rmse: 1.47795\tvalid_1's rmse: 1.53778\n",
      "[3600]\ttraining's rmse: 1.47633\tvalid_1's rmse: 1.53773\n",
      "[3700]\ttraining's rmse: 1.47471\tvalid_1's rmse: 1.53769\n",
      "[3800]\ttraining's rmse: 1.47312\tvalid_1's rmse: 1.53763\n",
      "[3900]\ttraining's rmse: 1.47153\tvalid_1's rmse: 1.53759\n",
      "[4000]\ttraining's rmse: 1.4699\tvalid_1's rmse: 1.53752\n",
      "[4100]\ttraining's rmse: 1.46832\tvalid_1's rmse: 1.53748\n",
      "Early stopping, best iteration is:\n",
      "[4091]\ttraining's rmse: 1.46847\tvalid_1's rmse: 1.53747\n",
      "CV score: 1.54074 \n"
     ]
    }
   ],
   "source": [
    "lgbparam = {'num_leaves': 31,\n",
    "            'boosting_type': 'rf',\n",
    "             'min_data_in_leaf': 30, \n",
    "             'objective':'regression',\n",
    "             'max_depth': -1,\n",
    "             'learning_rate': 0.005,\n",
    "             \"min_child_samples\": 20,\n",
    "             \"boosting\": \"gbdt\",\n",
    "             \"feature_fraction\": 0.9,\n",
    "             \"bagging_freq\": 1,\n",
    "             \"bagging_fraction\": 0.9 ,\n",
    "             \"bagging_seed\": 11,\n",
    "             \"metric\": 'rmse',\n",
    "             \"lambda_l1\": 0.1,\n",
    "             \"verbosity\": -1,\n",
    "             \"nthread\": 4,\n",
    "             \"random_state\": 4590}\n",
    "\n",
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "\n",
    "df_train = train[train['outliers'] == 0]\n",
    "df_target = target[normal_idx]\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]\n",
    "    \n",
    "normal_predictions_n_repeats_2, oof_n_repeats_2 = lgbm_regression_train_n_repeats_2(df_train, \n",
    "                                                                                    df_target, \n",
    "                                                                                    test, \n",
    "                                                                                    lgbparam, \n",
    "                                                                                    features, \n",
    "                                                                                    categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers_n_repeats_2 = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "model_without_outliers_n_repeats_2[\"target\"] = normal_predictions_n_repeats_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Training Model For Outliers Classification for 5 fold (n_repeats = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_classification_train_n_repeats_2(df_train, target, df_test, param, features, categorical_feats):\n",
    "    folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=15)\n",
    "    oof = np.zeros(len(df_train))\n",
    "    predictions = np.zeros(len(df_test))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    start = time.time()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / (5 * 2)\n",
    "        \n",
    "    print(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))\n",
    "\n",
    "    return predictions, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0462539\tvalid_1's binary_logloss: 0.0483859\n",
      "[200]\ttraining's binary_logloss: 0.0462506\tvalid_1's binary_logloss: 0.0483834\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0462377\tvalid_1's binary_logloss: 0.0482944\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0466662\tvalid_1's binary_logloss: 0.0470919\n",
      "[200]\ttraining's binary_logloss: 0.0466763\tvalid_1's binary_logloss: 0.047128\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0466228\tvalid_1's binary_logloss: 0.0470608\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0465256\tvalid_1's binary_logloss: 0.0466832\n",
      "[200]\ttraining's binary_logloss: 0.0464995\tvalid_1's binary_logloss: 0.0466729\n",
      "[300]\ttraining's binary_logloss: 0.0465142\tvalid_1's binary_logloss: 0.0466902\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's binary_logloss: 0.0464978\tvalid_1's binary_logloss: 0.046675\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0455144\tvalid_1's binary_logloss: 0.051521\n",
      "[200]\ttraining's binary_logloss: 0.0455096\tvalid_1's binary_logloss: 0.0515042\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.0455032\tvalid_1's binary_logloss: 0.0514879\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0464147\tvalid_1's binary_logloss: 0.0470045\n",
      "[200]\ttraining's binary_logloss: 0.0464242\tvalid_1's binary_logloss: 0.0470161\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0463755\tvalid_1's binary_logloss: 0.046915\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0459711\tvalid_1's binary_logloss: 0.0491655\n",
      "[200]\ttraining's binary_logloss: 0.0459618\tvalid_1's binary_logloss: 0.0491732\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.0459655\tvalid_1's binary_logloss: 0.0491395\n",
      "fold n°6\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0462161\tvalid_1's binary_logloss: 0.0486354\n",
      "[200]\ttraining's binary_logloss: 0.0462161\tvalid_1's binary_logloss: 0.0486538\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0461823\tvalid_1's binary_logloss: 0.0485603\n",
      "fold n°7\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0461915\tvalid_1's binary_logloss: 0.0488517\n",
      "[200]\ttraining's binary_logloss: 0.0462054\tvalid_1's binary_logloss: 0.0488537\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.0461518\tvalid_1's binary_logloss: 0.0488015\n",
      "fold n°8\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.046931\tvalid_1's binary_logloss: 0.0457764\n",
      "[200]\ttraining's binary_logloss: 0.0469323\tvalid_1's binary_logloss: 0.0457827\n",
      "[300]\ttraining's binary_logloss: 0.0469419\tvalid_1's binary_logloss: 0.0457809\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's binary_logloss: 0.0469159\tvalid_1's binary_logloss: 0.045753\n",
      "fold n°9\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0462128\tvalid_1's binary_logloss: 0.0483689\n",
      "[200]\ttraining's binary_logloss: 0.0461738\tvalid_1's binary_logloss: 0.0483438\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0461594\tvalid_1's binary_logloss: 0.048297\n",
      "CV score: 0.04811 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333}\n",
    "\n",
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "\n",
    "target = train['outliers']\n",
    "del train['outliers']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]\n",
    "outlier_label_n_repeats_2, oof_class_n_repeats_2 = lgbm_classification_train_n_repeats_2(train, \n",
    "                                                                                         target, \n",
    "                                                                                         test, \n",
    "                                                                                         param, \n",
    "                                                                                         features, \n",
    "                                                                                         categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>0.024092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>0.011282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab  0.024092\n",
       "1  C_ID_130fd0cbdd  0.001818\n",
       "2  C_ID_b709037bc5  0.011282\n",
       "3  C_ID_d27d835a9f  0.001818\n",
       "4  C_ID_2b5e3df5c2  0.001818"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlier_prob_n_repeats_2 = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "df_outlier_prob_n_repeats_2[\"target\"] = outlier_label_n_repeats_2\n",
    "df_outlier_prob_n_repeats_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Combining Submission for 5 fold (n_repeats = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_id_n_repeats_2 = pd.DataFrame(\\\n",
    "                                      df_outlier_prob_n_repeats_2.sort_values(by='target',\n",
    "                                                                              ascending = False)\n",
    "                                      .head(25000)['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv('../result/Blend2_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.346967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.354020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.148607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.090599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.346967\n",
       "1  C_ID_130fd0cbdd -0.354020\n",
       "2  C_ID_b709037bc5 -0.932773\n",
       "3  C_ID_d27d835a9f -0.148607\n",
       "4  C_ID_2b5e3df5c2 -1.090599"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_submission.shape[0])\n",
    "best_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.346967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_6d8dba8475</td>\n",
       "      <td>-0.881375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_4859ac9ed5</td>\n",
       "      <td>-0.641561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_7f1041e8e1</td>\n",
       "      <td>-5.193301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_22e4a47c72</td>\n",
       "      <td>0.341024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.346967\n",
       "1  C_ID_6d8dba8475 -0.881375\n",
       "2  C_ID_4859ac9ed5 -0.641561\n",
       "3  C_ID_7f1041e8e1 -5.193301\n",
       "4  C_ID_22e4a47c72  0.341024"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outlier_id.shape[0])\n",
    "most_likely_liers_n_repeats_2 = best_submission.merge(outlier_id_n_repeats_2,how='right')\n",
    "most_likely_liers_n_repeats_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 16s, sys: 44 ms, total: 4min 16s\n",
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for card_id in most_likely_liers_n_repeats_2['card_id']:\n",
    "    model_without_outliers_n_repeats_2.loc[model_without_outliers_n_repeats_2['card_id']==card_id,'target']\\\n",
    "    = most_likely_liers_n_repeats_2.loc[most_likely_liers_n_repeats_2['card_id']==card_id,'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers_n_repeats_2.to_csv(\"../result/Blend2_v6_n_repeats_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123623"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_without_outliers['target'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123623"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_without_outliers_n_repeats_2['target'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199644,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199644,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_n_repeats_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((201917,), 199644, 2273)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape, len(normal_idx), len(outlier_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2dfa7a5fcabd78829678fa4283e99862f1c4a0d7"
   },
   "source": [
    "## Part 7: Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(target))\n",
    "print(type(oof))\n",
    "print(type(oof_normal_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2273, 2273)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outlier_idx), len(outlier_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_normal_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "    \n",
    "oof_normal_final = pd.Series(np.zeros(len(target)))\n",
    "oof_normal_final[normal_idx] = oof\n",
    "oof_normal_final[outlier_idx] = outlier_idx\n",
    "\n",
    "oof_n_repeats_2_final = pd.Series(np.zeros(len(target)))\n",
    "oof_n_repeats_2_final[normal_idx] = oof_n_repeats_2\n",
    "oof_n_repeats_2_final[outlier_idx] = outlier_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "_uuid": "8c9afce8b59b5f51024150a997a9d2eb702ab85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "----------Stacking 0----------\n",
      "fold n°1\n",
      "----------Stacking 1----------\n",
      "fold n°2\n",
      "----------Stacking 2----------\n",
      "fold n°3\n",
      "----------Stacking 3----------\n",
      "fold n°4\n",
      "----------Stacking 4----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4648553532909525"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack = np.vstack([oof_normal_final,oof_n_repeats_2_final]).transpose()\n",
    "test_stack = np.vstack([model_without_outliers['target'].values.tolist(),\n",
    "                        model_without_outliers_n_repeats_2['target'].values.tolist()]).transpose()\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5,n_repeats=1,random_state=4520)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions_stack = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_stack, target)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "\n",
    "    print(\"-\" * 10 + \"Stacking \" + str(fold_) + \"-\" * 10)\n",
    "#     cb_model = CatBoostRegressor(iterations=3000, learning_rate=0.1, depth=8, l2_leaf_reg=20, bootstrap_type='Bernoulli',  eval_metric='RMSE', metric_period=50, od_type='Iter', od_wait=45, random_seed=17, allow_writing_files=False)\n",
    "#     cb_model.fit(trn_data, trn_y, eval_set=(val_data, val_y), cat_features=[], use_best_model=True, verbose=True)\n",
    "    clf = BayesianRidge()\n",
    "    clf.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf.predict(val_data)\n",
    "    predictions_stack += clf.predict(test_stack) / 5\n",
    "\n",
    "\n",
    "np.sqrt(mean_squared_error(target.values, oof_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "_uuid": "e871862de58a3ce43c148f78f152c1d6385a0a08"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample_submission['target'] = predictions_stack\n",
    "sample_submission.to_csv('../result/Bayesian_Ridge_Stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "_uuid": "b65e47686b49b31f0dc47171ab2aece4a4d0a941"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample1 = pd.read_csv(\"../result/3.695.csv\")\n",
    "sample2 = pd.read_csv(\"../result/combining_submission (1).csv\")\n",
    "sample_submission['target'] = model_without_outliers['target'] * 0.5 + model_without_outliers_n_repeats_2['target'] * 0.5\n",
    "sample_submission.to_csv(\"../result/Blend1.csv\", index = False)\n",
    "sample_submission['target'] = sample_submission['target'] * 0.2 + sample1['target'] * 0.2 + sample2['target'] * 0.6\n",
    "sample_submission.to_csv('../result/Blend2_v6.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Blend2_v6.csv` got the best submission score so far - 3.691."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "1259px",
    "right": "20px",
    "top": "14px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
