{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a9ef20fd4e6471fd2c9e3022edfdddc07a970aca"
   },
   "source": [
    "## P.S. The main idea behind this notebook is inspired from FabienDaniel Kernel Elo_world.\n",
    "https://www.kaggle.com/fabiendaniel/elo-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50e1f88df96b5e525237fe120650e679b7f60654"
   },
   "outputs": [],
   "source": [
    "# new_transactions = pd.read_csv('../input/elo-merchant-category-recommendation/new_merchant_transactions.csv', parse_dates=['purchase_date'])\n",
    "# historical_transactions = pd.read_csv('../input/elo-merchant-category-recommendation/historical_transactions.csv', parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_parquet('../input/hist_trans_df.parquet.gzip')\n",
    "new_transactions = pd.read_parquet('../input/new_trans_df.parquet.gzip')\n",
    "\n",
    "def binarize(df):\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y':1, 'N':0})\n",
    "    return df\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def add_new_merch_feat(df, merch_df):\n",
    "    df = pd.merge(left=df,\n",
    "                  right=merch_df[['merchant_id', 'merchant_group_id', 'category_4']],\n",
    "                  on=['merchant_id'],\n",
    "                  how='left')\n",
    "#     df['year'] = df['purchase_date'].dt.year.astype('int8')\n",
    "#     df['month'] = df['purchase_date'].dt.month.astype('int8')\n",
    "    df['dow'] = df['purchase_date'].dt.dayofweek.astype('int8')\n",
    "    df['hour'] = df['purchase_date'].dt.hour.astype('int8')\n",
    "    df['day_part'] = 'Morning'\n",
    "    df.loc[(df['hour'] > 12) & (df['hour'] <= 18), 'day_part'] = 'Afternoon'\n",
    "    df.loc[(df['hour'] > 18) & (df['hour'] <= 24), 'day_part'] = 'Evening'\n",
    "    # df['installments_flag'] = np.where(df['installments'] > 1, 'Y', 'N')\n",
    "    \n",
    "    # convert into proper data types\n",
    "#     df['hour'] = df['hour'].astype('category')\n",
    "#     df['day_part'] = df['day_part'].astype('category')\n",
    "    # df['installments_flag'] = hist_trans_df['installments_flag'].astype('category')\n",
    "    # df['dummy'] = 1\n",
    "    # df.head(5)\n",
    "    \n",
    "    return df\n",
    "\n",
    "merch_df = pd.read_parquet('../input/merch_df.parquet.gzip')\n",
    "\n",
    "historical_transactions = add_new_merch_feat(historical_transactions, merch_df)\n",
    "new_transactions = add_new_merch_feat(new_transactions, merch_df)\n",
    "\n",
    "del merch_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a940a9ce940fa489a5a5255f6d4523c9b7c3ffdc"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# def read_data(input_file):\n",
    "#     df = pd.read_csv(input_file)\n",
    "#     df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "#     df['elapsed_time'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days\n",
    "#     return df\n",
    "\n",
    "# train = read_data('../input/elo-merchant-category-recommendation/train.csv')\n",
    "# test = read_data('../input/elo-merchant-category-recommendation/test.csv')\n",
    "\n",
    "def read_data_v2(input_file):\n",
    "    df = pd.read_parquet(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days\n",
    "    return df\n",
    "\n",
    "train = read_data_v2('../input/train_df.parquet.gzip')\n",
    "test = read_data_v2('../input/test_df.parquet.gzip')\n",
    "\n",
    "target = train['target']\n",
    "del train['target']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd9f71f39664eef55e0b3ec3e6172e84a8e1a963"
   },
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_opt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_1\"] += 1\n",
    "historical_transactions[\"category_1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_1\"] += 1\n",
    "new_transactions[\"category_1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_2\"] = historical_transactions[\"category_2\"].fillna(0)\n",
    "historical_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_2\"] = new_transactions[\"category_2\"].fillna(0)\n",
    "new_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_3\"] = historical_transactions[\"category_3\"].replace({'A': 1, 'B': 2, 'C': 3, None: 0})\n",
    "historical_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_3\"] = new_transactions[\"category_3\"].replace({'A': 1, 'B': 2, 'C': 3, None: 0})\n",
    "new_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions[\"category_1_2_cross\"] = historical_transactions[\"category_1\"]*2 + historical_transactions[\"category_2\"]\n",
    "# np.sort(historical_transactions[\"category_1_2_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(new_transactions[\"category_1\"], new_transactions[\"category_2\"])\n",
    "#     plt.xlabel(\"category_1\")\n",
    "#     plt.ylabel(\"category_2\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_transactions[\"category_1_2_cross\"] = new_transactions[\"category_1\"]*2 + new_transactions[\"category_2\"]\n",
    "# np.sort(new_transactions[\"category_1_2_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(historical_transactions[\"category_1\"]+2, historical_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_1\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions[\"category_1_3_cross\"] = (historical_transactions[\"category_1\"]+2) * historical_transactions[\"category_3\"]\n",
    "# np.sort(historical_transactions[\"category_1_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(new_transactions[\"category_1\"], new_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_1\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_transactions[\"category_1_3_cross\"] = (new_transactions[\"category_1\"]+2) * new_transactions[\"category_3\"]\n",
    "# np.sort(new_transactions[\"category_1_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(historical_transactions[\"category_2\"]+6, historical_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_2\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions[\"category_2_3_cross\"] = (historical_transactions[\"category_2\"]+6) * historical_transactions[\"category_3\"]\n",
    "# np.sort(historical_transactions[\"category_2_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(new_transactions[\"category_2\"]+6, new_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_2\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_transactions[\"category_2_3_cross\"] = (new_transactions[\"category_2\"]+6) * new_transactions[\"category_3\"]\n",
    "# np.sort(new_transactions[\"category_2_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def category_make_cross_feat(df):\n",
    "    df[\"category_1_3_cross\"] = (df[\"category_1\"]+2) * df[\"category_3\"]\n",
    "    df[\"category_2_3_cross\"] = (df[\"category_2\"]+6) * df[\"category_3\"]\n",
    "    return df\n",
    "\n",
    "historical_transactions = category_make_cross_feat(historical_transactions)\n",
    "new_transactions = category_make_cross_feat(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "170f0e959ba5250b191b7cee6b586bdabd347018"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "historical_transactions = pd.get_dummies(historical_transactions, columns=['category_2', \n",
    "                                                                           'category_3',\n",
    "                                                                           'category_1_3_cross',\n",
    "                                                                           'category_2_3_cross'])\n",
    "new_transactions = pd.get_dummies(new_transactions, columns=['category_2', \n",
    "                                                             'category_3',\n",
    "                                                             'category_1_3_cross',\n",
    "                                                             'category_2_3_cross'])\n",
    "\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)\n",
    "\n",
    "agg_fun = {'authorized_flag': ['sum', 'mean', 'min', 'std', 'count']} # max is all 1's, useless\n",
    "auth_mean = historical_transactions.groupby(['card_id']).agg(agg_fun)\n",
    "auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns.values]\n",
    "auth_mean.reset_index(inplace=True)\n",
    "\n",
    "authorized_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 0]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90536f89e81fc4bb7f45a17f47e4b627f53e69b4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "historical_transactions['purchase_month'] = historical_transactions['purchase_date'].dt.month\n",
    "authorized_transactions['purchase_month'] = authorized_transactions['purchase_date'].dt.month\n",
    "new_transactions['purchase_month'] = new_transactions['purchase_date'].dt.month\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5de9c3bcc2ad2dfeb943e1b02fef3e433c91af3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def aggregate_transactions(history):\n",
    "    \n",
    "    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).\\\n",
    "                                      astype(np.int64) * 1e-9\n",
    "    \n",
    "    agg_func = {\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'category_2_1.0': ['mean'],\n",
    "        'category_2_2.0': ['mean'],\n",
    "        'category_2_3.0': ['mean'],\n",
    "        'category_2_4.0': ['mean'],\n",
    "        'category_2_5.0': ['mean'],\n",
    "        'category_3_1': ['mean'],\n",
    "        'category_3_2': ['mean'],\n",
    "        'category_3_3': ['mean'],\n",
    "        'category_1_3_cross_3': ['mean'],\n",
    "        'category_1_3_cross_4': ['mean'],\n",
    "        'category_1_3_cross_6': ['mean'],\n",
    "        'category_1_3_cross_8': ['mean'],\n",
    "        'category_1_3_cross_9': ['mean'],\n",
    "        'category_1_3_cross_12': ['mean'],\n",
    "        'category_2_3_cross_7.0': ['mean'],\n",
    "        'category_2_3_cross_8.0': ['mean'],\n",
    "        'category_2_3_cross_9.0': ['mean'],\n",
    "        'category_2_3_cross_10.0': ['mean'],\n",
    "        'category_2_3_cross_11.0': ['mean'],\n",
    "        'category_2_3_cross_12.0': ['mean'],\n",
    "        'category_2_3_cross_14.0': ['mean'],\n",
    "        'category_2_3_cross_16.0': ['mean'],\n",
    "        'category_2_3_cross_20.0': ['mean'],\n",
    "        'category_2_3_cross_21.0': ['mean'],\n",
    "        'category_2_3_cross_22.0': ['mean'],\n",
    "        'category_2_3_cross_24.0': ['mean'],\n",
    "        'category_2_3_cross_27.0': ['mean'],\n",
    "        'category_2_3_cross_30.0': ['mean'],\n",
    "        'category_2_3_cross_33.0': ['mean'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'state_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std', 'count'], #one count is enough, others are just the same\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'purchase_month': ['mean', 'max', 'min', 'std'],\n",
    "        'purchase_date': [np.ptp, 'min', 'max'],\n",
    "        'month_lag': ['min', 'max']\n",
    "        }\n",
    "    \n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "    \n",
    "    df = (history.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='transactions_count'))\n",
    "    \n",
    "    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n",
    "    \n",
    "    return agg_history\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf1f963f61841ef34f79fd16364bbf59b7f4e8a4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = aggregate_transactions(historical_transactions)\n",
    "history.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n",
    "history[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # history[[\"hist_purchase_amount_count\", \"hist_installments_count\", \"hist_purchase_month_count\"]].head(500)\n",
    "# history.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c1bdbaa7c16e22436893354b31d47e1846330ab"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "authorized = aggregate_transactions(authorized_transactions)\n",
    "authorized.columns = ['auth_' + c if c != 'card_id' else c for c in authorized.columns]\n",
    "authorized[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cc2775c29c17cb7438f3f5c45777b894afa94fc"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "new = aggregate_transactions(new_transactions)\n",
    "new.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n",
    "new[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb443fb1e2a47f5a0bef02921a2cba1d4e95e673"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def aggregate_per_month(history):\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "\n",
    "    agg_func = {\n",
    "#             'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "#             'installments': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "            'purchase_amount': ['count', 'sum'],\n",
    "            'installments': ['count', 'sum'],\n",
    "            }\n",
    "\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True)\n",
    "    \n",
    "    return final_group\n",
    "#___________________________________________________________\n",
    "final_group =  aggregate_per_month(historical_transactions) \n",
    "final_group[:10]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e5e313f605160783127a6f0798f176eaf6a55a4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.merge(train, history, on='card_id', how='left')\n",
    "test = pd.merge(test, history, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, authorized, on='card_id', how='left')\n",
    "test = pd.merge(test, authorized, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, new, on='card_id', how='left')\n",
    "test = pd.merge(test, new, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, final_group, on='card_id', how='left')\n",
    "test = pd.merge(test, final_group, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, auth_mean, on='card_id', how='left')\n",
    "test = pd.merge(test, auth_mean, on='card_id', how='left')\n",
    "\n",
    "print(\"Train Shape:\", train.shape)\n",
    "print(\"Test Shape:\", test.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feat(df):\n",
    "    # Feature crosses\n",
    "    df[\"feature_1_2_cross\"] = df[\"feature_1\"] + (df[\"feature_2\"]-1)*5\n",
    "    df[\"feature_1_3_cross\"] = df[\"feature_1\"] + df[\"feature_3\"]*3\n",
    "    df[\"feature_2_3_cross\"] = df[\"feature_2\"] + df[\"feature_3\"]*3\n",
    "    df = pd.get_dummies(df, columns=[\"feature_1_2_cross\", \"feature_1_3_cross\", \"feature_2_3_cross\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = generate_feat(train)\n",
    "test = generate_feat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_2_3_feat(df, feat_list):\n",
    "    for feat in feat_list:\n",
    "        df[feat+\"_power2\"] = df[feat]**2\n",
    "#         df[feat+\"_power3\"] = df[feat]**3\n",
    "    return df\n",
    "\n",
    "feat_list = [\"elapsed_time\", \"hist_purchase_date_ptp\"]\n",
    "train = power_2_3_feat(train, feat_list)\n",
    "test = power_2_3_feat(test, feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_feat(df, feat_list):\n",
    "    for feat in feat_list:\n",
    "        df[feat+\"_log\"] = np.log(df[feat])\n",
    "#         df[feat+\"_power3\"] = df[feat]**3\n",
    "    return df\n",
    "\n",
    "feat_list = [\"elapsed_time\"]\n",
    "train = log_feat(train, feat_list)\n",
    "test = log_feat(test, feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(100, 100))\n",
    "sns.heatmap(corrmat, vmax=1.0, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig(\"../img/corr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_feat_list = ['authorized_flag_min', \n",
    "                    'hist_purchase_amount_sum',\n",
    "                    'hist_purchase_amount_max',\n",
    "                    'hist_purchase_amount_min',\n",
    "                    'hist_purchase_amount_std',\n",
    "                    'hist_installments_sum',\n",
    "                    'hist_installments_max',\n",
    "                    'hist_installments_min',\n",
    "                    'hist_installments_std',\n",
    "                   ]\n",
    "train = train.drop(remove_feat_list, axis=1)\n",
    "test = test.drop(remove_feat_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(100, 100))\n",
    "sns.heatmap(corrmat, vmax=1.0, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig(\"../img/corr_after_feat_removal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../input/feat_list.pkl', 'rb') as f:\n",
    "#     feat_list = pickle.load(f)\n",
    "\n",
    "# train = train[feat_list]\n",
    "# test = test[feat_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target.pkl', 'wb') as f:\n",
    "    pickle.dump([train, target, test], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target.pkl', 'rb') as f:\n",
    "    [train, target, test] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n",
    "# saleprice correlation matrix\n",
    "\n",
    "# k = train.shape[1] #number of variables for heatmap\n",
    "# cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "# cm = np.corrcoef(df_train[cols].values.T)\n",
    "# sns.set(font_scale=1.25)\n",
    "# hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #scatterplot\n",
    "# sns.set()\n",
    "# # cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "# # sns.pairplot(df_train[cols], size = 2.5)\n",
    "# sns.pairplot(train, size = 2.5)\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,160))\n",
    "sns.distplot(target.values, bins=50, kde=False, color='blue')\n",
    "plt.title('Histogram of Loyalty Score before removal')\n",
    "plt.xlabel('Loyalty score', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "sns.distplot(target, fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(target, plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n",
    "print(\"Skewness: %f\" % pd.DataFrame(target).skew())\n",
    "print(\"Kurtosis: %f\" % pd.DataFrame(target).kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_target = min(value for value in target if value > -20)\n",
    "min_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_between_20_30 = [value for value in target if value >= -30 and value <=-20]\n",
    "len(idx_between_20_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_lessThan_30 = [value for value in target if value < -30]\n",
    "len(idx_lessThan_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/nottold/naive-ensemble-model-ridge-lasso\n",
    "class OutlierDetection(BaseEstimator):\n",
    "    def __init__(self, alpha, dims, std, mean, median):\n",
    "        self.alpha = alpha\n",
    "        self.dims = dims\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        self.median = median\n",
    "    def fit(self, X):\n",
    "        # std, mean, median = X.std(), X.mean(), X.median()\n",
    "        X[\"outliers\"] = 0\n",
    "        for col in X.columns:\n",
    "#             print(col)\n",
    "            if not col == \"outliers\":\n",
    "                # outlier_idx = (abs(X[col]) > (self.alpha * std[col] + mean[col]))\n",
    "                outlier_idx = (np.abs(X[col]) > (self.alpha * self.std[col] + self.mean[col]))\n",
    "                X.set_value(outlier_idx, \"outliers\", X[outlier_idx][\"outliers\"] + 1)\n",
    "        outliers = X[X[\"outliers\"] > self.dims]\n",
    "        X.drop(\"outliers\", axis=1, inplace=True)\n",
    "        outlier_idx = outliers.index.tolist()\n",
    "        # return outliers.index\n",
    "        return set(list(range(X.shape[0]))) - set(outlier_idx), outlier_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.DataFrame(target)\n",
    "\n",
    "outlier_removal = OutlierDetection(alpha=3, \n",
    "                                   dims=0, \n",
    "                                   std=target_df.std().astype('float'), \n",
    "                                   mean=target_df.mean().astype('float'), \n",
    "                                   median=target_df.median().astype('float'))\n",
    "normal_idx, outlier_idx = outlier_removal.fit(target_df)\n",
    "# samples = target_df.shape[0] - len(outlier)\n",
    "# xtrain = xtrain.drop(outlier_index).reset_index(drop=True)\n",
    "# y = y.drop(outlier_index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "796d4e17b4c4cc3121fc833669fc2eaf07bf4fba"
   },
   "outputs": [],
   "source": [
    "train[\"outliers\"] = 0\n",
    "train.at[outlier_idx, \"outliers\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"outliers\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'wb') as f:\n",
    "    pickle.dump([train, target, test, normal_idx, outlier_idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Model Without Outliers for 5 fold (n_repeats = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train[train['outliers'] == 0]\n",
    "df_target = target[normal_idx]\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199644, 208), (199644,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_regression_train(train, target, test, param, features, categorical_feats):\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))\n",
    "    return predictions, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62527\tvalid_1's rmse: 1.64356\n",
      "[200]\ttraining's rmse: 1.59162\tvalid_1's rmse: 1.61246\n",
      "[300]\ttraining's rmse: 1.57277\tvalid_1's rmse: 1.59586\n",
      "[400]\ttraining's rmse: 1.56033\tvalid_1's rmse: 1.58544\n",
      "[500]\ttraining's rmse: 1.55141\tvalid_1's rmse: 1.57839\n",
      "[600]\ttraining's rmse: 1.54427\tvalid_1's rmse: 1.57304\n",
      "[700]\ttraining's rmse: 1.53858\tvalid_1's rmse: 1.56906\n",
      "[800]\ttraining's rmse: 1.53387\tvalid_1's rmse: 1.56623\n",
      "[900]\ttraining's rmse: 1.52979\tvalid_1's rmse: 1.56395\n",
      "[1000]\ttraining's rmse: 1.52614\tvalid_1's rmse: 1.56218\n",
      "[1100]\ttraining's rmse: 1.52288\tvalid_1's rmse: 1.56074\n",
      "[1200]\ttraining's rmse: 1.5199\tvalid_1's rmse: 1.55964\n",
      "[1300]\ttraining's rmse: 1.51711\tvalid_1's rmse: 1.55868\n",
      "[1400]\ttraining's rmse: 1.51455\tvalid_1's rmse: 1.55791\n",
      "[1500]\ttraining's rmse: 1.51211\tvalid_1's rmse: 1.55729\n",
      "[1600]\ttraining's rmse: 1.50982\tvalid_1's rmse: 1.5568\n",
      "[1700]\ttraining's rmse: 1.50761\tvalid_1's rmse: 1.55641\n",
      "[1800]\ttraining's rmse: 1.50546\tvalid_1's rmse: 1.55604\n",
      "[1900]\ttraining's rmse: 1.50343\tvalid_1's rmse: 1.55572\n",
      "[2000]\ttraining's rmse: 1.50146\tvalid_1's rmse: 1.55548\n",
      "[2100]\ttraining's rmse: 1.49951\tvalid_1's rmse: 1.55531\n",
      "[2200]\ttraining's rmse: 1.49763\tvalid_1's rmse: 1.55511\n",
      "[2300]\ttraining's rmse: 1.49568\tvalid_1's rmse: 1.55487\n",
      "[2400]\ttraining's rmse: 1.49383\tvalid_1's rmse: 1.55469\n",
      "[2500]\ttraining's rmse: 1.49203\tvalid_1's rmse: 1.55456\n",
      "[2600]\ttraining's rmse: 1.49024\tvalid_1's rmse: 1.55442\n",
      "[2700]\ttraining's rmse: 1.48851\tvalid_1's rmse: 1.55432\n",
      "[2800]\ttraining's rmse: 1.48681\tvalid_1's rmse: 1.55417\n",
      "[2900]\ttraining's rmse: 1.48511\tvalid_1's rmse: 1.5541\n",
      "[3000]\ttraining's rmse: 1.48348\tvalid_1's rmse: 1.55399\n",
      "[3100]\ttraining's rmse: 1.4818\tvalid_1's rmse: 1.55389\n",
      "[3200]\ttraining's rmse: 1.48017\tvalid_1's rmse: 1.55377\n",
      "[3300]\ttraining's rmse: 1.47857\tvalid_1's rmse: 1.55369\n",
      "[3400]\ttraining's rmse: 1.47691\tvalid_1's rmse: 1.55366\n",
      "[3500]\ttraining's rmse: 1.47532\tvalid_1's rmse: 1.55357\n",
      "[3600]\ttraining's rmse: 1.47375\tvalid_1's rmse: 1.55347\n",
      "[3700]\ttraining's rmse: 1.47221\tvalid_1's rmse: 1.5534\n",
      "[3800]\ttraining's rmse: 1.47064\tvalid_1's rmse: 1.55335\n",
      "[3900]\ttraining's rmse: 1.46911\tvalid_1's rmse: 1.55331\n",
      "[4000]\ttraining's rmse: 1.46767\tvalid_1's rmse: 1.55328\n",
      "[4100]\ttraining's rmse: 1.46614\tvalid_1's rmse: 1.55327\n",
      "[4200]\ttraining's rmse: 1.4646\tvalid_1's rmse: 1.55321\n",
      "[4300]\ttraining's rmse: 1.46312\tvalid_1's rmse: 1.55317\n",
      "[4400]\ttraining's rmse: 1.46164\tvalid_1's rmse: 1.55312\n",
      "[4500]\ttraining's rmse: 1.46018\tvalid_1's rmse: 1.5531\n",
      "[4600]\ttraining's rmse: 1.45871\tvalid_1's rmse: 1.55309\n",
      "[4700]\ttraining's rmse: 1.45723\tvalid_1's rmse: 1.55306\n",
      "[4800]\ttraining's rmse: 1.45576\tvalid_1's rmse: 1.55304\n",
      "[4900]\ttraining's rmse: 1.4543\tvalid_1's rmse: 1.55302\n",
      "[5000]\ttraining's rmse: 1.45286\tvalid_1's rmse: 1.55299\n",
      "[5100]\ttraining's rmse: 1.45142\tvalid_1's rmse: 1.55297\n",
      "[5200]\ttraining's rmse: 1.44996\tvalid_1's rmse: 1.55298\n",
      "[5300]\ttraining's rmse: 1.44853\tvalid_1's rmse: 1.55296\n",
      "[5400]\ttraining's rmse: 1.44717\tvalid_1's rmse: 1.55295\n",
      "[5500]\ttraining's rmse: 1.44572\tvalid_1's rmse: 1.55292\n",
      "[5600]\ttraining's rmse: 1.4443\tvalid_1's rmse: 1.55286\n",
      "[5700]\ttraining's rmse: 1.44283\tvalid_1's rmse: 1.55284\n",
      "[5800]\ttraining's rmse: 1.44143\tvalid_1's rmse: 1.55281\n",
      "[5900]\ttraining's rmse: 1.44006\tvalid_1's rmse: 1.55284\n",
      "[6000]\ttraining's rmse: 1.43862\tvalid_1's rmse: 1.55287\n",
      "Early stopping, best iteration is:\n",
      "[5800]\ttraining's rmse: 1.44143\tvalid_1's rmse: 1.55281\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62925\tvalid_1's rmse: 1.62819\n",
      "[200]\ttraining's rmse: 1.59569\tvalid_1's rmse: 1.59625\n",
      "[300]\ttraining's rmse: 1.57748\tvalid_1's rmse: 1.57948\n",
      "[400]\ttraining's rmse: 1.565\tvalid_1's rmse: 1.56855\n",
      "[500]\ttraining's rmse: 1.55587\tvalid_1's rmse: 1.56096\n",
      "[600]\ttraining's rmse: 1.54872\tvalid_1's rmse: 1.55547\n",
      "[700]\ttraining's rmse: 1.54307\tvalid_1's rmse: 1.55156\n",
      "[800]\ttraining's rmse: 1.53836\tvalid_1's rmse: 1.54864\n",
      "[900]\ttraining's rmse: 1.53426\tvalid_1's rmse: 1.54625\n",
      "[1000]\ttraining's rmse: 1.53055\tvalid_1's rmse: 1.54437\n",
      "[1100]\ttraining's rmse: 1.52726\tvalid_1's rmse: 1.54298\n",
      "[1200]\ttraining's rmse: 1.52423\tvalid_1's rmse: 1.54192\n",
      "[1300]\ttraining's rmse: 1.52143\tvalid_1's rmse: 1.54102\n",
      "[1400]\ttraining's rmse: 1.51882\tvalid_1's rmse: 1.54027\n",
      "[1500]\ttraining's rmse: 1.51635\tvalid_1's rmse: 1.53971\n",
      "[1600]\ttraining's rmse: 1.51398\tvalid_1's rmse: 1.53929\n",
      "[1700]\ttraining's rmse: 1.51172\tvalid_1's rmse: 1.5389\n",
      "[1800]\ttraining's rmse: 1.50956\tvalid_1's rmse: 1.53853\n",
      "[1900]\ttraining's rmse: 1.50747\tvalid_1's rmse: 1.53828\n",
      "[2000]\ttraining's rmse: 1.50548\tvalid_1's rmse: 1.53804\n",
      "[2100]\ttraining's rmse: 1.50355\tvalid_1's rmse: 1.53783\n",
      "[2200]\ttraining's rmse: 1.50168\tvalid_1's rmse: 1.53767\n",
      "[2300]\ttraining's rmse: 1.49977\tvalid_1's rmse: 1.53755\n",
      "[2400]\ttraining's rmse: 1.49795\tvalid_1's rmse: 1.53743\n",
      "[2500]\ttraining's rmse: 1.49611\tvalid_1's rmse: 1.53728\n",
      "[2600]\ttraining's rmse: 1.49428\tvalid_1's rmse: 1.53716\n",
      "[2700]\ttraining's rmse: 1.49254\tvalid_1's rmse: 1.53707\n",
      "[2800]\ttraining's rmse: 1.49079\tvalid_1's rmse: 1.53695\n",
      "[2900]\ttraining's rmse: 1.48909\tvalid_1's rmse: 1.53688\n",
      "[3000]\ttraining's rmse: 1.48738\tvalid_1's rmse: 1.53682\n",
      "[3100]\ttraining's rmse: 1.48574\tvalid_1's rmse: 1.53675\n",
      "[3200]\ttraining's rmse: 1.48412\tvalid_1's rmse: 1.5367\n",
      "[3300]\ttraining's rmse: 1.48252\tvalid_1's rmse: 1.53667\n",
      "[3400]\ttraining's rmse: 1.48089\tvalid_1's rmse: 1.53659\n",
      "[3500]\ttraining's rmse: 1.47926\tvalid_1's rmse: 1.53655\n",
      "[3600]\ttraining's rmse: 1.4777\tvalid_1's rmse: 1.53649\n",
      "[3700]\ttraining's rmse: 1.47609\tvalid_1's rmse: 1.53641\n",
      "[3800]\ttraining's rmse: 1.4745\tvalid_1's rmse: 1.53634\n",
      "[3900]\ttraining's rmse: 1.47295\tvalid_1's rmse: 1.53632\n",
      "[4000]\ttraining's rmse: 1.47139\tvalid_1's rmse: 1.53627\n",
      "[4100]\ttraining's rmse: 1.46989\tvalid_1's rmse: 1.53622\n",
      "[4200]\ttraining's rmse: 1.46833\tvalid_1's rmse: 1.53621\n",
      "[4300]\ttraining's rmse: 1.46684\tvalid_1's rmse: 1.53618\n",
      "[4400]\ttraining's rmse: 1.46532\tvalid_1's rmse: 1.53616\n",
      "[4500]\ttraining's rmse: 1.46383\tvalid_1's rmse: 1.53614\n",
      "[4600]\ttraining's rmse: 1.46233\tvalid_1's rmse: 1.53614\n",
      "Early stopping, best iteration is:\n",
      "[4492]\ttraining's rmse: 1.46395\tvalid_1's rmse: 1.53613\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62702\tvalid_1's rmse: 1.63652\n",
      "[200]\ttraining's rmse: 1.59387\tvalid_1's rmse: 1.60394\n",
      "[300]\ttraining's rmse: 1.57554\tvalid_1's rmse: 1.58654\n",
      "[400]\ttraining's rmse: 1.56321\tvalid_1's rmse: 1.57548\n",
      "[500]\ttraining's rmse: 1.55417\tvalid_1's rmse: 1.56796\n",
      "[600]\ttraining's rmse: 1.54704\tvalid_1's rmse: 1.56252\n",
      "[700]\ttraining's rmse: 1.54133\tvalid_1's rmse: 1.55864\n",
      "[800]\ttraining's rmse: 1.53661\tvalid_1's rmse: 1.55574\n",
      "[900]\ttraining's rmse: 1.53246\tvalid_1's rmse: 1.55349\n",
      "[1000]\ttraining's rmse: 1.52879\tvalid_1's rmse: 1.55169\n",
      "[1100]\ttraining's rmse: 1.52547\tvalid_1's rmse: 1.55025\n",
      "[1200]\ttraining's rmse: 1.52242\tvalid_1's rmse: 1.54908\n",
      "[1300]\ttraining's rmse: 1.51961\tvalid_1's rmse: 1.54822\n",
      "[1400]\ttraining's rmse: 1.517\tvalid_1's rmse: 1.54751\n",
      "[1500]\ttraining's rmse: 1.51452\tvalid_1's rmse: 1.54694\n",
      "[1600]\ttraining's rmse: 1.51216\tvalid_1's rmse: 1.54648\n",
      "[1700]\ttraining's rmse: 1.50985\tvalid_1's rmse: 1.54609\n",
      "[1800]\ttraining's rmse: 1.50767\tvalid_1's rmse: 1.54576\n",
      "[1900]\ttraining's rmse: 1.50561\tvalid_1's rmse: 1.54549\n",
      "[2000]\ttraining's rmse: 1.50363\tvalid_1's rmse: 1.54529\n",
      "[2100]\ttraining's rmse: 1.50169\tvalid_1's rmse: 1.54508\n",
      "[2200]\ttraining's rmse: 1.49973\tvalid_1's rmse: 1.54488\n",
      "[2300]\ttraining's rmse: 1.49783\tvalid_1's rmse: 1.54472\n",
      "[2400]\ttraining's rmse: 1.49599\tvalid_1's rmse: 1.54459\n",
      "[2500]\ttraining's rmse: 1.49419\tvalid_1's rmse: 1.54446\n",
      "[2600]\ttraining's rmse: 1.49244\tvalid_1's rmse: 1.54434\n",
      "[2700]\ttraining's rmse: 1.4907\tvalid_1's rmse: 1.54423\n",
      "[2800]\ttraining's rmse: 1.48901\tvalid_1's rmse: 1.54416\n",
      "[2900]\ttraining's rmse: 1.48728\tvalid_1's rmse: 1.54405\n",
      "[3000]\ttraining's rmse: 1.48564\tvalid_1's rmse: 1.54393\n",
      "[3100]\ttraining's rmse: 1.48401\tvalid_1's rmse: 1.54385\n",
      "[3200]\ttraining's rmse: 1.48231\tvalid_1's rmse: 1.54377\n",
      "[3300]\ttraining's rmse: 1.48066\tvalid_1's rmse: 1.54369\n",
      "[3400]\ttraining's rmse: 1.47902\tvalid_1's rmse: 1.54361\n",
      "[3500]\ttraining's rmse: 1.47729\tvalid_1's rmse: 1.54351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3600]\ttraining's rmse: 1.47566\tvalid_1's rmse: 1.54347\n",
      "[3700]\ttraining's rmse: 1.47408\tvalid_1's rmse: 1.54335\n",
      "[3800]\ttraining's rmse: 1.47257\tvalid_1's rmse: 1.54334\n",
      "[3900]\ttraining's rmse: 1.47104\tvalid_1's rmse: 1.54328\n",
      "[4000]\ttraining's rmse: 1.46954\tvalid_1's rmse: 1.54325\n",
      "[4100]\ttraining's rmse: 1.46797\tvalid_1's rmse: 1.54317\n",
      "[4200]\ttraining's rmse: 1.46638\tvalid_1's rmse: 1.5431\n",
      "[4300]\ttraining's rmse: 1.46487\tvalid_1's rmse: 1.54307\n",
      "[4400]\ttraining's rmse: 1.46333\tvalid_1's rmse: 1.54303\n",
      "[4500]\ttraining's rmse: 1.46184\tvalid_1's rmse: 1.54297\n",
      "[4600]\ttraining's rmse: 1.46033\tvalid_1's rmse: 1.54295\n",
      "[4700]\ttraining's rmse: 1.45884\tvalid_1's rmse: 1.5429\n",
      "[4800]\ttraining's rmse: 1.45735\tvalid_1's rmse: 1.54288\n",
      "[4900]\ttraining's rmse: 1.45584\tvalid_1's rmse: 1.54282\n",
      "[5000]\ttraining's rmse: 1.45436\tvalid_1's rmse: 1.54278\n",
      "[5100]\ttraining's rmse: 1.4529\tvalid_1's rmse: 1.54274\n",
      "[5200]\ttraining's rmse: 1.45143\tvalid_1's rmse: 1.54271\n",
      "[5300]\ttraining's rmse: 1.44995\tvalid_1's rmse: 1.54271\n",
      "[5400]\ttraining's rmse: 1.44852\tvalid_1's rmse: 1.54266\n",
      "[5500]\ttraining's rmse: 1.4471\tvalid_1's rmse: 1.54266\n",
      "[5600]\ttraining's rmse: 1.44563\tvalid_1's rmse: 1.54263\n",
      "[5700]\ttraining's rmse: 1.44419\tvalid_1's rmse: 1.5426\n",
      "[5800]\ttraining's rmse: 1.44279\tvalid_1's rmse: 1.5426\n",
      "[5900]\ttraining's rmse: 1.44133\tvalid_1's rmse: 1.54258\n",
      "[6000]\ttraining's rmse: 1.4399\tvalid_1's rmse: 1.54257\n",
      "[6100]\ttraining's rmse: 1.4385\tvalid_1's rmse: 1.54255\n",
      "[6200]\ttraining's rmse: 1.43712\tvalid_1's rmse: 1.54252\n",
      "[6300]\ttraining's rmse: 1.43572\tvalid_1's rmse: 1.54245\n",
      "[6400]\ttraining's rmse: 1.43436\tvalid_1's rmse: 1.54246\n",
      "[6500]\ttraining's rmse: 1.43291\tvalid_1's rmse: 1.54243\n",
      "[6600]\ttraining's rmse: 1.43151\tvalid_1's rmse: 1.54243\n",
      "[6700]\ttraining's rmse: 1.43011\tvalid_1's rmse: 1.54245\n",
      "Early stopping, best iteration is:\n",
      "[6532]\ttraining's rmse: 1.43247\tvalid_1's rmse: 1.5424\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62869\tvalid_1's rmse: 1.62954\n",
      "[200]\ttraining's rmse: 1.59527\tvalid_1's rmse: 1.59827\n",
      "[300]\ttraining's rmse: 1.57634\tvalid_1's rmse: 1.58161\n",
      "[400]\ttraining's rmse: 1.56388\tvalid_1's rmse: 1.57167\n",
      "[500]\ttraining's rmse: 1.55473\tvalid_1's rmse: 1.56481\n",
      "[600]\ttraining's rmse: 1.5475\tvalid_1's rmse: 1.5598\n",
      "[700]\ttraining's rmse: 1.54177\tvalid_1's rmse: 1.55626\n",
      "[800]\ttraining's rmse: 1.53707\tvalid_1's rmse: 1.55366\n",
      "[900]\ttraining's rmse: 1.53293\tvalid_1's rmse: 1.55157\n",
      "[1000]\ttraining's rmse: 1.52925\tvalid_1's rmse: 1.54993\n",
      "[1100]\ttraining's rmse: 1.52594\tvalid_1's rmse: 1.54867\n",
      "[1200]\ttraining's rmse: 1.52296\tvalid_1's rmse: 1.54767\n",
      "[1300]\ttraining's rmse: 1.52014\tvalid_1's rmse: 1.5469\n",
      "[1400]\ttraining's rmse: 1.51751\tvalid_1's rmse: 1.54624\n",
      "[1500]\ttraining's rmse: 1.5151\tvalid_1's rmse: 1.54576\n",
      "[1600]\ttraining's rmse: 1.51276\tvalid_1's rmse: 1.54535\n",
      "[1700]\ttraining's rmse: 1.51052\tvalid_1's rmse: 1.54501\n",
      "[1800]\ttraining's rmse: 1.50843\tvalid_1's rmse: 1.54472\n",
      "[1900]\ttraining's rmse: 1.50637\tvalid_1's rmse: 1.54454\n",
      "[2000]\ttraining's rmse: 1.50433\tvalid_1's rmse: 1.54432\n",
      "[2100]\ttraining's rmse: 1.50232\tvalid_1's rmse: 1.5441\n",
      "[2200]\ttraining's rmse: 1.50035\tvalid_1's rmse: 1.54394\n",
      "[2300]\ttraining's rmse: 1.49848\tvalid_1's rmse: 1.54378\n",
      "[2400]\ttraining's rmse: 1.49669\tvalid_1's rmse: 1.5437\n",
      "[2500]\ttraining's rmse: 1.49486\tvalid_1's rmse: 1.54361\n",
      "[2600]\ttraining's rmse: 1.49314\tvalid_1's rmse: 1.54352\n",
      "[2700]\ttraining's rmse: 1.49138\tvalid_1's rmse: 1.54344\n",
      "[2800]\ttraining's rmse: 1.48968\tvalid_1's rmse: 1.54337\n",
      "[2900]\ttraining's rmse: 1.48791\tvalid_1's rmse: 1.54325\n",
      "[3000]\ttraining's rmse: 1.48622\tvalid_1's rmse: 1.54314\n",
      "[3100]\ttraining's rmse: 1.48455\tvalid_1's rmse: 1.54312\n",
      "[3200]\ttraining's rmse: 1.48295\tvalid_1's rmse: 1.54307\n",
      "[3300]\ttraining's rmse: 1.48126\tvalid_1's rmse: 1.54303\n",
      "[3400]\ttraining's rmse: 1.47965\tvalid_1's rmse: 1.54299\n",
      "[3500]\ttraining's rmse: 1.47812\tvalid_1's rmse: 1.54295\n",
      "[3600]\ttraining's rmse: 1.4765\tvalid_1's rmse: 1.54287\n",
      "[3700]\ttraining's rmse: 1.47494\tvalid_1's rmse: 1.5428\n",
      "[3800]\ttraining's rmse: 1.47335\tvalid_1's rmse: 1.54276\n",
      "[3900]\ttraining's rmse: 1.47178\tvalid_1's rmse: 1.54274\n",
      "[4000]\ttraining's rmse: 1.47026\tvalid_1's rmse: 1.54273\n",
      "[4100]\ttraining's rmse: 1.46873\tvalid_1's rmse: 1.54272\n",
      "[4200]\ttraining's rmse: 1.46721\tvalid_1's rmse: 1.54268\n",
      "[4300]\ttraining's rmse: 1.46573\tvalid_1's rmse: 1.54265\n",
      "[4400]\ttraining's rmse: 1.46422\tvalid_1's rmse: 1.54263\n",
      "[4500]\ttraining's rmse: 1.4627\tvalid_1's rmse: 1.5426\n",
      "[4600]\ttraining's rmse: 1.46118\tvalid_1's rmse: 1.54261\n",
      "[4700]\ttraining's rmse: 1.45969\tvalid_1's rmse: 1.54257\n",
      "[4800]\ttraining's rmse: 1.45817\tvalid_1's rmse: 1.54256\n",
      "[4900]\ttraining's rmse: 1.4567\tvalid_1's rmse: 1.54256\n",
      "Early stopping, best iteration is:\n",
      "[4784]\ttraining's rmse: 1.45842\tvalid_1's rmse: 1.54255\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.63225\tvalid_1's rmse: 1.61488\n",
      "[200]\ttraining's rmse: 1.59846\tvalid_1's rmse: 1.58415\n",
      "[300]\ttraining's rmse: 1.57957\tvalid_1's rmse: 1.56809\n",
      "[400]\ttraining's rmse: 1.56724\tvalid_1's rmse: 1.5581\n",
      "[500]\ttraining's rmse: 1.55819\tvalid_1's rmse: 1.55125\n",
      "[600]\ttraining's rmse: 1.55106\tvalid_1's rmse: 1.54606\n",
      "[700]\ttraining's rmse: 1.54538\tvalid_1's rmse: 1.54235\n",
      "[800]\ttraining's rmse: 1.54067\tvalid_1's rmse: 1.53963\n",
      "[900]\ttraining's rmse: 1.53658\tvalid_1's rmse: 1.53747\n",
      "[1000]\ttraining's rmse: 1.53297\tvalid_1's rmse: 1.5358\n",
      "[1100]\ttraining's rmse: 1.5297\tvalid_1's rmse: 1.53451\n",
      "[1200]\ttraining's rmse: 1.52671\tvalid_1's rmse: 1.53343\n",
      "[1300]\ttraining's rmse: 1.5239\tvalid_1's rmse: 1.53259\n",
      "[1400]\ttraining's rmse: 1.52129\tvalid_1's rmse: 1.53201\n",
      "[1500]\ttraining's rmse: 1.51884\tvalid_1's rmse: 1.53146\n",
      "[1600]\ttraining's rmse: 1.51647\tvalid_1's rmse: 1.53101\n",
      "[1700]\ttraining's rmse: 1.51424\tvalid_1's rmse: 1.53062\n",
      "[1800]\ttraining's rmse: 1.51199\tvalid_1's rmse: 1.5303\n",
      "[1900]\ttraining's rmse: 1.50994\tvalid_1's rmse: 1.53008\n",
      "[2000]\ttraining's rmse: 1.50791\tvalid_1's rmse: 1.52983\n",
      "[2100]\ttraining's rmse: 1.50595\tvalid_1's rmse: 1.52959\n",
      "[2200]\ttraining's rmse: 1.50401\tvalid_1's rmse: 1.52947\n",
      "[2300]\ttraining's rmse: 1.50216\tvalid_1's rmse: 1.52928\n",
      "[2400]\ttraining's rmse: 1.50032\tvalid_1's rmse: 1.52918\n",
      "[2500]\ttraining's rmse: 1.49849\tvalid_1's rmse: 1.52906\n",
      "[2600]\ttraining's rmse: 1.49663\tvalid_1's rmse: 1.52896\n",
      "[2700]\ttraining's rmse: 1.49486\tvalid_1's rmse: 1.52884\n",
      "[2800]\ttraining's rmse: 1.49309\tvalid_1's rmse: 1.52873\n",
      "[2900]\ttraining's rmse: 1.49136\tvalid_1's rmse: 1.52861\n",
      "[3000]\ttraining's rmse: 1.48966\tvalid_1's rmse: 1.5285\n",
      "[3100]\ttraining's rmse: 1.48798\tvalid_1's rmse: 1.52844\n",
      "[3200]\ttraining's rmse: 1.48634\tvalid_1's rmse: 1.52838\n",
      "[3300]\ttraining's rmse: 1.48472\tvalid_1's rmse: 1.52828\n",
      "[3400]\ttraining's rmse: 1.48306\tvalid_1's rmse: 1.52819\n",
      "[3500]\ttraining's rmse: 1.48143\tvalid_1's rmse: 1.52815\n",
      "[3600]\ttraining's rmse: 1.47983\tvalid_1's rmse: 1.52809\n",
      "[3700]\ttraining's rmse: 1.47823\tvalid_1's rmse: 1.5281\n",
      "[3800]\ttraining's rmse: 1.47666\tvalid_1's rmse: 1.52802\n",
      "[3900]\ttraining's rmse: 1.4751\tvalid_1's rmse: 1.52798\n",
      "[4000]\ttraining's rmse: 1.47354\tvalid_1's rmse: 1.52792\n",
      "[4100]\ttraining's rmse: 1.47199\tvalid_1's rmse: 1.52793\n",
      "[4200]\ttraining's rmse: 1.47048\tvalid_1's rmse: 1.5279\n",
      "[4300]\ttraining's rmse: 1.46894\tvalid_1's rmse: 1.52782\n",
      "[4400]\ttraining's rmse: 1.46739\tvalid_1's rmse: 1.52782\n",
      "[4500]\ttraining's rmse: 1.46586\tvalid_1's rmse: 1.52779\n",
      "[4600]\ttraining's rmse: 1.4643\tvalid_1's rmse: 1.52773\n",
      "[4700]\ttraining's rmse: 1.46277\tvalid_1's rmse: 1.52772\n",
      "[4800]\ttraining's rmse: 1.46124\tvalid_1's rmse: 1.52772\n",
      "[4900]\ttraining's rmse: 1.45978\tvalid_1's rmse: 1.52769\n",
      "[5000]\ttraining's rmse: 1.45835\tvalid_1's rmse: 1.52767\n",
      "[5100]\ttraining's rmse: 1.45686\tvalid_1's rmse: 1.52769\n",
      "[5200]\ttraining's rmse: 1.45535\tvalid_1's rmse: 1.52767\n",
      "[5300]\ttraining's rmse: 1.4539\tvalid_1's rmse: 1.52769\n",
      "Early stopping, best iteration is:\n",
      "[5161]\ttraining's rmse: 1.45592\tvalid_1's rmse: 1.52764\n",
      "CV score: 1.54033 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005, #default: 0.005 (3.66940)   /   0.005(3.67032), 0.01 (3.67152), 0.05 ()\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"nthread\": -1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "normal_predictions, oof = lgbm_regression_train(df_train, \n",
    "                                                df_target, \n",
    "                                                test, \n",
    "                                                param, \n",
    "                                                features, \n",
    "                                                categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "model_without_outliers[\"target\"] = normal_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Training Model For Outliers Classification for 5 fold (n_repeats = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_classification_train(df_train, target, df_test, param, features, categorical_feats):\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(len(df_train))\n",
    "    predictions = np.zeros(len(df_test))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    start = time.time()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "        \n",
    "    print(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))\n",
    "\n",
    "    return predictions, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0451509\tvalid_1's binary_logloss: 0.0480669\n",
      "[200]\ttraining's binary_logloss: 0.0451168\tvalid_1's binary_logloss: 0.0480732\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0451386\tvalid_1's binary_logloss: 0.0480215\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0457537\tvalid_1's binary_logloss: 0.046939\n",
      "[200]\ttraining's binary_logloss: 0.0457265\tvalid_1's binary_logloss: 0.0468905\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.0456993\tvalid_1's binary_logloss: 0.0468931\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0453821\tvalid_1's binary_logloss: 0.0466012\n",
      "[200]\ttraining's binary_logloss: 0.0453995\tvalid_1's binary_logloss: 0.0465879\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0453747\tvalid_1's binary_logloss: 0.0465525\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0444893\tvalid_1's binary_logloss: 0.0512099\n",
      "[200]\ttraining's binary_logloss: 0.0444781\tvalid_1's binary_logloss: 0.0512198\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.0446097\tvalid_1's binary_logloss: 0.0511024\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.045296\tvalid_1's binary_logloss: 0.0470667\n",
      "[200]\ttraining's binary_logloss: 0.0452779\tvalid_1's binary_logloss: 0.047031\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0452333\tvalid_1's binary_logloss: 0.0469927\n",
      "CV score: 0.04791 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 51, #default: 31\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333}\n",
    "\n",
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "\n",
    "target = train['outliers']\n",
    "del train['outliers']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]\n",
    "outlier_label, oof_class = lgbm_classification_train(train, target, test, param, features, categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>0.107459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>0.010603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>0.000683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>0.000683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab  0.107459\n",
       "1  C_ID_130fd0cbdd  0.000801\n",
       "2  C_ID_b709037bc5  0.010603\n",
       "3  C_ID_d27d835a9f  0.000683\n",
       "4  C_ID_2b5e3df5c2  0.000683"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlier_prob = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "df_outlier_prob[\"target\"] = outlier_label\n",
    "df_outlier_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Predict outlier for 5 fold (n_repeats = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train[train['outliers'] == 1]\n",
    "df_target = target[outlier_idx]\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 5.63465\tvalid_1's rmse: 3.97548\n",
      "[200]\ttraining's rmse: 5.37692\tvalid_1's rmse: 4.04092\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's rmse: 5.90163\tvalid_1's rmse: 3.93729\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 5.21715\tvalid_1's rmse: 6.19824\n",
      "[200]\ttraining's rmse: 5.0162\tvalid_1's rmse: 6.15378\n",
      "[300]\ttraining's rmse: 4.83747\tvalid_1's rmse: 6.11821\n",
      "[400]\ttraining's rmse: 4.67576\tvalid_1's rmse: 6.08059\n",
      "[500]\ttraining's rmse: 4.52147\tvalid_1's rmse: 6.04763\n",
      "[600]\ttraining's rmse: 4.3771\tvalid_1's rmse: 6.02036\n",
      "[700]\ttraining's rmse: 4.2439\tvalid_1's rmse: 5.99999\n",
      "[800]\ttraining's rmse: 4.11679\tvalid_1's rmse: 5.97422\n",
      "[900]\ttraining's rmse: 3.99291\tvalid_1's rmse: 5.96361\n",
      "[1000]\ttraining's rmse: 3.88143\tvalid_1's rmse: 5.95469\n",
      "[1100]\ttraining's rmse: 3.7716\tvalid_1's rmse: 5.93845\n",
      "[1200]\ttraining's rmse: 3.66845\tvalid_1's rmse: 5.92679\n",
      "[1300]\ttraining's rmse: 3.57088\tvalid_1's rmse: 5.91566\n",
      "[1400]\ttraining's rmse: 3.47913\tvalid_1's rmse: 5.90835\n",
      "[1500]\ttraining's rmse: 3.38696\tvalid_1's rmse: 5.89988\n",
      "[1600]\ttraining's rmse: 3.29786\tvalid_1's rmse: 5.89366\n",
      "[1700]\ttraining's rmse: 3.21622\tvalid_1's rmse: 5.88657\n",
      "[1800]\ttraining's rmse: 3.136\tvalid_1's rmse: 5.8806\n",
      "[1900]\ttraining's rmse: 3.0593\tvalid_1's rmse: 5.87689\n",
      "[2000]\ttraining's rmse: 2.98239\tvalid_1's rmse: 5.86979\n",
      "[2100]\ttraining's rmse: 2.90896\tvalid_1's rmse: 5.87021\n",
      "[2200]\ttraining's rmse: 2.84169\tvalid_1's rmse: 5.86606\n",
      "[2300]\ttraining's rmse: 2.77381\tvalid_1's rmse: 5.86469\n",
      "[2400]\ttraining's rmse: 2.70972\tvalid_1's rmse: 5.86154\n",
      "[2500]\ttraining's rmse: 2.64698\tvalid_1's rmse: 5.85879\n",
      "[2600]\ttraining's rmse: 2.58663\tvalid_1's rmse: 5.85517\n",
      "[2700]\ttraining's rmse: 2.5276\tvalid_1's rmse: 5.85502\n",
      "[2800]\ttraining's rmse: 2.47065\tvalid_1's rmse: 5.85394\n",
      "[2900]\ttraining's rmse: 2.41281\tvalid_1's rmse: 5.85061\n",
      "[3000]\ttraining's rmse: 2.35988\tvalid_1's rmse: 5.85115\n",
      "[3100]\ttraining's rmse: 2.30804\tvalid_1's rmse: 5.84997\n",
      "Early stopping, best iteration is:\n",
      "[2916]\ttraining's rmse: 2.40374\tvalid_1's rmse: 5.84878\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 5.30907\tvalid_1's rmse: 5.8505\n",
      "[200]\ttraining's rmse: 5.09503\tvalid_1's rmse: 5.72005\n",
      "[300]\ttraining's rmse: 4.90739\tvalid_1's rmse: 5.63058\n",
      "[400]\ttraining's rmse: 4.73694\tvalid_1's rmse: 5.57237\n",
      "[500]\ttraining's rmse: 4.57891\tvalid_1's rmse: 5.52861\n",
      "[600]\ttraining's rmse: 4.4302\tvalid_1's rmse: 5.48831\n",
      "[700]\ttraining's rmse: 4.2926\tvalid_1's rmse: 5.4519\n",
      "[800]\ttraining's rmse: 4.15953\tvalid_1's rmse: 5.42642\n",
      "[900]\ttraining's rmse: 4.02756\tvalid_1's rmse: 5.40089\n",
      "[1000]\ttraining's rmse: 3.90332\tvalid_1's rmse: 5.38471\n",
      "[1100]\ttraining's rmse: 3.7862\tvalid_1's rmse: 5.36877\n",
      "[1200]\ttraining's rmse: 3.67693\tvalid_1's rmse: 5.35675\n",
      "[1300]\ttraining's rmse: 3.57298\tvalid_1's rmse: 5.34385\n",
      "[1400]\ttraining's rmse: 3.47342\tvalid_1's rmse: 5.33151\n",
      "[1500]\ttraining's rmse: 3.37711\tvalid_1's rmse: 5.3229\n",
      "[1600]\ttraining's rmse: 3.28094\tvalid_1's rmse: 5.316\n",
      "[1700]\ttraining's rmse: 3.18884\tvalid_1's rmse: 5.31172\n",
      "[1800]\ttraining's rmse: 3.10046\tvalid_1's rmse: 5.30428\n",
      "[1900]\ttraining's rmse: 3.01737\tvalid_1's rmse: 5.30406\n",
      "[2000]\ttraining's rmse: 2.93596\tvalid_1's rmse: 5.30222\n",
      "[2100]\ttraining's rmse: 2.85683\tvalid_1's rmse: 5.29659\n",
      "[2200]\ttraining's rmse: 2.78024\tvalid_1's rmse: 5.29707\n",
      "[2300]\ttraining's rmse: 2.70694\tvalid_1's rmse: 5.29744\n",
      "[2400]\ttraining's rmse: 2.63529\tvalid_1's rmse: 5.29406\n",
      "[2500]\ttraining's rmse: 2.56817\tvalid_1's rmse: 5.29354\n",
      "[2600]\ttraining's rmse: 2.5007\tvalid_1's rmse: 5.29649\n",
      "Early stopping, best iteration is:\n",
      "[2475]\ttraining's rmse: 2.58458\tvalid_1's rmse: 5.29217\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 5.26815\tvalid_1's rmse: 5.99214\n",
      "[200]\ttraining's rmse: 5.04219\tvalid_1's rmse: 5.88084\n",
      "[300]\ttraining's rmse: 4.85159\tvalid_1's rmse: 5.80972\n",
      "[400]\ttraining's rmse: 4.66633\tvalid_1's rmse: 5.7634\n",
      "[500]\ttraining's rmse: 4.5035\tvalid_1's rmse: 5.71902\n",
      "[600]\ttraining's rmse: 4.34993\tvalid_1's rmse: 5.68969\n",
      "[700]\ttraining's rmse: 4.20634\tvalid_1's rmse: 5.67339\n",
      "[800]\ttraining's rmse: 4.07153\tvalid_1's rmse: 5.65342\n",
      "[900]\ttraining's rmse: 3.94768\tvalid_1's rmse: 5.63056\n",
      "[1000]\ttraining's rmse: 3.82403\tvalid_1's rmse: 5.61806\n",
      "[1100]\ttraining's rmse: 3.70809\tvalid_1's rmse: 5.60672\n",
      "[1200]\ttraining's rmse: 3.59901\tvalid_1's rmse: 5.59935\n",
      "[1300]\ttraining's rmse: 3.49722\tvalid_1's rmse: 5.59513\n",
      "[1400]\ttraining's rmse: 3.39644\tvalid_1's rmse: 5.58816\n",
      "[1500]\ttraining's rmse: 3.30045\tvalid_1's rmse: 5.58078\n",
      "[1600]\ttraining's rmse: 3.20862\tvalid_1's rmse: 5.57952\n",
      "[1700]\ttraining's rmse: 3.11814\tvalid_1's rmse: 5.57115\n",
      "[1800]\ttraining's rmse: 3.032\tvalid_1's rmse: 5.56752\n",
      "[1900]\ttraining's rmse: 2.94996\tvalid_1's rmse: 5.56683\n",
      "[2000]\ttraining's rmse: 2.87322\tvalid_1's rmse: 5.56784\n",
      "[2100]\ttraining's rmse: 2.79855\tvalid_1's rmse: 5.56742\n",
      "Early stopping, best iteration is:\n",
      "[1952]\ttraining's rmse: 2.90943\tvalid_1's rmse: 5.564\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 5.41932\tvalid_1's rmse: 5.35849\n",
      "[200]\ttraining's rmse: 5.20485\tvalid_1's rmse: 5.25552\n",
      "[300]\ttraining's rmse: 5.00047\tvalid_1's rmse: 5.18523\n",
      "[400]\ttraining's rmse: 4.82063\tvalid_1's rmse: 5.13636\n",
      "[500]\ttraining's rmse: 4.65728\tvalid_1's rmse: 5.08496\n",
      "[600]\ttraining's rmse: 4.51288\tvalid_1's rmse: 5.05045\n",
      "[700]\ttraining's rmse: 4.37279\tvalid_1's rmse: 5.02295\n",
      "[800]\ttraining's rmse: 4.23502\tvalid_1's rmse: 5.00933\n",
      "[900]\ttraining's rmse: 4.10602\tvalid_1's rmse: 4.98847\n",
      "[1000]\ttraining's rmse: 3.98729\tvalid_1's rmse: 4.97362\n",
      "[1100]\ttraining's rmse: 3.8761\tvalid_1's rmse: 4.96178\n",
      "[1200]\ttraining's rmse: 3.76766\tvalid_1's rmse: 4.94612\n",
      "[1300]\ttraining's rmse: 3.66416\tvalid_1's rmse: 4.94647\n",
      "[1400]\ttraining's rmse: 3.56148\tvalid_1's rmse: 4.93428\n",
      "[1500]\ttraining's rmse: 3.46457\tvalid_1's rmse: 4.9241\n",
      "[1600]\ttraining's rmse: 3.37203\tvalid_1's rmse: 4.92049\n",
      "[1700]\ttraining's rmse: 3.27854\tvalid_1's rmse: 4.91709\n",
      "[1800]\ttraining's rmse: 3.19501\tvalid_1's rmse: 4.91881\n",
      "[1900]\ttraining's rmse: 3.11012\tvalid_1's rmse: 4.90889\n",
      "[2000]\ttraining's rmse: 3.02989\tvalid_1's rmse: 4.90497\n",
      "[2100]\ttraining's rmse: 2.9502\tvalid_1's rmse: 4.90843\n",
      "[2200]\ttraining's rmse: 2.87507\tvalid_1's rmse: 4.90724\n",
      "Early stopping, best iteration is:\n",
      "[2014]\ttraining's rmse: 3.02025\tvalid_1's rmse: 4.90339\n",
      "CV score: 5.15198 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005, #default: 0.005 (3.66940)   /   0.005(3.67032), 0.01 (3.67152), 0.05 ()\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"nthread\": -1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "outlier_predictions, oof_outlier = lgbm_regression_train(df_train, \n",
    "                                                         df_target, \n",
    "                                                         test, \n",
    "                                                         param, \n",
    "                                                         features, \n",
    "                                                         categorical_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Combining Submission for 5 fold (n_repeats = 1)\n",
    "\n",
    "### Using the old way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_id = pd.DataFrame(\\\n",
    "                          df_outlier_prob.sort_values(by='target',\n",
    "                                                      ascending = False)\n",
    "                          .head(25000)['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_submission = pd.read_csv('../result/Blend2_v2.csv')\n",
    "best_submission = pd.read_csv('../result/Blend2_v10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.409111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.360448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.833417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.246980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.150486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.409111\n",
       "1  C_ID_130fd0cbdd -0.360448\n",
       "2  C_ID_b709037bc5 -0.833417\n",
       "3  C_ID_d27d835a9f -0.246980\n",
       "4  C_ID_2b5e3df5c2 -1.150486"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_submission.shape[0])\n",
    "best_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.409111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_6d8dba8475</td>\n",
       "      <td>-0.886411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_4859ac9ed5</td>\n",
       "      <td>-0.627507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_7f1041e8e1</td>\n",
       "      <td>-5.065158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_22e4a47c72</td>\n",
       "      <td>0.362193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.409111\n",
       "1  C_ID_6d8dba8475 -0.886411\n",
       "2  C_ID_4859ac9ed5 -0.627507\n",
       "3  C_ID_7f1041e8e1 -5.065158\n",
       "4  C_ID_22e4a47c72  0.362193"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outlier_id.shape[0])\n",
    "most_likely_liers = best_submission.merge(outlier_id,how='right')\n",
    "most_likely_liers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 23s, sys: 44.9 ms, total: 4min 23s\n",
      "Wall time: 4min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for card_id in most_likely_liers['card_id']:\n",
    "    model_without_outliers.loc[model_without_outliers['card_id']==card_id,'target']\\\n",
    "    = most_likely_liers.loc[most_likely_liers['card_id']==card_id,'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_without_outliers.to_csv(\"../result/Blend2_v3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers_new = pd.read_csv('../result/Blend2_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_without_outliers_new[] = \n",
    "# model_without_outliers_new[] = outlier_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training Model Without Outliers for 5 fold (n_repeats = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_regression_train_n_repeats_2(train, target, test, param, features, categorical_feats):\n",
    "    folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4520)\n",
    "    oof_lgb = np.zeros(len(train))\n",
    "    predictions_lgb = np.zeros(len(test))\n",
    "    start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 11000\n",
    "        clf = lgb.train(lgbparam, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "        oof_lgb[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions_lgb += clf.predict(test[features], num_iteration=clf.best_iteration) / (5 * 2)\n",
    "\n",
    "    print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_lgb, target)**0.5))\n",
    "    return predictions_lgb, oof_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.6162\tvalid_1's rmse: 1.63259\n",
      "[200]\ttraining's rmse: 1.57665\tvalid_1's rmse: 1.59753\n",
      "[300]\ttraining's rmse: 1.55418\tvalid_1's rmse: 1.57959\n",
      "[400]\ttraining's rmse: 1.53928\tvalid_1's rmse: 1.56914\n",
      "[500]\ttraining's rmse: 1.52808\tvalid_1's rmse: 1.56232\n",
      "[600]\ttraining's rmse: 1.51906\tvalid_1's rmse: 1.55764\n",
      "[700]\ttraining's rmse: 1.51142\tvalid_1's rmse: 1.55434\n",
      "[800]\ttraining's rmse: 1.50478\tvalid_1's rmse: 1.55203\n",
      "[900]\ttraining's rmse: 1.49877\tvalid_1's rmse: 1.55038\n",
      "[1000]\ttraining's rmse: 1.49314\tvalid_1's rmse: 1.54915\n",
      "[1100]\ttraining's rmse: 1.48792\tvalid_1's rmse: 1.54826\n",
      "[1200]\ttraining's rmse: 1.48299\tvalid_1's rmse: 1.54769\n",
      "[1300]\ttraining's rmse: 1.47837\tvalid_1's rmse: 1.54714\n",
      "[1400]\ttraining's rmse: 1.47394\tvalid_1's rmse: 1.5468\n",
      "[1500]\ttraining's rmse: 1.46965\tvalid_1's rmse: 1.54647\n",
      "[1600]\ttraining's rmse: 1.46551\tvalid_1's rmse: 1.54624\n",
      "[1700]\ttraining's rmse: 1.46157\tvalid_1's rmse: 1.54618\n",
      "[1800]\ttraining's rmse: 1.45774\tvalid_1's rmse: 1.54602\n",
      "[1900]\ttraining's rmse: 1.45399\tvalid_1's rmse: 1.54588\n",
      "[2000]\ttraining's rmse: 1.45035\tvalid_1's rmse: 1.54579\n",
      "[2100]\ttraining's rmse: 1.44681\tvalid_1's rmse: 1.54571\n",
      "[2200]\ttraining's rmse: 1.44327\tvalid_1's rmse: 1.54571\n",
      "Early stopping, best iteration is:\n",
      "[2179]\ttraining's rmse: 1.44398\tvalid_1's rmse: 1.54568\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61732\tvalid_1's rmse: 1.62572\n",
      "[200]\ttraining's rmse: 1.57719\tvalid_1's rmse: 1.59152\n",
      "[300]\ttraining's rmse: 1.5546\tvalid_1's rmse: 1.57449\n",
      "[400]\ttraining's rmse: 1.53939\tvalid_1's rmse: 1.56461\n",
      "[500]\ttraining's rmse: 1.52806\tvalid_1's rmse: 1.55851\n",
      "[600]\ttraining's rmse: 1.51894\tvalid_1's rmse: 1.55439\n",
      "[700]\ttraining's rmse: 1.5112\tvalid_1's rmse: 1.55148\n",
      "[800]\ttraining's rmse: 1.50449\tvalid_1's rmse: 1.54937\n",
      "[900]\ttraining's rmse: 1.49845\tvalid_1's rmse: 1.54796\n",
      "[1000]\ttraining's rmse: 1.49286\tvalid_1's rmse: 1.54688\n",
      "[1100]\ttraining's rmse: 1.4876\tvalid_1's rmse: 1.54606\n",
      "[1200]\ttraining's rmse: 1.48269\tvalid_1's rmse: 1.54551\n",
      "[1300]\ttraining's rmse: 1.478\tvalid_1's rmse: 1.54513\n",
      "[1400]\ttraining's rmse: 1.47362\tvalid_1's rmse: 1.54477\n",
      "[1500]\ttraining's rmse: 1.46936\tvalid_1's rmse: 1.54454\n",
      "[1600]\ttraining's rmse: 1.46526\tvalid_1's rmse: 1.54436\n",
      "[1700]\ttraining's rmse: 1.4612\tvalid_1's rmse: 1.54416\n",
      "[1800]\ttraining's rmse: 1.45733\tvalid_1's rmse: 1.54413\n",
      "[1900]\ttraining's rmse: 1.45354\tvalid_1's rmse: 1.54409\n",
      "[2000]\ttraining's rmse: 1.44982\tvalid_1's rmse: 1.54401\n",
      "[2100]\ttraining's rmse: 1.44623\tvalid_1's rmse: 1.54403\n",
      "Early stopping, best iteration is:\n",
      "[2041]\ttraining's rmse: 1.44834\tvalid_1's rmse: 1.54398\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61835\tvalid_1's rmse: 1.62209\n",
      "[200]\ttraining's rmse: 1.57848\tvalid_1's rmse: 1.58753\n",
      "[300]\ttraining's rmse: 1.55592\tvalid_1's rmse: 1.57024\n",
      "[400]\ttraining's rmse: 1.54086\tvalid_1's rmse: 1.56041\n",
      "[500]\ttraining's rmse: 1.52953\tvalid_1's rmse: 1.55413\n",
      "[600]\ttraining's rmse: 1.52049\tvalid_1's rmse: 1.55004\n",
      "[700]\ttraining's rmse: 1.51272\tvalid_1's rmse: 1.54728\n",
      "[800]\ttraining's rmse: 1.506\tvalid_1's rmse: 1.54538\n",
      "[900]\ttraining's rmse: 1.49993\tvalid_1's rmse: 1.54401\n",
      "[1000]\ttraining's rmse: 1.49434\tvalid_1's rmse: 1.54291\n",
      "[1100]\ttraining's rmse: 1.48913\tvalid_1's rmse: 1.54223\n",
      "[1200]\ttraining's rmse: 1.48421\tvalid_1's rmse: 1.54165\n",
      "[1300]\ttraining's rmse: 1.47958\tvalid_1's rmse: 1.5412\n",
      "[1400]\ttraining's rmse: 1.47517\tvalid_1's rmse: 1.54092\n",
      "[1500]\ttraining's rmse: 1.47095\tvalid_1's rmse: 1.54064\n",
      "[1600]\ttraining's rmse: 1.46683\tvalid_1's rmse: 1.54038\n",
      "[1700]\ttraining's rmse: 1.46289\tvalid_1's rmse: 1.54017\n",
      "[1800]\ttraining's rmse: 1.459\tvalid_1's rmse: 1.53999\n",
      "[1900]\ttraining's rmse: 1.45528\tvalid_1's rmse: 1.53986\n",
      "[2000]\ttraining's rmse: 1.45158\tvalid_1's rmse: 1.53975\n",
      "[2100]\ttraining's rmse: 1.44794\tvalid_1's rmse: 1.53966\n",
      "[2200]\ttraining's rmse: 1.44441\tvalid_1's rmse: 1.53961\n",
      "[2300]\ttraining's rmse: 1.44093\tvalid_1's rmse: 1.53951\n",
      "[2400]\ttraining's rmse: 1.43746\tvalid_1's rmse: 1.5395\n",
      "[2500]\ttraining's rmse: 1.43402\tvalid_1's rmse: 1.53948\n",
      "Early stopping, best iteration is:\n",
      "[2432]\ttraining's rmse: 1.43633\tvalid_1's rmse: 1.53947\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61946\tvalid_1's rmse: 1.61884\n",
      "[200]\ttraining's rmse: 1.57981\tvalid_1's rmse: 1.58371\n",
      "[300]\ttraining's rmse: 1.55739\tvalid_1's rmse: 1.56615\n",
      "[400]\ttraining's rmse: 1.54231\tvalid_1's rmse: 1.5559\n",
      "[500]\ttraining's rmse: 1.53101\tvalid_1's rmse: 1.54955\n",
      "[600]\ttraining's rmse: 1.5219\tvalid_1's rmse: 1.54528\n",
      "[700]\ttraining's rmse: 1.51421\tvalid_1's rmse: 1.54229\n",
      "[800]\ttraining's rmse: 1.50746\tvalid_1's rmse: 1.54024\n",
      "[900]\ttraining's rmse: 1.50146\tvalid_1's rmse: 1.5388\n",
      "[1000]\ttraining's rmse: 1.4959\tvalid_1's rmse: 1.53764\n",
      "[1100]\ttraining's rmse: 1.4907\tvalid_1's rmse: 1.53685\n",
      "[1200]\ttraining's rmse: 1.48582\tvalid_1's rmse: 1.53626\n",
      "[1300]\ttraining's rmse: 1.48121\tvalid_1's rmse: 1.53574\n",
      "[1400]\ttraining's rmse: 1.47683\tvalid_1's rmse: 1.53531\n",
      "[1500]\ttraining's rmse: 1.47254\tvalid_1's rmse: 1.53499\n",
      "[1600]\ttraining's rmse: 1.46837\tvalid_1's rmse: 1.53475\n",
      "[1700]\ttraining's rmse: 1.46442\tvalid_1's rmse: 1.53453\n",
      "[1800]\ttraining's rmse: 1.46056\tvalid_1's rmse: 1.53433\n",
      "[1900]\ttraining's rmse: 1.45682\tvalid_1's rmse: 1.5342\n",
      "[2000]\ttraining's rmse: 1.45309\tvalid_1's rmse: 1.53412\n",
      "[2100]\ttraining's rmse: 1.44947\tvalid_1's rmse: 1.53405\n",
      "[2200]\ttraining's rmse: 1.44598\tvalid_1's rmse: 1.53398\n",
      "[2300]\ttraining's rmse: 1.44248\tvalid_1's rmse: 1.53395\n",
      "[2400]\ttraining's rmse: 1.43906\tvalid_1's rmse: 1.53383\n",
      "[2500]\ttraining's rmse: 1.43567\tvalid_1's rmse: 1.53377\n",
      "[2600]\ttraining's rmse: 1.43226\tvalid_1's rmse: 1.53375\n",
      "[2700]\ttraining's rmse: 1.42899\tvalid_1's rmse: 1.53374\n",
      "[2800]\ttraining's rmse: 1.42569\tvalid_1's rmse: 1.53365\n",
      "[2900]\ttraining's rmse: 1.42248\tvalid_1's rmse: 1.53365\n",
      "[3000]\ttraining's rmse: 1.41915\tvalid_1's rmse: 1.53363\n",
      "Early stopping, best iteration is:\n",
      "[2944]\ttraining's rmse: 1.42101\tvalid_1's rmse: 1.53359\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62012\tvalid_1's rmse: 1.61809\n",
      "[200]\ttraining's rmse: 1.58045\tvalid_1's rmse: 1.58311\n",
      "[300]\ttraining's rmse: 1.55787\tvalid_1's rmse: 1.56537\n",
      "[400]\ttraining's rmse: 1.54265\tvalid_1's rmse: 1.55508\n",
      "[500]\ttraining's rmse: 1.53131\tvalid_1's rmse: 1.54854\n",
      "[600]\ttraining's rmse: 1.52216\tvalid_1's rmse: 1.54412\n",
      "[700]\ttraining's rmse: 1.51443\tvalid_1's rmse: 1.54123\n",
      "[800]\ttraining's rmse: 1.50767\tvalid_1's rmse: 1.53908\n",
      "[900]\ttraining's rmse: 1.50153\tvalid_1's rmse: 1.5376\n",
      "[1000]\ttraining's rmse: 1.49591\tvalid_1's rmse: 1.53658\n",
      "[1100]\ttraining's rmse: 1.49067\tvalid_1's rmse: 1.53586\n",
      "[1200]\ttraining's rmse: 1.48567\tvalid_1's rmse: 1.53523\n",
      "[1300]\ttraining's rmse: 1.48097\tvalid_1's rmse: 1.53488\n",
      "[1400]\ttraining's rmse: 1.47658\tvalid_1's rmse: 1.53454\n",
      "[1500]\ttraining's rmse: 1.47234\tvalid_1's rmse: 1.53429\n",
      "[1600]\ttraining's rmse: 1.46827\tvalid_1's rmse: 1.53414\n",
      "[1700]\ttraining's rmse: 1.46439\tvalid_1's rmse: 1.53397\n",
      "[1800]\ttraining's rmse: 1.46055\tvalid_1's rmse: 1.53387\n",
      "[1900]\ttraining's rmse: 1.45678\tvalid_1's rmse: 1.53384\n",
      "[2000]\ttraining's rmse: 1.45312\tvalid_1's rmse: 1.53378\n",
      "[2100]\ttraining's rmse: 1.44952\tvalid_1's rmse: 1.53371\n",
      "[2200]\ttraining's rmse: 1.446\tvalid_1's rmse: 1.53373\n",
      "Early stopping, best iteration is:\n",
      "[2118]\ttraining's rmse: 1.4489\tvalid_1's rmse: 1.53369\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61628\tvalid_1's rmse: 1.63267\n",
      "[200]\ttraining's rmse: 1.57673\tvalid_1's rmse: 1.59722\n",
      "[300]\ttraining's rmse: 1.55442\tvalid_1's rmse: 1.57926\n",
      "[400]\ttraining's rmse: 1.53938\tvalid_1's rmse: 1.56874\n",
      "[500]\ttraining's rmse: 1.52823\tvalid_1's rmse: 1.56199\n",
      "[600]\ttraining's rmse: 1.51923\tvalid_1's rmse: 1.55739\n",
      "[700]\ttraining's rmse: 1.51153\tvalid_1's rmse: 1.55423\n",
      "[800]\ttraining's rmse: 1.50483\tvalid_1's rmse: 1.55199\n",
      "[900]\ttraining's rmse: 1.49878\tvalid_1's rmse: 1.55034\n",
      "[1000]\ttraining's rmse: 1.49317\tvalid_1's rmse: 1.54909\n",
      "[1100]\ttraining's rmse: 1.48799\tvalid_1's rmse: 1.54826\n",
      "[1200]\ttraining's rmse: 1.48311\tvalid_1's rmse: 1.54762\n",
      "[1300]\ttraining's rmse: 1.47854\tvalid_1's rmse: 1.54716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\ttraining's rmse: 1.47402\tvalid_1's rmse: 1.54677\n",
      "[1500]\ttraining's rmse: 1.46978\tvalid_1's rmse: 1.54653\n",
      "[1600]\ttraining's rmse: 1.46567\tvalid_1's rmse: 1.5463\n",
      "[1700]\ttraining's rmse: 1.4617\tvalid_1's rmse: 1.54619\n",
      "[1800]\ttraining's rmse: 1.45779\tvalid_1's rmse: 1.54614\n",
      "[1900]\ttraining's rmse: 1.454\tvalid_1's rmse: 1.54611\n",
      "[2000]\ttraining's rmse: 1.45029\tvalid_1's rmse: 1.54603\n",
      "[2100]\ttraining's rmse: 1.44673\tvalid_1's rmse: 1.54594\n",
      "[2200]\ttraining's rmse: 1.44315\tvalid_1's rmse: 1.54593\n",
      "[2300]\ttraining's rmse: 1.43963\tvalid_1's rmse: 1.54585\n",
      "[2400]\ttraining's rmse: 1.43614\tvalid_1's rmse: 1.54588\n",
      "Early stopping, best iteration is:\n",
      "[2314]\ttraining's rmse: 1.43915\tvalid_1's rmse: 1.54583\n",
      "fold n°6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61936\tvalid_1's rmse: 1.61665\n",
      "[200]\ttraining's rmse: 1.57937\tvalid_1's rmse: 1.58285\n",
      "[300]\ttraining's rmse: 1.55684\tvalid_1's rmse: 1.56634\n",
      "[400]\ttraining's rmse: 1.54162\tvalid_1's rmse: 1.55674\n",
      "[500]\ttraining's rmse: 1.53023\tvalid_1's rmse: 1.5507\n",
      "[600]\ttraining's rmse: 1.52104\tvalid_1's rmse: 1.54672\n",
      "[700]\ttraining's rmse: 1.51333\tvalid_1's rmse: 1.54388\n",
      "[800]\ttraining's rmse: 1.50661\tvalid_1's rmse: 1.54201\n",
      "[900]\ttraining's rmse: 1.50059\tvalid_1's rmse: 1.54068\n",
      "[1000]\ttraining's rmse: 1.49502\tvalid_1's rmse: 1.53963\n",
      "[1100]\ttraining's rmse: 1.48981\tvalid_1's rmse: 1.53901\n",
      "[1200]\ttraining's rmse: 1.48484\tvalid_1's rmse: 1.53847\n",
      "[1300]\ttraining's rmse: 1.4802\tvalid_1's rmse: 1.53801\n",
      "[1400]\ttraining's rmse: 1.4758\tvalid_1's rmse: 1.53764\n",
      "[1500]\ttraining's rmse: 1.47152\tvalid_1's rmse: 1.53743\n",
      "[1600]\ttraining's rmse: 1.46743\tvalid_1's rmse: 1.53731\n",
      "[1700]\ttraining's rmse: 1.46354\tvalid_1's rmse: 1.53715\n",
      "[1800]\ttraining's rmse: 1.45967\tvalid_1's rmse: 1.53704\n",
      "[1900]\ttraining's rmse: 1.45584\tvalid_1's rmse: 1.53695\n",
      "[2000]\ttraining's rmse: 1.45213\tvalid_1's rmse: 1.53686\n",
      "[2100]\ttraining's rmse: 1.44859\tvalid_1's rmse: 1.53674\n",
      "[2200]\ttraining's rmse: 1.445\tvalid_1's rmse: 1.53667\n",
      "[2300]\ttraining's rmse: 1.44152\tvalid_1's rmse: 1.53657\n",
      "[2400]\ttraining's rmse: 1.43801\tvalid_1's rmse: 1.53654\n",
      "[2500]\ttraining's rmse: 1.43459\tvalid_1's rmse: 1.53649\n",
      "[2600]\ttraining's rmse: 1.43121\tvalid_1's rmse: 1.53649\n",
      "Early stopping, best iteration is:\n",
      "[2515]\ttraining's rmse: 1.43409\tvalid_1's rmse: 1.53647\n",
      "fold n°7\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.6184\tvalid_1's rmse: 1.62433\n",
      "[200]\ttraining's rmse: 1.57883\tvalid_1's rmse: 1.58855\n",
      "[300]\ttraining's rmse: 1.55636\tvalid_1's rmse: 1.57038\n",
      "[400]\ttraining's rmse: 1.54125\tvalid_1's rmse: 1.55994\n",
      "[500]\ttraining's rmse: 1.53002\tvalid_1's rmse: 1.55347\n",
      "[600]\ttraining's rmse: 1.52095\tvalid_1's rmse: 1.54918\n",
      "[700]\ttraining's rmse: 1.51319\tvalid_1's rmse: 1.54626\n",
      "[800]\ttraining's rmse: 1.50649\tvalid_1's rmse: 1.54421\n",
      "[900]\ttraining's rmse: 1.50041\tvalid_1's rmse: 1.54286\n",
      "[1000]\ttraining's rmse: 1.49482\tvalid_1's rmse: 1.5418\n",
      "[1100]\ttraining's rmse: 1.48961\tvalid_1's rmse: 1.54104\n",
      "[1200]\ttraining's rmse: 1.4847\tvalid_1's rmse: 1.54044\n",
      "[1300]\ttraining's rmse: 1.48009\tvalid_1's rmse: 1.54006\n",
      "[1400]\ttraining's rmse: 1.47561\tvalid_1's rmse: 1.5398\n",
      "[1500]\ttraining's rmse: 1.47143\tvalid_1's rmse: 1.53952\n",
      "[1600]\ttraining's rmse: 1.46735\tvalid_1's rmse: 1.53929\n",
      "[1700]\ttraining's rmse: 1.46343\tvalid_1's rmse: 1.53921\n",
      "[1800]\ttraining's rmse: 1.45959\tvalid_1's rmse: 1.53906\n",
      "[1900]\ttraining's rmse: 1.45591\tvalid_1's rmse: 1.53897\n",
      "[2000]\ttraining's rmse: 1.45219\tvalid_1's rmse: 1.53897\n",
      "Early stopping, best iteration is:\n",
      "[1917]\ttraining's rmse: 1.45523\tvalid_1's rmse: 1.53895\n",
      "fold n°8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61793\tvalid_1's rmse: 1.62394\n",
      "[200]\ttraining's rmse: 1.57815\tvalid_1's rmse: 1.58951\n",
      "[300]\ttraining's rmse: 1.55556\tvalid_1's rmse: 1.57198\n",
      "[400]\ttraining's rmse: 1.54054\tvalid_1's rmse: 1.56194\n",
      "[500]\ttraining's rmse: 1.52927\tvalid_1's rmse: 1.55557\n",
      "[600]\ttraining's rmse: 1.52025\tvalid_1's rmse: 1.55137\n",
      "[700]\ttraining's rmse: 1.51257\tvalid_1's rmse: 1.54834\n",
      "[800]\ttraining's rmse: 1.50592\tvalid_1's rmse: 1.54631\n",
      "[900]\ttraining's rmse: 1.49988\tvalid_1's rmse: 1.54486\n",
      "[1000]\ttraining's rmse: 1.49435\tvalid_1's rmse: 1.54378\n",
      "[1100]\ttraining's rmse: 1.48917\tvalid_1's rmse: 1.54299\n",
      "[1200]\ttraining's rmse: 1.4843\tvalid_1's rmse: 1.54233\n",
      "[1300]\ttraining's rmse: 1.47969\tvalid_1's rmse: 1.54189\n",
      "[1400]\ttraining's rmse: 1.47523\tvalid_1's rmse: 1.54154\n",
      "[1500]\ttraining's rmse: 1.47097\tvalid_1's rmse: 1.54124\n",
      "[1600]\ttraining's rmse: 1.46691\tvalid_1's rmse: 1.54107\n",
      "[1700]\ttraining's rmse: 1.4629\tvalid_1's rmse: 1.5409\n",
      "[1800]\ttraining's rmse: 1.45898\tvalid_1's rmse: 1.54074\n",
      "[1900]\ttraining's rmse: 1.45529\tvalid_1's rmse: 1.54064\n",
      "[2000]\ttraining's rmse: 1.45159\tvalid_1's rmse: 1.54052\n",
      "[2100]\ttraining's rmse: 1.44803\tvalid_1's rmse: 1.54045\n",
      "[2200]\ttraining's rmse: 1.44441\tvalid_1's rmse: 1.54038\n",
      "[2300]\ttraining's rmse: 1.44092\tvalid_1's rmse: 1.54032\n",
      "[2400]\ttraining's rmse: 1.43744\tvalid_1's rmse: 1.54031\n",
      "[2500]\ttraining's rmse: 1.43396\tvalid_1's rmse: 1.5403\n",
      "[2600]\ttraining's rmse: 1.43063\tvalid_1's rmse: 1.54026\n",
      "[2700]\ttraining's rmse: 1.42735\tvalid_1's rmse: 1.54027\n",
      "Early stopping, best iteration is:\n",
      "[2603]\ttraining's rmse: 1.43053\tvalid_1's rmse: 1.54025\n",
      "fold n°9\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.619\tvalid_1's rmse: 1.62039\n",
      "[200]\ttraining's rmse: 1.57921\tvalid_1's rmse: 1.58637\n",
      "[300]\ttraining's rmse: 1.55656\tvalid_1's rmse: 1.56917\n",
      "[400]\ttraining's rmse: 1.5414\tvalid_1's rmse: 1.55914\n",
      "[500]\ttraining's rmse: 1.53003\tvalid_1's rmse: 1.55267\n",
      "[600]\ttraining's rmse: 1.52091\tvalid_1's rmse: 1.54829\n",
      "[700]\ttraining's rmse: 1.51314\tvalid_1's rmse: 1.54525\n",
      "[800]\ttraining's rmse: 1.50634\tvalid_1's rmse: 1.54313\n",
      "[900]\ttraining's rmse: 1.50025\tvalid_1's rmse: 1.54154\n",
      "[1000]\ttraining's rmse: 1.49461\tvalid_1's rmse: 1.54041\n",
      "[1100]\ttraining's rmse: 1.48927\tvalid_1's rmse: 1.53959\n",
      "[1200]\ttraining's rmse: 1.48436\tvalid_1's rmse: 1.53893\n",
      "[1300]\ttraining's rmse: 1.47968\tvalid_1's rmse: 1.5384\n",
      "[1400]\ttraining's rmse: 1.47523\tvalid_1's rmse: 1.53803\n",
      "[1500]\ttraining's rmse: 1.47086\tvalid_1's rmse: 1.53774\n",
      "[1600]\ttraining's rmse: 1.46671\tvalid_1's rmse: 1.53752\n",
      "[1700]\ttraining's rmse: 1.46281\tvalid_1's rmse: 1.53735\n",
      "[1800]\ttraining's rmse: 1.45899\tvalid_1's rmse: 1.53725\n",
      "[1900]\ttraining's rmse: 1.45526\tvalid_1's rmse: 1.53716\n",
      "[2000]\ttraining's rmse: 1.45158\tvalid_1's rmse: 1.53705\n",
      "[2100]\ttraining's rmse: 1.44792\tvalid_1's rmse: 1.53696\n",
      "[2200]\ttraining's rmse: 1.44436\tvalid_1's rmse: 1.5369\n",
      "[2300]\ttraining's rmse: 1.44093\tvalid_1's rmse: 1.53686\n",
      "[2400]\ttraining's rmse: 1.43749\tvalid_1's rmse: 1.53684\n",
      "[2500]\ttraining's rmse: 1.43404\tvalid_1's rmse: 1.53685\n",
      "Early stopping, best iteration is:\n",
      "[2411]\ttraining's rmse: 1.43714\tvalid_1's rmse: 1.53682\n",
      "CV score: 1.53967 \n"
     ]
    }
   ],
   "source": [
    "lgbparam = {'num_leaves': 80,\n",
    "            'min_data_in_leaf': 100, \n",
    "            'boosting_type': 'rf',\n",
    "             'objective':'regression',\n",
    "             'max_depth': -1,\n",
    "             'learning_rate': 0.005,\n",
    "             \"min_child_samples\": 20,\n",
    "             \"boosting\": \"gbdt\",\n",
    "             \"feature_fraction\": 0.9,\n",
    "             \"bagging_freq\": 1,\n",
    "             \"bagging_fraction\": 0.9 ,\n",
    "             \"bagging_seed\": 11,\n",
    "             \"metric\": 'rmse',\n",
    "             \"lambda_l1\": 0.1,\n",
    "             \"verbosity\": -1,\n",
    "             \"nthread\": -1,\n",
    "             \"random_state\": 4590}\n",
    "\n",
    "# lgbparam = {'num_leaves': 31,\n",
    "#             'boosting_type': 'rf',\n",
    "#              'min_data_in_leaf': 30, \n",
    "#              'objective':'regression',\n",
    "#              'max_depth': -1,\n",
    "#              'learning_rate': 0.005,\n",
    "#              \"min_child_samples\": 20,\n",
    "#              \"boosting\": \"gbdt\",\n",
    "#              \"feature_fraction\": 0.9,\n",
    "#              \"bagging_freq\": 1,\n",
    "#              \"bagging_fraction\": 0.9 ,\n",
    "#              \"bagging_seed\": 11,\n",
    "#              \"metric\": 'rmse',\n",
    "#              \"lambda_l1\": 0.1,\n",
    "#              \"verbosity\": -1,\n",
    "#              \"nthread\": 4,\n",
    "#              \"random_state\": 4590} # 1.54083\n",
    "\n",
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "\n",
    "df_train = train[train['outliers'] == 0]\n",
    "df_target = target[normal_idx]\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]\n",
    "    \n",
    "normal_predictions_n_repeats_2, oof_n_repeats_2 = lgbm_regression_train_n_repeats_2(df_train, \n",
    "                                                                                    df_target, \n",
    "                                                                                    test, \n",
    "                                                                                    lgbparam, \n",
    "                                                                                    features, \n",
    "                                                                                    categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers_n_repeats_2 = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "model_without_outliers_n_repeats_2[\"target\"] = normal_predictions_n_repeats_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Training Model For Outliers Classification for 5 fold (n_repeats = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_classification_train_n_repeats_2(df_train, target, df_test, param, features, categorical_feats):\n",
    "    folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=15)\n",
    "    oof = np.zeros(len(df_train))\n",
    "    predictions = np.zeros(len(df_test))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    start = time.time()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / (5 * 2)\n",
    "        \n",
    "    print(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))\n",
    "\n",
    "    return predictions, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0451509\tvalid_1's binary_logloss: 0.0480669\n",
      "[200]\ttraining's binary_logloss: 0.0451168\tvalid_1's binary_logloss: 0.0480732\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0451386\tvalid_1's binary_logloss: 0.0480215\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0457537\tvalid_1's binary_logloss: 0.046939\n",
      "[200]\ttraining's binary_logloss: 0.0457265\tvalid_1's binary_logloss: 0.0468905\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.0456993\tvalid_1's binary_logloss: 0.0468931\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0453821\tvalid_1's binary_logloss: 0.0466012\n",
      "[200]\ttraining's binary_logloss: 0.0453995\tvalid_1's binary_logloss: 0.0465879\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0453747\tvalid_1's binary_logloss: 0.0465525\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0444893\tvalid_1's binary_logloss: 0.0512099\n",
      "[200]\ttraining's binary_logloss: 0.0444781\tvalid_1's binary_logloss: 0.0512198\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.0446097\tvalid_1's binary_logloss: 0.0511024\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.045296\tvalid_1's binary_logloss: 0.0470667\n",
      "[200]\ttraining's binary_logloss: 0.0452779\tvalid_1's binary_logloss: 0.047031\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0452333\tvalid_1's binary_logloss: 0.0469927\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0448307\tvalid_1's binary_logloss: 0.0491449\n",
      "[200]\ttraining's binary_logloss: 0.0448214\tvalid_1's binary_logloss: 0.0491739\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.0448295\tvalid_1's binary_logloss: 0.049093\n",
      "fold n°6\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0452354\tvalid_1's binary_logloss: 0.0481428\n",
      "[200]\ttraining's binary_logloss: 0.0452072\tvalid_1's binary_logloss: 0.0481364\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.0452176\tvalid_1's binary_logloss: 0.0480818\n",
      "fold n°7\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0449679\tvalid_1's binary_logloss: 0.0485653\n",
      "[200]\ttraining's binary_logloss: 0.0449779\tvalid_1's binary_logloss: 0.0485735\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.0449352\tvalid_1's binary_logloss: 0.0484912\n",
      "fold n°8\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0456344\tvalid_1's binary_logloss: 0.0453504\n",
      "[200]\ttraining's binary_logloss: 0.0455954\tvalid_1's binary_logloss: 0.0453344\n",
      "[300]\ttraining's binary_logloss: 0.04557\tvalid_1's binary_logloss: 0.0453559\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's binary_logloss: 0.0455914\tvalid_1's binary_logloss: 0.0453226\n",
      "fold n°9\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0450546\tvalid_1's binary_logloss: 0.0482166\n",
      "[200]\ttraining's binary_logloss: 0.0450469\tvalid_1's binary_logloss: 0.0482205\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's binary_logloss: 0.044958\tvalid_1's binary_logloss: 0.0480996\n",
      "CV score: 0.04782 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 51,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.001,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333}\n",
    "\n",
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "\n",
    "target = train['outliers']\n",
    "del train['outliers']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]\n",
    "outlier_label_n_repeats_2, oof_class_n_repeats_2 = lgbm_classification_train_n_repeats_2(train, \n",
    "                                                                                         target, \n",
    "                                                                                         test, \n",
    "                                                                                         param, \n",
    "                                                                                         features, \n",
    "                                                                                         categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>0.102901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>0.000779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>0.010566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>0.000679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>0.000693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab  0.102901\n",
       "1  C_ID_130fd0cbdd  0.000779\n",
       "2  C_ID_b709037bc5  0.010566\n",
       "3  C_ID_d27d835a9f  0.000679\n",
       "4  C_ID_2b5e3df5c2  0.000693"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlier_prob_n_repeats_2 = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "df_outlier_prob_n_repeats_2[\"target\"] = outlier_label_n_repeats_2\n",
    "df_outlier_prob_n_repeats_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Combining Submission for 5 fold (n_repeats = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_id_n_repeats_2 = pd.DataFrame(\\\n",
    "                                      df_outlier_prob_n_repeats_2.sort_values(by='target',\n",
    "                                                                              ascending = False)\n",
    "                                      .head(25000)['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_submission = pd.read_csv('../result/Blend2_v2.csv')\n",
    "best_submission = pd.read_csv('../result/Blend2_v10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.409111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.360448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.833417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.246980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.150486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.409111\n",
       "1  C_ID_130fd0cbdd -0.360448\n",
       "2  C_ID_b709037bc5 -0.833417\n",
       "3  C_ID_d27d835a9f -0.246980\n",
       "4  C_ID_2b5e3df5c2 -1.150486"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_submission.shape[0])\n",
    "best_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.409111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_6d8dba8475</td>\n",
       "      <td>-0.886411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_4859ac9ed5</td>\n",
       "      <td>-0.627507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_7f1041e8e1</td>\n",
       "      <td>-5.065158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_22e4a47c72</td>\n",
       "      <td>0.362193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.409111\n",
       "1  C_ID_6d8dba8475 -0.886411\n",
       "2  C_ID_4859ac9ed5 -0.627507\n",
       "3  C_ID_7f1041e8e1 -5.065158\n",
       "4  C_ID_22e4a47c72  0.362193"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outlier_id.shape[0])\n",
    "most_likely_liers_n_repeats_2 = best_submission.merge(outlier_id_n_repeats_2,how='right')\n",
    "most_likely_liers_n_repeats_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 24s, sys: 54.1 ms, total: 4min 24s\n",
      "Wall time: 4min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for card_id in most_likely_liers_n_repeats_2['card_id']:\n",
    "    model_without_outliers_n_repeats_2.loc[model_without_outliers_n_repeats_2['card_id']==card_id,'target']\\\n",
    "    = most_likely_liers_n_repeats_2.loc[most_likely_liers_n_repeats_2['card_id']==card_id,'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_without_outliers_n_repeats_2.to_csv(\"../result/Blend2_v6_n_repeats_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(model_without_outliers['target'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(model_without_outliers_n_repeats_2['target'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_n_repeats_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target.shape, len(normal_idx), len(outlier_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2dfa7a5fcabd78829678fa4283e99862f1c4a0d7"
   },
   "source": [
    "## Part 7: Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(type(target))\n",
    "# print(type(oof))\n",
    "# # print(type(oof_normal_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(outlier_idx), len(outlier_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_normal_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "    \n",
    "oof_normal_final = pd.Series(np.zeros(len(target)))\n",
    "oof_normal_final[normal_idx] = oof\n",
    "oof_normal_final[outlier_idx] = outlier_idx\n",
    "\n",
    "oof_n_repeats_2_final = pd.Series(np.zeros(len(target)))\n",
    "oof_n_repeats_2_final[normal_idx] = oof_n_repeats_2\n",
    "oof_n_repeats_2_final[outlier_idx] = outlier_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "8c9afce8b59b5f51024150a997a9d2eb702ab85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "----------Stacking 0----------\n",
      "fold n°1\n",
      "----------Stacking 1----------\n",
      "fold n°2\n",
      "----------Stacking 2----------\n",
      "fold n°3\n",
      "----------Stacking 3----------\n",
      "fold n°4\n",
      "----------Stacking 4----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.464877040274838"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack = np.vstack([oof_normal_final,oof_n_repeats_2_final]).transpose()\n",
    "test_stack = np.vstack([model_without_outliers['target'].values.tolist(),\n",
    "                        model_without_outliers_n_repeats_2['target'].values.tolist()]).transpose()\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5,n_repeats=1,random_state=4520)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions_stack = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_stack, target)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "\n",
    "    print(\"-\" * 10 + \"Stacking \" + str(fold_) + \"-\" * 10)\n",
    "#     cb_model = CatBoostRegressor(iterations=3000, learning_rate=0.1, depth=8, l2_leaf_reg=20, bootstrap_type='Bernoulli',  eval_metric='RMSE', metric_period=50, od_type='Iter', od_wait=45, random_seed=17, allow_writing_files=False)\n",
    "#     cb_model.fit(trn_data, trn_y, eval_set=(val_data, val_y), cat_features=[], use_best_model=True, verbose=True)\n",
    "    clf = BayesianRidge()\n",
    "    clf.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf.predict(val_data)\n",
    "    predictions_stack += clf.predict(test_stack) / 5\n",
    "\n",
    "\n",
    "np.sqrt(mean_squared_error(target.values, oof_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "e871862de58a3ce43c148f78f152c1d6385a0a08"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample_submission['target'] = predictions_stack\n",
    "sample_submission.to_csv('../result/Bayesian_Ridge_Stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "b65e47686b49b31f0dc47171ab2aece4a4d0a941"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample1 = pd.read_csv(\"../result/3.695.csv\")\n",
    "sample2 = pd.read_csv(\"../result/combining_submission (1).csv\")\n",
    "sample3 = pd.read_csv(\"../result/single_model_v13_final.csv\")\n",
    "sample4 = pd.read_csv(\"../result/cttsai_simple_lgbm_cv_bagging_cv_3.648358_lb_3.691.csv\")\n",
    "sample_submission['target'] = model_without_outliers['target'] * 0.5 + model_without_outliers_n_repeats_2['target'] * 0.5\n",
    "sample_submission.to_csv(\"../result/3_step_model_final_v11.csv\", index = False)\n",
    "# sample_submission['target'] = sample_submission['target'] * 0.2 + sample1['target'] * 0.2 + sample2['target'] * 0.6\n",
    "# sample_submission['target'] = sample_submission['target'] * 0.6 + sample1['target'] * 0.2 + sample2['target'] * 0.2\n",
    "# sample_submission['target'] = sample_submission['target'] / 2 + sample3['target'] / 2\n",
    "sample_submission['target'] = sample_submission['target'] / 3 + sample3['target'] / 3 + sample4['target'] / 3\n",
    "# sample_submission.to_csv('../result/special_blend_v3.csv', index=False)\n",
    "sample_submission.to_csv('../result/special_blending_v5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`special_blending_v5.csv` got the best submission score so far - 3.686."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "1259px",
    "right": "20px",
    "top": "14px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
