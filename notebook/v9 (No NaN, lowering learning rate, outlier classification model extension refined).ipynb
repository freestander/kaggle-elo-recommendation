{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a9ef20fd4e6471fd2c9e3022edfdddc07a970aca"
   },
   "source": [
    "## P.S. The main idea behind this notebook is inspired from FabienDaniel Kernel Elo_world.\n",
    "https://www.kaggle.com/fabiendaniel/elo-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50e1f88df96b5e525237fe120650e679b7f60654"
   },
   "outputs": [],
   "source": [
    "# new_transactions = pd.read_csv('../input/elo-merchant-category-recommendation/new_merchant_transactions.csv', parse_dates=['purchase_date'])\n",
    "# historical_transactions = pd.read_csv('../input/elo-merchant-category-recommendation/historical_transactions.csv', parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_parquet('../input/hist_trans_df.parquet.gzip')\n",
    "new_transactions = pd.read_parquet('../input/new_trans_df.parquet.gzip')\n",
    "\n",
    "def binarize(df):\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y':1, 'N':0})\n",
    "    return df\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a940a9ce940fa489a5a5255f6d4523c9b7c3ffdc"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# def read_data(input_file):\n",
    "#     df = pd.read_csv(input_file)\n",
    "#     df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "#     df['elapsed_time'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days\n",
    "#     return df\n",
    "\n",
    "# train = read_data('../input/elo-merchant-category-recommendation/train.csv')\n",
    "# test = read_data('../input/elo-merchant-category-recommendation/test.csv')\n",
    "\n",
    "def read_data_v2(input_file):\n",
    "    df = pd.read_parquet(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days\n",
    "    return df\n",
    "\n",
    "train = read_data_v2('../input/train_df.parquet.gzip')\n",
    "test = read_data_v2('../input/test_df.parquet.gzip')\n",
    "\n",
    "target = train['target']\n",
    "del train['target']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd9f71f39664eef55e0b3ec3e6172e84a8e1a963"
   },
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_opt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_1\"] += 1\n",
    "historical_transactions[\"category_1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_1\"] += 1\n",
    "new_transactions[\"category_1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_2\"] = historical_transactions[\"category_2\"].fillna(0)\n",
    "historical_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_2\"] = new_transactions[\"category_2\"].fillna(0)\n",
    "new_transactions[\"category_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions[\"category_3\"] = historical_transactions[\"category_3\"].replace({'A': 1, 'B': 2, 'C': 3, None: 0})\n",
    "historical_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions[\"category_3\"] = new_transactions[\"category_3\"].replace({'A': 1, 'B': 2, 'C': 3, None: 0})\n",
    "new_transactions[\"category_3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions[\"category_1_2_cross\"] = historical_transactions[\"category_1\"]*2 + historical_transactions[\"category_2\"]\n",
    "# np.sort(historical_transactions[\"category_1_2_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(new_transactions[\"category_1\"], new_transactions[\"category_2\"])\n",
    "#     plt.xlabel(\"category_1\")\n",
    "#     plt.ylabel(\"category_2\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_transactions[\"category_1_2_cross\"] = new_transactions[\"category_1\"]*2 + new_transactions[\"category_2\"]\n",
    "# np.sort(new_transactions[\"category_1_2_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(historical_transactions[\"category_1\"]+2, historical_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_1\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions[\"category_1_3_cross\"] = (historical_transactions[\"category_1\"]+2) * historical_transactions[\"category_3\"]\n",
    "# np.sort(historical_transactions[\"category_1_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(new_transactions[\"category_1\"], new_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_1\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_transactions[\"category_1_3_cross\"] = (new_transactions[\"category_1\"]+2) * new_transactions[\"category_3\"]\n",
    "# np.sort(new_transactions[\"category_1_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(historical_transactions[\"category_2\"]+6, historical_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_2\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions[\"category_2_3_cross\"] = (historical_transactions[\"category_2\"]+6) * historical_transactions[\"category_3\"]\n",
    "# np.sort(historical_transactions[\"category_2_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if plot_opt:\n",
    "#     plt.scatter(new_transactions[\"category_2\"]+6, new_transactions[\"category_3\"])\n",
    "#     plt.xlabel(\"category_2\")\n",
    "#     plt.ylabel(\"category_3\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_transactions[\"category_2_3_cross\"] = (new_transactions[\"category_2\"]+6) * new_transactions[\"category_3\"]\n",
    "# np.sort(new_transactions[\"category_2_3_cross\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def category_make_cross_feat(df):\n",
    "    df[\"category_1_3_cross\"] = (df[\"category_1\"]+2) * df[\"category_3\"]\n",
    "    df[\"category_2_3_cross\"] = (df[\"category_2\"]+6) * df[\"category_3\"]\n",
    "    return df\n",
    "\n",
    "historical_transactions = category_make_cross_feat(historical_transactions)\n",
    "new_transactions = category_make_cross_feat(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "170f0e959ba5250b191b7cee6b586bdabd347018"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "historical_transactions = pd.get_dummies(historical_transactions, columns=['category_2', \n",
    "                                                                           'category_3',\n",
    "                                                                           'category_1_3_cross',\n",
    "                                                                           'category_2_3_cross'])\n",
    "new_transactions = pd.get_dummies(new_transactions, columns=['category_2', \n",
    "                                                             'category_3',\n",
    "                                                             'category_1_3_cross',\n",
    "                                                             'category_2_3_cross'])\n",
    "\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)\n",
    "\n",
    "agg_fun = {'authorized_flag': ['sum', 'mean', 'min', 'std', 'count']} # max is all 1's, useless\n",
    "auth_mean = historical_transactions.groupby(['card_id']).agg(agg_fun)\n",
    "auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns.values]\n",
    "auth_mean.reset_index(inplace=True)\n",
    "\n",
    "authorized_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 0]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90536f89e81fc4bb7f45a17f47e4b627f53e69b4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "historical_transactions['purchase_month'] = historical_transactions['purchase_date'].dt.month\n",
    "authorized_transactions['purchase_month'] = authorized_transactions['purchase_date'].dt.month\n",
    "new_transactions['purchase_month'] = new_transactions['purchase_date'].dt.month\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5de9c3bcc2ad2dfeb943e1b02fef3e433c91af3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def aggregate_transactions(history):\n",
    "    \n",
    "    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).\\\n",
    "                                      astype(np.int64) * 1e-9\n",
    "    \n",
    "    agg_func = {\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'category_2_1.0': ['mean'],\n",
    "        'category_2_2.0': ['mean'],\n",
    "        'category_2_3.0': ['mean'],\n",
    "        'category_2_4.0': ['mean'],\n",
    "        'category_2_5.0': ['mean'],\n",
    "        'category_3_1': ['mean'],\n",
    "        'category_3_2': ['mean'],\n",
    "        'category_3_3': ['mean'],\n",
    "        'category_1_3_cross_3': ['mean'],\n",
    "        'category_1_3_cross_4': ['mean'],\n",
    "        'category_1_3_cross_6': ['mean'],\n",
    "        'category_1_3_cross_8': ['mean'],\n",
    "        'category_1_3_cross_9': ['mean'],\n",
    "        'category_1_3_cross_12': ['mean'],\n",
    "        'category_2_3_cross_7.0': ['mean'],\n",
    "        'category_2_3_cross_8.0': ['mean'],\n",
    "        'category_2_3_cross_9.0': ['mean'],\n",
    "        'category_2_3_cross_10.0': ['mean'],\n",
    "        'category_2_3_cross_11.0': ['mean'],\n",
    "        'category_2_3_cross_12.0': ['mean'],\n",
    "        'category_2_3_cross_14.0': ['mean'],\n",
    "        'category_2_3_cross_16.0': ['mean'],\n",
    "        'category_2_3_cross_20.0': ['mean'],\n",
    "        'category_2_3_cross_21.0': ['mean'],\n",
    "        'category_2_3_cross_22.0': ['mean'],\n",
    "        'category_2_3_cross_24.0': ['mean'],\n",
    "        'category_2_3_cross_27.0': ['mean'],\n",
    "        'category_2_3_cross_30.0': ['mean'],\n",
    "        'category_2_3_cross_33.0': ['mean'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'state_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std', 'count'], #one count is enough, others are just the same\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'purchase_month': ['mean', 'max', 'min', 'std'],\n",
    "        'purchase_date': [np.ptp, 'min', 'max'],\n",
    "        'month_lag': ['min', 'max']\n",
    "        }\n",
    "    \n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "    \n",
    "    df = (history.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='transactions_count'))\n",
    "    \n",
    "    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n",
    "    \n",
    "    return agg_history\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf1f963f61841ef34f79fd16364bbf59b7f4e8a4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = aggregate_transactions(historical_transactions)\n",
    "history.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n",
    "history[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # history[[\"hist_purchase_amount_count\", \"hist_installments_count\", \"hist_purchase_month_count\"]].head(500)\n",
    "# history.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c1bdbaa7c16e22436893354b31d47e1846330ab"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "authorized = aggregate_transactions(authorized_transactions)\n",
    "authorized.columns = ['auth_' + c if c != 'card_id' else c for c in authorized.columns]\n",
    "authorized[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cc2775c29c17cb7438f3f5c45777b894afa94fc"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "new = aggregate_transactions(new_transactions)\n",
    "new.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n",
    "new[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb443fb1e2a47f5a0bef02921a2cba1d4e95e673"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def aggregate_per_month(history):\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "\n",
    "    agg_func = {\n",
    "#             'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "#             'installments': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "            'purchase_amount': ['count', 'sum'],\n",
    "            'installments': ['count', 'sum'],\n",
    "            }\n",
    "\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True)\n",
    "    \n",
    "    return final_group\n",
    "#___________________________________________________________\n",
    "final_group =  aggregate_per_month(historical_transactions) \n",
    "final_group[:10]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e5e313f605160783127a6f0798f176eaf6a55a4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.merge(train, history, on='card_id', how='left')\n",
    "test = pd.merge(test, history, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, authorized, on='card_id', how='left')\n",
    "test = pd.merge(test, authorized, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, new, on='card_id', how='left')\n",
    "test = pd.merge(test, new, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, final_group, on='card_id', how='left')\n",
    "test = pd.merge(test, final_group, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, auth_mean, on='card_id', how='left')\n",
    "test = pd.merge(test, auth_mean, on='card_id', how='left')\n",
    "\n",
    "print(\"Train Shape:\", train.shape)\n",
    "print(\"Test Shape:\", test.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feat(df):\n",
    "    # Feature crosses\n",
    "    df[\"feature_1_2_cross\"] = df[\"feature_1\"] + (df[\"feature_2\"]-1)*5\n",
    "    df[\"feature_1_3_cross\"] = df[\"feature_1\"] + df[\"feature_3\"]*3\n",
    "    df[\"feature_2_3_cross\"] = df[\"feature_2\"] + df[\"feature_3\"]*3\n",
    "    df = pd.get_dummies(df, columns=[\"feature_1_2_cross\", \"feature_1_3_cross\", \"feature_2_3_cross\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = generate_feat(train)\n",
    "test = generate_feat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_2_3_feat(df, feat_list):\n",
    "    for feat in feat_list:\n",
    "        df[feat+\"_power2\"] = df[feat]**2\n",
    "#         df[feat+\"_power3\"] = df[feat]**3\n",
    "    return df\n",
    "\n",
    "feat_list = [\"elapsed_time\", \"hist_purchase_date_ptp\"]\n",
    "train = power_2_3_feat(train, feat_list)\n",
    "test = power_2_3_feat(test, feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_feat(df, feat_list):\n",
    "    for feat in feat_list:\n",
    "        df[feat+\"_log\"] = np.log(df[feat])\n",
    "#         df[feat+\"_power3\"] = df[feat]**3\n",
    "    return df\n",
    "\n",
    "feat_list = [\"elapsed_time\"]\n",
    "train = log_feat(train, feat_list)\n",
    "test = log_feat(test, feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(100, 100))\n",
    "sns.heatmap(corrmat, vmax=1.0, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig(\"../img/corr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_feat_list = ['authorized_flag_min', \n",
    "                    'hist_purchase_amount_sum',\n",
    "                    'hist_purchase_amount_max',\n",
    "                    'hist_purchase_amount_min',\n",
    "                    'hist_purchase_amount_std',\n",
    "                    'hist_installments_sum',\n",
    "                    'hist_installments_max',\n",
    "                    'hist_installments_min',\n",
    "                    'hist_installments_std',\n",
    "                   ]\n",
    "train = train.drop(remove_feat_list, axis=1)\n",
    "test = test.drop(remove_feat_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(100, 100))\n",
    "sns.heatmap(corrmat, vmax=1.0, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig(\"../img/corr_after_feat_removal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../input/feat_list.pkl', 'rb') as f:\n",
    "#     feat_list = pickle.load(f)\n",
    "\n",
    "# train = train[feat_list]\n",
    "# test = test[feat_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target.pkl', 'wb') as f:\n",
    "    pickle.dump([train, target, test], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target.pkl', 'rb') as f:\n",
    "    [train, target, test] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n",
    "# saleprice correlation matrix\n",
    "\n",
    "# k = train.shape[1] #number of variables for heatmap\n",
    "# cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "# cm = np.corrcoef(df_train[cols].values.T)\n",
    "# sns.set(font_scale=1.25)\n",
    "# hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #scatterplot\n",
    "# sns.set()\n",
    "# # cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "# # sns.pairplot(df_train[cols], size = 2.5)\n",
    "# sns.pairplot(train, size = 2.5)\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,160))\n",
    "sns.distplot(target.values, bins=50, kde=False, color='blue')\n",
    "plt.title('Histogram of Loyalty Score before removal')\n",
    "plt.xlabel('Loyalty score', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "sns.distplot(target, fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(target, plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n",
    "print(\"Skewness: %f\" % pd.DataFrame(target).skew())\n",
    "print(\"Kurtosis: %f\" % pd.DataFrame(target).kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_target = min(value for value in target if value > -20)\n",
    "min_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_between_20_30 = [value for value in target if value >= -30 and value <=-20]\n",
    "len(idx_between_20_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_lessThan_30 = [value for value in target if value < -30]\n",
    "len(idx_lessThan_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/nottold/naive-ensemble-model-ridge-lasso\n",
    "class OutlierDetection(BaseEstimator):\n",
    "    def __init__(self, alpha, dims, std, mean, median):\n",
    "        self.alpha = alpha\n",
    "        self.dims = dims\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        self.median = median\n",
    "    def fit(self, X):\n",
    "        # std, mean, median = X.std(), X.mean(), X.median()\n",
    "        X[\"outliers\"] = 0\n",
    "        for col in X.columns:\n",
    "#             print(col)\n",
    "            if not col == \"outliers\":\n",
    "                # outlier_idx = (abs(X[col]) > (self.alpha * std[col] + mean[col]))\n",
    "                outlier_idx = (np.abs(X[col]) > (self.alpha * self.std[col] + self.mean[col]))\n",
    "                X.set_value(outlier_idx, \"outliers\", X[outlier_idx][\"outliers\"] + 1)\n",
    "        outliers = X[X[\"outliers\"] > self.dims]\n",
    "        X.drop(\"outliers\", axis=1, inplace=True)\n",
    "        outlier_idx = outliers.index.tolist()\n",
    "        # return outliers.index\n",
    "        return set(list(range(X.shape[0]))) - set(outlier_idx), outlier_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.DataFrame(target)\n",
    "\n",
    "outlier_removal = OutlierDetection(alpha=3, \n",
    "                                   dims=0, \n",
    "                                   std=target_df.std().astype('float'), \n",
    "                                   mean=target_df.mean().astype('float'), \n",
    "                                   median=target_df.median().astype('float'))\n",
    "normal_idx, outlier_idx = outlier_removal.fit(target_df)\n",
    "# samples = target_df.shape[0] - len(outlier)\n",
    "# xtrain = xtrain.drop(outlier_index).reset_index(drop=True)\n",
    "# y = y.drop(outlier_index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "796d4e17b4c4cc3121fc833669fc2eaf07bf4fba"
   },
   "outputs": [],
   "source": [
    "train[\"outliers\"] = 0\n",
    "train.at[outlier_idx, \"outliers\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"outliers\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'wb') as f:\n",
    "    pickle.dump([train, target, test, normal_idx, outlier_idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Model Without Outliers for 5 fold (n_repeats = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train[train['outliers'] == 0]\n",
    "df_target = target[normal_idx]\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199644, 208), (199644,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_regression_train(train, target, test, param, features, categorical_feats):\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))\n",
    "    return predictions, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62527\tvalid_1's rmse: 1.64356\n",
      "[200]\ttraining's rmse: 1.59162\tvalid_1's rmse: 1.61246\n",
      "[300]\ttraining's rmse: 1.57277\tvalid_1's rmse: 1.59586\n",
      "[400]\ttraining's rmse: 1.56033\tvalid_1's rmse: 1.58544\n",
      "[500]\ttraining's rmse: 1.55141\tvalid_1's rmse: 1.57839\n",
      "[600]\ttraining's rmse: 1.54427\tvalid_1's rmse: 1.57304\n",
      "[700]\ttraining's rmse: 1.53858\tvalid_1's rmse: 1.56906\n",
      "[800]\ttraining's rmse: 1.53387\tvalid_1's rmse: 1.56623\n",
      "[900]\ttraining's rmse: 1.52979\tvalid_1's rmse: 1.56395\n",
      "[1000]\ttraining's rmse: 1.52614\tvalid_1's rmse: 1.56218\n",
      "[1100]\ttraining's rmse: 1.52288\tvalid_1's rmse: 1.56074\n",
      "[1200]\ttraining's rmse: 1.5199\tvalid_1's rmse: 1.55964\n",
      "[1300]\ttraining's rmse: 1.51711\tvalid_1's rmse: 1.55868\n",
      "[1400]\ttraining's rmse: 1.51455\tvalid_1's rmse: 1.55791\n",
      "[1500]\ttraining's rmse: 1.51211\tvalid_1's rmse: 1.55729\n",
      "[1600]\ttraining's rmse: 1.50982\tvalid_1's rmse: 1.5568\n",
      "[1700]\ttraining's rmse: 1.50761\tvalid_1's rmse: 1.55641\n",
      "[1800]\ttraining's rmse: 1.50546\tvalid_1's rmse: 1.55604\n",
      "[1900]\ttraining's rmse: 1.50343\tvalid_1's rmse: 1.55572\n",
      "[2000]\ttraining's rmse: 1.50146\tvalid_1's rmse: 1.55548\n",
      "[2100]\ttraining's rmse: 1.49951\tvalid_1's rmse: 1.55531\n",
      "[2200]\ttraining's rmse: 1.49763\tvalid_1's rmse: 1.55511\n",
      "[2300]\ttraining's rmse: 1.49568\tvalid_1's rmse: 1.55487\n",
      "[2400]\ttraining's rmse: 1.49383\tvalid_1's rmse: 1.55469\n",
      "[2500]\ttraining's rmse: 1.49203\tvalid_1's rmse: 1.55456\n",
      "[2600]\ttraining's rmse: 1.49024\tvalid_1's rmse: 1.55442\n",
      "[2700]\ttraining's rmse: 1.48851\tvalid_1's rmse: 1.55432\n",
      "[2800]\ttraining's rmse: 1.48681\tvalid_1's rmse: 1.55417\n",
      "[2900]\ttraining's rmse: 1.48511\tvalid_1's rmse: 1.5541\n",
      "[3000]\ttraining's rmse: 1.48348\tvalid_1's rmse: 1.55399\n",
      "[3100]\ttraining's rmse: 1.4818\tvalid_1's rmse: 1.55389\n",
      "[3200]\ttraining's rmse: 1.48017\tvalid_1's rmse: 1.55377\n",
      "[3300]\ttraining's rmse: 1.47857\tvalid_1's rmse: 1.55369\n",
      "[3400]\ttraining's rmse: 1.47691\tvalid_1's rmse: 1.55366\n",
      "[3500]\ttraining's rmse: 1.47532\tvalid_1's rmse: 1.55357\n",
      "[3600]\ttraining's rmse: 1.47375\tvalid_1's rmse: 1.55347\n",
      "[3700]\ttraining's rmse: 1.47221\tvalid_1's rmse: 1.5534\n",
      "[3800]\ttraining's rmse: 1.47064\tvalid_1's rmse: 1.55335\n",
      "[3900]\ttraining's rmse: 1.46911\tvalid_1's rmse: 1.55331\n",
      "[4000]\ttraining's rmse: 1.46767\tvalid_1's rmse: 1.55328\n",
      "[4100]\ttraining's rmse: 1.46614\tvalid_1's rmse: 1.55327\n",
      "[4200]\ttraining's rmse: 1.4646\tvalid_1's rmse: 1.55321\n",
      "[4300]\ttraining's rmse: 1.46312\tvalid_1's rmse: 1.55317\n",
      "[4400]\ttraining's rmse: 1.46164\tvalid_1's rmse: 1.55312\n",
      "[4500]\ttraining's rmse: 1.46018\tvalid_1's rmse: 1.5531\n",
      "[4600]\ttraining's rmse: 1.45871\tvalid_1's rmse: 1.55309\n",
      "[4700]\ttraining's rmse: 1.45723\tvalid_1's rmse: 1.55306\n",
      "[4800]\ttraining's rmse: 1.45576\tvalid_1's rmse: 1.55304\n",
      "[4900]\ttraining's rmse: 1.4543\tvalid_1's rmse: 1.55302\n",
      "[5000]\ttraining's rmse: 1.45286\tvalid_1's rmse: 1.55299\n",
      "[5100]\ttraining's rmse: 1.45142\tvalid_1's rmse: 1.55297\n",
      "[5200]\ttraining's rmse: 1.44996\tvalid_1's rmse: 1.55298\n",
      "[5300]\ttraining's rmse: 1.44853\tvalid_1's rmse: 1.55296\n",
      "[5400]\ttraining's rmse: 1.44717\tvalid_1's rmse: 1.55295\n",
      "[5500]\ttraining's rmse: 1.44572\tvalid_1's rmse: 1.55292\n",
      "[5600]\ttraining's rmse: 1.4443\tvalid_1's rmse: 1.55286\n",
      "[5700]\ttraining's rmse: 1.44283\tvalid_1's rmse: 1.55284\n",
      "[5800]\ttraining's rmse: 1.44143\tvalid_1's rmse: 1.55281\n",
      "[5900]\ttraining's rmse: 1.44006\tvalid_1's rmse: 1.55284\n",
      "[6000]\ttraining's rmse: 1.43862\tvalid_1's rmse: 1.55287\n",
      "Early stopping, best iteration is:\n",
      "[5800]\ttraining's rmse: 1.44143\tvalid_1's rmse: 1.55281\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62925\tvalid_1's rmse: 1.62819\n",
      "[200]\ttraining's rmse: 1.59569\tvalid_1's rmse: 1.59625\n",
      "[300]\ttraining's rmse: 1.57748\tvalid_1's rmse: 1.57948\n",
      "[400]\ttraining's rmse: 1.565\tvalid_1's rmse: 1.56855\n",
      "[500]\ttraining's rmse: 1.55587\tvalid_1's rmse: 1.56096\n",
      "[600]\ttraining's rmse: 1.54872\tvalid_1's rmse: 1.55547\n",
      "[700]\ttraining's rmse: 1.54307\tvalid_1's rmse: 1.55156\n",
      "[800]\ttraining's rmse: 1.53836\tvalid_1's rmse: 1.54864\n",
      "[900]\ttraining's rmse: 1.53426\tvalid_1's rmse: 1.54625\n",
      "[1000]\ttraining's rmse: 1.53055\tvalid_1's rmse: 1.54437\n",
      "[1100]\ttraining's rmse: 1.52726\tvalid_1's rmse: 1.54298\n",
      "[1200]\ttraining's rmse: 1.52423\tvalid_1's rmse: 1.54192\n",
      "[1300]\ttraining's rmse: 1.52143\tvalid_1's rmse: 1.54102\n",
      "[1400]\ttraining's rmse: 1.51882\tvalid_1's rmse: 1.54027\n",
      "[1500]\ttraining's rmse: 1.51635\tvalid_1's rmse: 1.53971\n",
      "[1600]\ttraining's rmse: 1.51398\tvalid_1's rmse: 1.53929\n",
      "[1700]\ttraining's rmse: 1.51172\tvalid_1's rmse: 1.5389\n",
      "[1800]\ttraining's rmse: 1.50956\tvalid_1's rmse: 1.53853\n",
      "[1900]\ttraining's rmse: 1.50747\tvalid_1's rmse: 1.53828\n",
      "[2000]\ttraining's rmse: 1.50548\tvalid_1's rmse: 1.53804\n",
      "[2100]\ttraining's rmse: 1.50355\tvalid_1's rmse: 1.53783\n",
      "[2200]\ttraining's rmse: 1.50168\tvalid_1's rmse: 1.53767\n",
      "[2300]\ttraining's rmse: 1.49977\tvalid_1's rmse: 1.53755\n",
      "[2400]\ttraining's rmse: 1.49795\tvalid_1's rmse: 1.53743\n",
      "[2500]\ttraining's rmse: 1.49611\tvalid_1's rmse: 1.53728\n",
      "[2600]\ttraining's rmse: 1.49428\tvalid_1's rmse: 1.53716\n",
      "[2700]\ttraining's rmse: 1.49254\tvalid_1's rmse: 1.53707\n",
      "[2800]\ttraining's rmse: 1.49079\tvalid_1's rmse: 1.53695\n",
      "[2900]\ttraining's rmse: 1.48909\tvalid_1's rmse: 1.53688\n",
      "[3000]\ttraining's rmse: 1.48738\tvalid_1's rmse: 1.53682\n",
      "[3100]\ttraining's rmse: 1.48574\tvalid_1's rmse: 1.53675\n",
      "[3200]\ttraining's rmse: 1.48412\tvalid_1's rmse: 1.5367\n",
      "[3300]\ttraining's rmse: 1.48252\tvalid_1's rmse: 1.53667\n",
      "[3400]\ttraining's rmse: 1.48089\tvalid_1's rmse: 1.53659\n",
      "[3500]\ttraining's rmse: 1.47926\tvalid_1's rmse: 1.53655\n",
      "[3600]\ttraining's rmse: 1.4777\tvalid_1's rmse: 1.53649\n",
      "[3700]\ttraining's rmse: 1.47609\tvalid_1's rmse: 1.53641\n",
      "[3800]\ttraining's rmse: 1.4745\tvalid_1's rmse: 1.53634\n",
      "[3900]\ttraining's rmse: 1.47295\tvalid_1's rmse: 1.53632\n",
      "[4000]\ttraining's rmse: 1.47139\tvalid_1's rmse: 1.53627\n",
      "[4100]\ttraining's rmse: 1.46989\tvalid_1's rmse: 1.53622\n",
      "[4200]\ttraining's rmse: 1.46833\tvalid_1's rmse: 1.53621\n",
      "[4300]\ttraining's rmse: 1.46684\tvalid_1's rmse: 1.53618\n",
      "[4400]\ttraining's rmse: 1.46532\tvalid_1's rmse: 1.53616\n",
      "[4500]\ttraining's rmse: 1.46383\tvalid_1's rmse: 1.53614\n",
      "[4600]\ttraining's rmse: 1.46233\tvalid_1's rmse: 1.53614\n",
      "Early stopping, best iteration is:\n",
      "[4492]\ttraining's rmse: 1.46395\tvalid_1's rmse: 1.53613\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62702\tvalid_1's rmse: 1.63652\n",
      "[200]\ttraining's rmse: 1.59387\tvalid_1's rmse: 1.60394\n",
      "[300]\ttraining's rmse: 1.57554\tvalid_1's rmse: 1.58654\n",
      "[400]\ttraining's rmse: 1.56321\tvalid_1's rmse: 1.57548\n",
      "[500]\ttraining's rmse: 1.55417\tvalid_1's rmse: 1.56796\n",
      "[600]\ttraining's rmse: 1.54704\tvalid_1's rmse: 1.56252\n",
      "[700]\ttraining's rmse: 1.54133\tvalid_1's rmse: 1.55864\n",
      "[800]\ttraining's rmse: 1.53661\tvalid_1's rmse: 1.55574\n",
      "[900]\ttraining's rmse: 1.53246\tvalid_1's rmse: 1.55349\n",
      "[1000]\ttraining's rmse: 1.52879\tvalid_1's rmse: 1.55169\n",
      "[1100]\ttraining's rmse: 1.52547\tvalid_1's rmse: 1.55025\n",
      "[1200]\ttraining's rmse: 1.52242\tvalid_1's rmse: 1.54908\n",
      "[1300]\ttraining's rmse: 1.51961\tvalid_1's rmse: 1.54822\n",
      "[1400]\ttraining's rmse: 1.517\tvalid_1's rmse: 1.54751\n",
      "[1500]\ttraining's rmse: 1.51452\tvalid_1's rmse: 1.54694\n",
      "[1600]\ttraining's rmse: 1.51216\tvalid_1's rmse: 1.54648\n",
      "[1700]\ttraining's rmse: 1.50985\tvalid_1's rmse: 1.54609\n",
      "[1800]\ttraining's rmse: 1.50767\tvalid_1's rmse: 1.54576\n",
      "[1900]\ttraining's rmse: 1.50561\tvalid_1's rmse: 1.54549\n",
      "[2000]\ttraining's rmse: 1.50363\tvalid_1's rmse: 1.54529\n",
      "[2100]\ttraining's rmse: 1.50169\tvalid_1's rmse: 1.54508\n",
      "[2200]\ttraining's rmse: 1.49973\tvalid_1's rmse: 1.54488\n",
      "[2300]\ttraining's rmse: 1.49783\tvalid_1's rmse: 1.54472\n",
      "[2400]\ttraining's rmse: 1.49599\tvalid_1's rmse: 1.54459\n",
      "[2500]\ttraining's rmse: 1.49419\tvalid_1's rmse: 1.54446\n",
      "[2600]\ttraining's rmse: 1.49244\tvalid_1's rmse: 1.54434\n",
      "[2700]\ttraining's rmse: 1.4907\tvalid_1's rmse: 1.54423\n",
      "[2800]\ttraining's rmse: 1.48901\tvalid_1's rmse: 1.54416\n",
      "[2900]\ttraining's rmse: 1.48728\tvalid_1's rmse: 1.54405\n",
      "[3000]\ttraining's rmse: 1.48564\tvalid_1's rmse: 1.54393\n",
      "[3100]\ttraining's rmse: 1.48401\tvalid_1's rmse: 1.54385\n",
      "[3200]\ttraining's rmse: 1.48231\tvalid_1's rmse: 1.54377\n",
      "[3300]\ttraining's rmse: 1.48066\tvalid_1's rmse: 1.54369\n",
      "[3400]\ttraining's rmse: 1.47902\tvalid_1's rmse: 1.54361\n",
      "[3500]\ttraining's rmse: 1.47729\tvalid_1's rmse: 1.54351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3600]\ttraining's rmse: 1.47566\tvalid_1's rmse: 1.54347\n",
      "[3700]\ttraining's rmse: 1.47408\tvalid_1's rmse: 1.54335\n",
      "[3800]\ttraining's rmse: 1.47257\tvalid_1's rmse: 1.54334\n",
      "[3900]\ttraining's rmse: 1.47104\tvalid_1's rmse: 1.54328\n",
      "[4000]\ttraining's rmse: 1.46954\tvalid_1's rmse: 1.54325\n",
      "[4100]\ttraining's rmse: 1.46797\tvalid_1's rmse: 1.54317\n",
      "[4200]\ttraining's rmse: 1.46638\tvalid_1's rmse: 1.5431\n",
      "[4300]\ttraining's rmse: 1.46487\tvalid_1's rmse: 1.54307\n",
      "[4400]\ttraining's rmse: 1.46333\tvalid_1's rmse: 1.54303\n",
      "[4500]\ttraining's rmse: 1.46184\tvalid_1's rmse: 1.54297\n",
      "[4600]\ttraining's rmse: 1.46033\tvalid_1's rmse: 1.54295\n",
      "[4700]\ttraining's rmse: 1.45884\tvalid_1's rmse: 1.5429\n",
      "[4800]\ttraining's rmse: 1.45735\tvalid_1's rmse: 1.54288\n",
      "[4900]\ttraining's rmse: 1.45584\tvalid_1's rmse: 1.54282\n",
      "[5000]\ttraining's rmse: 1.45436\tvalid_1's rmse: 1.54278\n",
      "[5100]\ttraining's rmse: 1.4529\tvalid_1's rmse: 1.54274\n",
      "[5200]\ttraining's rmse: 1.45143\tvalid_1's rmse: 1.54271\n",
      "[5300]\ttraining's rmse: 1.44995\tvalid_1's rmse: 1.54271\n",
      "[5400]\ttraining's rmse: 1.44852\tvalid_1's rmse: 1.54266\n",
      "[5500]\ttraining's rmse: 1.4471\tvalid_1's rmse: 1.54266\n",
      "[5600]\ttraining's rmse: 1.44563\tvalid_1's rmse: 1.54263\n",
      "[5700]\ttraining's rmse: 1.44419\tvalid_1's rmse: 1.5426\n",
      "[5800]\ttraining's rmse: 1.44279\tvalid_1's rmse: 1.5426\n",
      "[5900]\ttraining's rmse: 1.44133\tvalid_1's rmse: 1.54258\n",
      "[6000]\ttraining's rmse: 1.4399\tvalid_1's rmse: 1.54257\n",
      "[6100]\ttraining's rmse: 1.4385\tvalid_1's rmse: 1.54255\n",
      "[6200]\ttraining's rmse: 1.43712\tvalid_1's rmse: 1.54252\n",
      "[6300]\ttraining's rmse: 1.43572\tvalid_1's rmse: 1.54245\n",
      "[6400]\ttraining's rmse: 1.43436\tvalid_1's rmse: 1.54246\n",
      "[6500]\ttraining's rmse: 1.43291\tvalid_1's rmse: 1.54243\n",
      "[6600]\ttraining's rmse: 1.43151\tvalid_1's rmse: 1.54243\n",
      "[6700]\ttraining's rmse: 1.43011\tvalid_1's rmse: 1.54245\n",
      "Early stopping, best iteration is:\n",
      "[6532]\ttraining's rmse: 1.43247\tvalid_1's rmse: 1.5424\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62869\tvalid_1's rmse: 1.62954\n",
      "[200]\ttraining's rmse: 1.59527\tvalid_1's rmse: 1.59827\n",
      "[300]\ttraining's rmse: 1.57634\tvalid_1's rmse: 1.58161\n",
      "[400]\ttraining's rmse: 1.56388\tvalid_1's rmse: 1.57167\n",
      "[500]\ttraining's rmse: 1.55473\tvalid_1's rmse: 1.56481\n",
      "[600]\ttraining's rmse: 1.5475\tvalid_1's rmse: 1.5598\n",
      "[700]\ttraining's rmse: 1.54177\tvalid_1's rmse: 1.55626\n",
      "[800]\ttraining's rmse: 1.53707\tvalid_1's rmse: 1.55366\n",
      "[900]\ttraining's rmse: 1.53293\tvalid_1's rmse: 1.55157\n",
      "[1000]\ttraining's rmse: 1.52925\tvalid_1's rmse: 1.54993\n",
      "[1100]\ttraining's rmse: 1.52594\tvalid_1's rmse: 1.54867\n",
      "[1200]\ttraining's rmse: 1.52296\tvalid_1's rmse: 1.54767\n",
      "[1300]\ttraining's rmse: 1.52014\tvalid_1's rmse: 1.5469\n",
      "[1400]\ttraining's rmse: 1.51751\tvalid_1's rmse: 1.54624\n",
      "[1500]\ttraining's rmse: 1.5151\tvalid_1's rmse: 1.54576\n",
      "[1600]\ttraining's rmse: 1.51276\tvalid_1's rmse: 1.54535\n",
      "[1700]\ttraining's rmse: 1.51052\tvalid_1's rmse: 1.54501\n",
      "[1800]\ttraining's rmse: 1.50843\tvalid_1's rmse: 1.54472\n",
      "[1900]\ttraining's rmse: 1.50637\tvalid_1's rmse: 1.54454\n",
      "[2000]\ttraining's rmse: 1.50433\tvalid_1's rmse: 1.54432\n",
      "[2100]\ttraining's rmse: 1.50232\tvalid_1's rmse: 1.5441\n",
      "[2200]\ttraining's rmse: 1.50035\tvalid_1's rmse: 1.54394\n",
      "[2300]\ttraining's rmse: 1.49848\tvalid_1's rmse: 1.54378\n",
      "[2400]\ttraining's rmse: 1.49669\tvalid_1's rmse: 1.5437\n",
      "[2500]\ttraining's rmse: 1.49486\tvalid_1's rmse: 1.54361\n",
      "[2600]\ttraining's rmse: 1.49314\tvalid_1's rmse: 1.54352\n",
      "[2700]\ttraining's rmse: 1.49138\tvalid_1's rmse: 1.54344\n",
      "[2800]\ttraining's rmse: 1.48968\tvalid_1's rmse: 1.54337\n",
      "[2900]\ttraining's rmse: 1.48791\tvalid_1's rmse: 1.54325\n",
      "[3000]\ttraining's rmse: 1.48622\tvalid_1's rmse: 1.54314\n",
      "[3100]\ttraining's rmse: 1.48455\tvalid_1's rmse: 1.54312\n",
      "[3200]\ttraining's rmse: 1.48295\tvalid_1's rmse: 1.54307\n",
      "[3300]\ttraining's rmse: 1.48126\tvalid_1's rmse: 1.54303\n",
      "[3400]\ttraining's rmse: 1.47965\tvalid_1's rmse: 1.54299\n",
      "[3500]\ttraining's rmse: 1.47812\tvalid_1's rmse: 1.54295\n",
      "[3600]\ttraining's rmse: 1.4765\tvalid_1's rmse: 1.54287\n",
      "[3700]\ttraining's rmse: 1.47494\tvalid_1's rmse: 1.5428\n",
      "[3800]\ttraining's rmse: 1.47335\tvalid_1's rmse: 1.54276\n",
      "[3900]\ttraining's rmse: 1.47178\tvalid_1's rmse: 1.54274\n",
      "[4000]\ttraining's rmse: 1.47026\tvalid_1's rmse: 1.54273\n",
      "[4100]\ttraining's rmse: 1.46873\tvalid_1's rmse: 1.54272\n",
      "[4200]\ttraining's rmse: 1.46721\tvalid_1's rmse: 1.54268\n",
      "[4300]\ttraining's rmse: 1.46573\tvalid_1's rmse: 1.54265\n",
      "[4400]\ttraining's rmse: 1.46422\tvalid_1's rmse: 1.54263\n",
      "[4500]\ttraining's rmse: 1.4627\tvalid_1's rmse: 1.5426\n",
      "[4600]\ttraining's rmse: 1.46118\tvalid_1's rmse: 1.54261\n",
      "[4700]\ttraining's rmse: 1.45969\tvalid_1's rmse: 1.54257\n",
      "[4800]\ttraining's rmse: 1.45817\tvalid_1's rmse: 1.54256\n",
      "[4900]\ttraining's rmse: 1.4567\tvalid_1's rmse: 1.54256\n",
      "Early stopping, best iteration is:\n",
      "[4784]\ttraining's rmse: 1.45842\tvalid_1's rmse: 1.54255\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.63225\tvalid_1's rmse: 1.61488\n",
      "[200]\ttraining's rmse: 1.59846\tvalid_1's rmse: 1.58415\n",
      "[300]\ttraining's rmse: 1.57957\tvalid_1's rmse: 1.56809\n",
      "[400]\ttraining's rmse: 1.56724\tvalid_1's rmse: 1.5581\n",
      "[500]\ttraining's rmse: 1.55819\tvalid_1's rmse: 1.55125\n",
      "[600]\ttraining's rmse: 1.55106\tvalid_1's rmse: 1.54606\n",
      "[700]\ttraining's rmse: 1.54538\tvalid_1's rmse: 1.54235\n",
      "[800]\ttraining's rmse: 1.54067\tvalid_1's rmse: 1.53963\n",
      "[900]\ttraining's rmse: 1.53658\tvalid_1's rmse: 1.53747\n",
      "[1000]\ttraining's rmse: 1.53297\tvalid_1's rmse: 1.5358\n",
      "[1100]\ttraining's rmse: 1.5297\tvalid_1's rmse: 1.53451\n",
      "[1200]\ttraining's rmse: 1.52671\tvalid_1's rmse: 1.53343\n",
      "[1300]\ttraining's rmse: 1.5239\tvalid_1's rmse: 1.53259\n",
      "[1400]\ttraining's rmse: 1.52129\tvalid_1's rmse: 1.53201\n",
      "[1500]\ttraining's rmse: 1.51884\tvalid_1's rmse: 1.53146\n",
      "[1600]\ttraining's rmse: 1.51647\tvalid_1's rmse: 1.53101\n",
      "[1700]\ttraining's rmse: 1.51424\tvalid_1's rmse: 1.53062\n",
      "[1800]\ttraining's rmse: 1.51199\tvalid_1's rmse: 1.5303\n",
      "[1900]\ttraining's rmse: 1.50994\tvalid_1's rmse: 1.53008\n",
      "[2000]\ttraining's rmse: 1.50791\tvalid_1's rmse: 1.52983\n",
      "[2100]\ttraining's rmse: 1.50595\tvalid_1's rmse: 1.52959\n",
      "[2200]\ttraining's rmse: 1.50401\tvalid_1's rmse: 1.52947\n",
      "[2300]\ttraining's rmse: 1.50216\tvalid_1's rmse: 1.52928\n",
      "[2400]\ttraining's rmse: 1.50032\tvalid_1's rmse: 1.52918\n",
      "[2500]\ttraining's rmse: 1.49849\tvalid_1's rmse: 1.52906\n",
      "[2600]\ttraining's rmse: 1.49663\tvalid_1's rmse: 1.52896\n",
      "[2700]\ttraining's rmse: 1.49486\tvalid_1's rmse: 1.52884\n",
      "[2800]\ttraining's rmse: 1.49309\tvalid_1's rmse: 1.52873\n",
      "[2900]\ttraining's rmse: 1.49136\tvalid_1's rmse: 1.52861\n",
      "[3000]\ttraining's rmse: 1.48966\tvalid_1's rmse: 1.5285\n",
      "[3100]\ttraining's rmse: 1.48798\tvalid_1's rmse: 1.52844\n",
      "[3200]\ttraining's rmse: 1.48634\tvalid_1's rmse: 1.52838\n",
      "[3300]\ttraining's rmse: 1.48472\tvalid_1's rmse: 1.52828\n",
      "[3400]\ttraining's rmse: 1.48306\tvalid_1's rmse: 1.52819\n",
      "[3500]\ttraining's rmse: 1.48143\tvalid_1's rmse: 1.52815\n",
      "[3600]\ttraining's rmse: 1.47983\tvalid_1's rmse: 1.52809\n",
      "[3700]\ttraining's rmse: 1.47823\tvalid_1's rmse: 1.5281\n",
      "[3800]\ttraining's rmse: 1.47666\tvalid_1's rmse: 1.52802\n",
      "[3900]\ttraining's rmse: 1.4751\tvalid_1's rmse: 1.52798\n",
      "[4000]\ttraining's rmse: 1.47354\tvalid_1's rmse: 1.52792\n",
      "[4100]\ttraining's rmse: 1.47199\tvalid_1's rmse: 1.52793\n",
      "[4200]\ttraining's rmse: 1.47048\tvalid_1's rmse: 1.5279\n",
      "[4300]\ttraining's rmse: 1.46894\tvalid_1's rmse: 1.52782\n",
      "[4400]\ttraining's rmse: 1.46739\tvalid_1's rmse: 1.52782\n",
      "[4500]\ttraining's rmse: 1.46586\tvalid_1's rmse: 1.52779\n",
      "[4600]\ttraining's rmse: 1.4643\tvalid_1's rmse: 1.52773\n",
      "[4700]\ttraining's rmse: 1.46277\tvalid_1's rmse: 1.52772\n",
      "[4800]\ttraining's rmse: 1.46124\tvalid_1's rmse: 1.52772\n",
      "[4900]\ttraining's rmse: 1.45978\tvalid_1's rmse: 1.52769\n",
      "[5000]\ttraining's rmse: 1.45835\tvalid_1's rmse: 1.52767\n",
      "[5100]\ttraining's rmse: 1.45686\tvalid_1's rmse: 1.52769\n",
      "[5200]\ttraining's rmse: 1.45535\tvalid_1's rmse: 1.52767\n",
      "[5300]\ttraining's rmse: 1.4539\tvalid_1's rmse: 1.52769\n",
      "Early stopping, best iteration is:\n",
      "[5161]\ttraining's rmse: 1.45592\tvalid_1's rmse: 1.52764\n",
      "CV score: 1.54033 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005, #default: 0.005 (3.66940)   /   0.005(3.67032), 0.01 (3.67152), 0.05 ()\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"nthread\": -1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "normal_predictions, oof = lgbm_regression_train(df_train, \n",
    "                                                df_target, \n",
    "                                                test, \n",
    "                                                param, \n",
    "                                                features, \n",
    "                                                categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "model_without_outliers[\"target\"] = normal_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Training Model For Outliers Classification for 5 fold (n_repeats = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_classification_train(df_train, target, df_test, param, features, categorical_feats):\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(len(df_train))\n",
    "    predictions = np.zeros(len(df_test))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    start = time.time()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "        \n",
    "    print(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))\n",
    "\n",
    "    return predictions, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0451509\tvalid_1's binary_logloss: 0.0480669\n",
      "[200]\ttraining's binary_logloss: 0.0451168\tvalid_1's binary_logloss: 0.0480732\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0451386\tvalid_1's binary_logloss: 0.0480215\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0457537\tvalid_1's binary_logloss: 0.046939\n",
      "[200]\ttraining's binary_logloss: 0.0457265\tvalid_1's binary_logloss: 0.0468905\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.0456993\tvalid_1's binary_logloss: 0.0468931\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0453821\tvalid_1's binary_logloss: 0.0466012\n",
      "[200]\ttraining's binary_logloss: 0.0453995\tvalid_1's binary_logloss: 0.0465879\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0453747\tvalid_1's binary_logloss: 0.0465525\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0444893\tvalid_1's binary_logloss: 0.0512099\n",
      "[200]\ttraining's binary_logloss: 0.0444781\tvalid_1's binary_logloss: 0.0512198\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.0446097\tvalid_1's binary_logloss: 0.0511024\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.045296\tvalid_1's binary_logloss: 0.0470667\n",
      "[200]\ttraining's binary_logloss: 0.0452779\tvalid_1's binary_logloss: 0.047031\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0452333\tvalid_1's binary_logloss: 0.0469927\n",
      "CV score: 0.04791 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 51, #default: 31\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333}\n",
    "\n",
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "\n",
    "target = train['outliers']\n",
    "del train['outliers']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]\n",
    "outlier_label, oof_class = lgbm_classification_train(train, target, test, param, features, categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>0.101807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>0.001830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>0.008345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>0.001787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>0.001787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab  0.101807\n",
       "1  C_ID_130fd0cbdd  0.001830\n",
       "2  C_ID_b709037bc5  0.008345\n",
       "3  C_ID_d27d835a9f  0.001787\n",
       "4  C_ID_2b5e3df5c2  0.001787"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlier_prob = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "df_outlier_prob[\"target\"] = outlier_label\n",
    "df_outlier_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Predict outlier for 5 fold (n_repeats = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train[train['outliers'] == 1]\n",
    "df_target = target[outlier_idx]\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 5.63465\tvalid_1's rmse: 3.97548\n",
      "[200]\ttraining's rmse: 5.37692\tvalid_1's rmse: 4.04092\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's rmse: 5.90163\tvalid_1's rmse: 3.93729\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 5.21715\tvalid_1's rmse: 6.19824\n",
      "[200]\ttraining's rmse: 5.0162\tvalid_1's rmse: 6.15378\n",
      "[300]\ttraining's rmse: 4.83747\tvalid_1's rmse: 6.11821\n",
      "[400]\ttraining's rmse: 4.67576\tvalid_1's rmse: 6.08059\n",
      "[500]\ttraining's rmse: 4.52147\tvalid_1's rmse: 6.04763\n",
      "[600]\ttraining's rmse: 4.3771\tvalid_1's rmse: 6.02036\n",
      "[700]\ttraining's rmse: 4.2439\tvalid_1's rmse: 5.99999\n",
      "[800]\ttraining's rmse: 4.11679\tvalid_1's rmse: 5.97422\n",
      "[900]\ttraining's rmse: 3.99291\tvalid_1's rmse: 5.96361\n",
      "[1000]\ttraining's rmse: 3.88143\tvalid_1's rmse: 5.95469\n",
      "[1100]\ttraining's rmse: 3.7716\tvalid_1's rmse: 5.93845\n",
      "[1200]\ttraining's rmse: 3.66845\tvalid_1's rmse: 5.92679\n",
      "[1300]\ttraining's rmse: 3.57088\tvalid_1's rmse: 5.91566\n",
      "[1400]\ttraining's rmse: 3.47913\tvalid_1's rmse: 5.90835\n",
      "[1500]\ttraining's rmse: 3.38696\tvalid_1's rmse: 5.89988\n",
      "[1600]\ttraining's rmse: 3.29786\tvalid_1's rmse: 5.89366\n",
      "[1700]\ttraining's rmse: 3.21622\tvalid_1's rmse: 5.88657\n",
      "[1800]\ttraining's rmse: 3.136\tvalid_1's rmse: 5.8806\n",
      "[1900]\ttraining's rmse: 3.0593\tvalid_1's rmse: 5.87689\n",
      "[2000]\ttraining's rmse: 2.98239\tvalid_1's rmse: 5.86979\n",
      "[2100]\ttraining's rmse: 2.90896\tvalid_1's rmse: 5.87021\n",
      "[2200]\ttraining's rmse: 2.84169\tvalid_1's rmse: 5.86606\n",
      "[2300]\ttraining's rmse: 2.77381\tvalid_1's rmse: 5.86469\n",
      "[2400]\ttraining's rmse: 2.70972\tvalid_1's rmse: 5.86154\n",
      "[2500]\ttraining's rmse: 2.64698\tvalid_1's rmse: 5.85879\n",
      "[2600]\ttraining's rmse: 2.58663\tvalid_1's rmse: 5.85517\n",
      "[2700]\ttraining's rmse: 2.5276\tvalid_1's rmse: 5.85502\n",
      "[2800]\ttraining's rmse: 2.47065\tvalid_1's rmse: 5.85394\n",
      "[2900]\ttraining's rmse: 2.41281\tvalid_1's rmse: 5.85061\n",
      "[3000]\ttraining's rmse: 2.35988\tvalid_1's rmse: 5.85115\n",
      "[3100]\ttraining's rmse: 2.30804\tvalid_1's rmse: 5.84997\n",
      "Early stopping, best iteration is:\n",
      "[2916]\ttraining's rmse: 2.40374\tvalid_1's rmse: 5.84878\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 5.30907\tvalid_1's rmse: 5.8505\n",
      "[200]\ttraining's rmse: 5.09503\tvalid_1's rmse: 5.72005\n",
      "[300]\ttraining's rmse: 4.90739\tvalid_1's rmse: 5.63058\n",
      "[400]\ttraining's rmse: 4.73694\tvalid_1's rmse: 5.57237\n",
      "[500]\ttraining's rmse: 4.57891\tvalid_1's rmse: 5.52861\n",
      "[600]\ttraining's rmse: 4.4302\tvalid_1's rmse: 5.48831\n",
      "[700]\ttraining's rmse: 4.2926\tvalid_1's rmse: 5.4519\n",
      "[800]\ttraining's rmse: 4.15953\tvalid_1's rmse: 5.42642\n",
      "[900]\ttraining's rmse: 4.02756\tvalid_1's rmse: 5.40089\n",
      "[1000]\ttraining's rmse: 3.90332\tvalid_1's rmse: 5.38471\n",
      "[1100]\ttraining's rmse: 3.7862\tvalid_1's rmse: 5.36877\n",
      "[1200]\ttraining's rmse: 3.67693\tvalid_1's rmse: 5.35675\n",
      "[1300]\ttraining's rmse: 3.57298\tvalid_1's rmse: 5.34385\n",
      "[1400]\ttraining's rmse: 3.47342\tvalid_1's rmse: 5.33151\n",
      "[1500]\ttraining's rmse: 3.37711\tvalid_1's rmse: 5.3229\n",
      "[1600]\ttraining's rmse: 3.28094\tvalid_1's rmse: 5.316\n",
      "[1700]\ttraining's rmse: 3.18884\tvalid_1's rmse: 5.31172\n",
      "[1800]\ttraining's rmse: 3.10046\tvalid_1's rmse: 5.30428\n",
      "[1900]\ttraining's rmse: 3.01737\tvalid_1's rmse: 5.30406\n",
      "[2000]\ttraining's rmse: 2.93596\tvalid_1's rmse: 5.30222\n",
      "[2100]\ttraining's rmse: 2.85683\tvalid_1's rmse: 5.29659\n",
      "[2200]\ttraining's rmse: 2.78024\tvalid_1's rmse: 5.29707\n",
      "[2300]\ttraining's rmse: 2.70694\tvalid_1's rmse: 5.29744\n",
      "[2400]\ttraining's rmse: 2.63529\tvalid_1's rmse: 5.29406\n",
      "[2500]\ttraining's rmse: 2.56817\tvalid_1's rmse: 5.29354\n",
      "[2600]\ttraining's rmse: 2.5007\tvalid_1's rmse: 5.29649\n",
      "Early stopping, best iteration is:\n",
      "[2475]\ttraining's rmse: 2.58458\tvalid_1's rmse: 5.29217\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 5.26815\tvalid_1's rmse: 5.99214\n",
      "[200]\ttraining's rmse: 5.04219\tvalid_1's rmse: 5.88084\n",
      "[300]\ttraining's rmse: 4.85159\tvalid_1's rmse: 5.80972\n",
      "[400]\ttraining's rmse: 4.66633\tvalid_1's rmse: 5.7634\n",
      "[500]\ttraining's rmse: 4.5035\tvalid_1's rmse: 5.71902\n",
      "[600]\ttraining's rmse: 4.34993\tvalid_1's rmse: 5.68969\n",
      "[700]\ttraining's rmse: 4.20634\tvalid_1's rmse: 5.67339\n",
      "[800]\ttraining's rmse: 4.07153\tvalid_1's rmse: 5.65342\n",
      "[900]\ttraining's rmse: 3.94768\tvalid_1's rmse: 5.63056\n",
      "[1000]\ttraining's rmse: 3.82403\tvalid_1's rmse: 5.61806\n",
      "[1100]\ttraining's rmse: 3.70809\tvalid_1's rmse: 5.60672\n",
      "[1200]\ttraining's rmse: 3.59901\tvalid_1's rmse: 5.59935\n",
      "[1300]\ttraining's rmse: 3.49722\tvalid_1's rmse: 5.59513\n",
      "[1400]\ttraining's rmse: 3.39644\tvalid_1's rmse: 5.58816\n",
      "[1500]\ttraining's rmse: 3.30045\tvalid_1's rmse: 5.58078\n",
      "[1600]\ttraining's rmse: 3.20862\tvalid_1's rmse: 5.57952\n",
      "[1700]\ttraining's rmse: 3.11814\tvalid_1's rmse: 5.57115\n",
      "[1800]\ttraining's rmse: 3.032\tvalid_1's rmse: 5.56752\n",
      "[1900]\ttraining's rmse: 2.94996\tvalid_1's rmse: 5.56683\n",
      "[2000]\ttraining's rmse: 2.87322\tvalid_1's rmse: 5.56784\n",
      "[2100]\ttraining's rmse: 2.79855\tvalid_1's rmse: 5.56742\n",
      "Early stopping, best iteration is:\n",
      "[1952]\ttraining's rmse: 2.90943\tvalid_1's rmse: 5.564\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 5.41932\tvalid_1's rmse: 5.35849\n",
      "[200]\ttraining's rmse: 5.20485\tvalid_1's rmse: 5.25552\n",
      "[300]\ttraining's rmse: 5.00047\tvalid_1's rmse: 5.18523\n",
      "[400]\ttraining's rmse: 4.82063\tvalid_1's rmse: 5.13636\n",
      "[500]\ttraining's rmse: 4.65728\tvalid_1's rmse: 5.08496\n",
      "[600]\ttraining's rmse: 4.51288\tvalid_1's rmse: 5.05045\n",
      "[700]\ttraining's rmse: 4.37279\tvalid_1's rmse: 5.02295\n",
      "[800]\ttraining's rmse: 4.23502\tvalid_1's rmse: 5.00933\n",
      "[900]\ttraining's rmse: 4.10602\tvalid_1's rmse: 4.98847\n",
      "[1000]\ttraining's rmse: 3.98729\tvalid_1's rmse: 4.97362\n",
      "[1100]\ttraining's rmse: 3.8761\tvalid_1's rmse: 4.96178\n",
      "[1200]\ttraining's rmse: 3.76766\tvalid_1's rmse: 4.94612\n",
      "[1300]\ttraining's rmse: 3.66416\tvalid_1's rmse: 4.94647\n",
      "[1400]\ttraining's rmse: 3.56148\tvalid_1's rmse: 4.93428\n",
      "[1500]\ttraining's rmse: 3.46457\tvalid_1's rmse: 4.9241\n",
      "[1600]\ttraining's rmse: 3.37203\tvalid_1's rmse: 4.92049\n",
      "[1700]\ttraining's rmse: 3.27854\tvalid_1's rmse: 4.91709\n",
      "[1800]\ttraining's rmse: 3.19501\tvalid_1's rmse: 4.91881\n",
      "[1900]\ttraining's rmse: 3.11012\tvalid_1's rmse: 4.90889\n",
      "[2000]\ttraining's rmse: 3.02989\tvalid_1's rmse: 4.90497\n",
      "[2100]\ttraining's rmse: 2.9502\tvalid_1's rmse: 4.90843\n",
      "[2200]\ttraining's rmse: 2.87507\tvalid_1's rmse: 4.90724\n",
      "Early stopping, best iteration is:\n",
      "[2014]\ttraining's rmse: 3.02025\tvalid_1's rmse: 4.90339\n",
      "CV score: 5.15198 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005, #default: 0.005 (3.66940)   /   0.005(3.67032), 0.01 (3.67152), 0.05 ()\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"nthread\": -1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "outlier_predictions, oof_outlier = lgbm_regression_train(df_train, \n",
    "                                                         df_target, \n",
    "                                                         test, \n",
    "                                                         param, \n",
    "                                                         features, \n",
    "                                                         categorical_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Combining Submission for 5 fold (n_repeats = 1)\n",
    "\n",
    "### Using the old way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_id = pd.DataFrame(\\\n",
    "                          df_outlier_prob.sort_values(by='target',\n",
    "                                                      ascending = False)\n",
    "                          .head(25000)['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv('../result/Blend2_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.346967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.354020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.148607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.090599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.346967\n",
       "1  C_ID_130fd0cbdd -0.354020\n",
       "2  C_ID_b709037bc5 -0.932773\n",
       "3  C_ID_d27d835a9f -0.148607\n",
       "4  C_ID_2b5e3df5c2 -1.090599"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_submission.shape[0])\n",
    "best_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.346967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_6d8dba8475</td>\n",
       "      <td>-0.881375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_4859ac9ed5</td>\n",
       "      <td>-0.641561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_7f1041e8e1</td>\n",
       "      <td>-5.193301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_22e4a47c72</td>\n",
       "      <td>0.341024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.346967\n",
       "1  C_ID_6d8dba8475 -0.881375\n",
       "2  C_ID_4859ac9ed5 -0.641561\n",
       "3  C_ID_7f1041e8e1 -5.193301\n",
       "4  C_ID_22e4a47c72  0.341024"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outlier_id.shape[0])\n",
    "most_likely_liers = best_submission.merge(outlier_id,how='right')\n",
    "most_likely_liers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 25s, sys: 63.4 ms, total: 4min 25s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for card_id in most_likely_liers['card_id']:\n",
    "    model_without_outliers.loc[model_without_outliers['card_id']==card_id,'target']\\\n",
    "    = most_likely_liers.loc[most_likely_liers['card_id']==card_id,'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_without_outliers.to_csv(\"../result/Blend2_v3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers_new = pd.read_csv('../result/Blend2_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers_new[] = \n",
    "model_without_outliers_new[] = outlier_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training Model Without Outliers for 5 fold (n_repeats = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_regression_train_n_repeats_2(train, target, test, param, features, categorical_feats):\n",
    "    folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4520)\n",
    "    oof_lgb = np.zeros(len(train))\n",
    "    predictions_lgb = np.zeros(len(test))\n",
    "    start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 11000\n",
    "        clf = lgb.train(lgbparam, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "        oof_lgb[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions_lgb += clf.predict(test[features], num_iteration=clf.best_iteration) / (5 * 2)\n",
    "\n",
    "    print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_lgb, target)**0.5))\n",
    "    return predictions_lgb, oof_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61622\tvalid_1's rmse: 1.63265\n",
      "[200]\ttraining's rmse: 1.5766\tvalid_1's rmse: 1.59755\n",
      "[300]\ttraining's rmse: 1.5542\tvalid_1's rmse: 1.57956\n",
      "[400]\ttraining's rmse: 1.53932\tvalid_1's rmse: 1.56914\n",
      "[500]\ttraining's rmse: 1.52809\tvalid_1's rmse: 1.56229\n",
      "[600]\ttraining's rmse: 1.51914\tvalid_1's rmse: 1.55765\n",
      "[700]\ttraining's rmse: 1.51147\tvalid_1's rmse: 1.55421\n",
      "[800]\ttraining's rmse: 1.50484\tvalid_1's rmse: 1.55185\n",
      "[900]\ttraining's rmse: 1.49889\tvalid_1's rmse: 1.55031\n",
      "[1000]\ttraining's rmse: 1.4933\tvalid_1's rmse: 1.54904\n",
      "[1100]\ttraining's rmse: 1.48811\tvalid_1's rmse: 1.54809\n",
      "[1200]\ttraining's rmse: 1.48312\tvalid_1's rmse: 1.5474\n",
      "[1300]\ttraining's rmse: 1.47849\tvalid_1's rmse: 1.54688\n",
      "[1400]\ttraining's rmse: 1.47406\tvalid_1's rmse: 1.54654\n",
      "[1500]\ttraining's rmse: 1.46976\tvalid_1's rmse: 1.54619\n",
      "[1600]\ttraining's rmse: 1.46563\tvalid_1's rmse: 1.54599\n",
      "[1700]\ttraining's rmse: 1.46174\tvalid_1's rmse: 1.5458\n",
      "[1800]\ttraining's rmse: 1.45781\tvalid_1's rmse: 1.5456\n",
      "[1900]\ttraining's rmse: 1.45412\tvalid_1's rmse: 1.54551\n",
      "[2000]\ttraining's rmse: 1.45035\tvalid_1's rmse: 1.5454\n",
      "[2100]\ttraining's rmse: 1.44678\tvalid_1's rmse: 1.54536\n",
      "[2200]\ttraining's rmse: 1.44325\tvalid_1's rmse: 1.54527\n",
      "[2300]\ttraining's rmse: 1.4398\tvalid_1's rmse: 1.5452\n",
      "[2400]\ttraining's rmse: 1.43639\tvalid_1's rmse: 1.54515\n",
      "[2500]\ttraining's rmse: 1.43303\tvalid_1's rmse: 1.54514\n",
      "Early stopping, best iteration is:\n",
      "[2449]\ttraining's rmse: 1.43472\tvalid_1's rmse: 1.54511\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61732\tvalid_1's rmse: 1.62584\n",
      "[200]\ttraining's rmse: 1.57717\tvalid_1's rmse: 1.59166\n",
      "[300]\ttraining's rmse: 1.55454\tvalid_1's rmse: 1.57462\n",
      "[400]\ttraining's rmse: 1.53927\tvalid_1's rmse: 1.56478\n",
      "[500]\ttraining's rmse: 1.52802\tvalid_1's rmse: 1.55854\n",
      "[600]\ttraining's rmse: 1.51889\tvalid_1's rmse: 1.55449\n",
      "[700]\ttraining's rmse: 1.51116\tvalid_1's rmse: 1.5516\n",
      "[800]\ttraining's rmse: 1.50444\tvalid_1's rmse: 1.54956\n",
      "[900]\ttraining's rmse: 1.49835\tvalid_1's rmse: 1.54818\n",
      "[1000]\ttraining's rmse: 1.49278\tvalid_1's rmse: 1.5471\n",
      "[1100]\ttraining's rmse: 1.48757\tvalid_1's rmse: 1.5464\n",
      "[1200]\ttraining's rmse: 1.48261\tvalid_1's rmse: 1.54584\n",
      "[1300]\ttraining's rmse: 1.47795\tvalid_1's rmse: 1.54539\n",
      "[1400]\ttraining's rmse: 1.47353\tvalid_1's rmse: 1.54513\n",
      "[1500]\ttraining's rmse: 1.46927\tvalid_1's rmse: 1.54488\n",
      "[1600]\ttraining's rmse: 1.46511\tvalid_1's rmse: 1.54471\n",
      "[1700]\ttraining's rmse: 1.46117\tvalid_1's rmse: 1.54457\n",
      "[1800]\ttraining's rmse: 1.45731\tvalid_1's rmse: 1.54452\n",
      "[1900]\ttraining's rmse: 1.4535\tvalid_1's rmse: 1.54444\n",
      "[2000]\ttraining's rmse: 1.4498\tvalid_1's rmse: 1.5444\n",
      "[2100]\ttraining's rmse: 1.44608\tvalid_1's rmse: 1.54439\n",
      "[2200]\ttraining's rmse: 1.44248\tvalid_1's rmse: 1.54434\n",
      "[2300]\ttraining's rmse: 1.43904\tvalid_1's rmse: 1.54433\n",
      "Early stopping, best iteration is:\n",
      "[2211]\ttraining's rmse: 1.44211\tvalid_1's rmse: 1.54432\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61828\tvalid_1's rmse: 1.62216\n",
      "[200]\ttraining's rmse: 1.5784\tvalid_1's rmse: 1.58749\n",
      "[300]\ttraining's rmse: 1.55584\tvalid_1's rmse: 1.5702\n",
      "[400]\ttraining's rmse: 1.54082\tvalid_1's rmse: 1.5604\n",
      "[500]\ttraining's rmse: 1.52954\tvalid_1's rmse: 1.5543\n",
      "[600]\ttraining's rmse: 1.52045\tvalid_1's rmse: 1.55031\n",
      "[700]\ttraining's rmse: 1.5127\tvalid_1's rmse: 1.54747\n",
      "[800]\ttraining's rmse: 1.50602\tvalid_1's rmse: 1.54555\n",
      "[900]\ttraining's rmse: 1.49996\tvalid_1's rmse: 1.54414\n",
      "[1000]\ttraining's rmse: 1.49431\tvalid_1's rmse: 1.54308\n",
      "[1100]\ttraining's rmse: 1.48911\tvalid_1's rmse: 1.54233\n",
      "[1200]\ttraining's rmse: 1.48421\tvalid_1's rmse: 1.54168\n",
      "[1300]\ttraining's rmse: 1.47957\tvalid_1's rmse: 1.54118\n",
      "[1400]\ttraining's rmse: 1.47512\tvalid_1's rmse: 1.54079\n",
      "[1500]\ttraining's rmse: 1.47088\tvalid_1's rmse: 1.54043\n",
      "[1600]\ttraining's rmse: 1.46678\tvalid_1's rmse: 1.54022\n",
      "[1700]\ttraining's rmse: 1.46288\tvalid_1's rmse: 1.54005\n",
      "[1800]\ttraining's rmse: 1.45905\tvalid_1's rmse: 1.53985\n",
      "[1900]\ttraining's rmse: 1.4553\tvalid_1's rmse: 1.5398\n",
      "[2000]\ttraining's rmse: 1.45166\tvalid_1's rmse: 1.5397\n",
      "[2100]\ttraining's rmse: 1.44802\tvalid_1's rmse: 1.53963\n",
      "[2200]\ttraining's rmse: 1.44448\tvalid_1's rmse: 1.53963\n",
      "[2300]\ttraining's rmse: 1.44096\tvalid_1's rmse: 1.53958\n",
      "[2400]\ttraining's rmse: 1.43748\tvalid_1's rmse: 1.53958\n",
      "Early stopping, best iteration is:\n",
      "[2340]\ttraining's rmse: 1.43958\tvalid_1's rmse: 1.53956\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.6195\tvalid_1's rmse: 1.61882\n",
      "[200]\ttraining's rmse: 1.57983\tvalid_1's rmse: 1.58365\n",
      "[300]\ttraining's rmse: 1.5573\tvalid_1's rmse: 1.56595\n",
      "[400]\ttraining's rmse: 1.54226\tvalid_1's rmse: 1.55575\n",
      "[500]\ttraining's rmse: 1.53097\tvalid_1's rmse: 1.54931\n",
      "[600]\ttraining's rmse: 1.52184\tvalid_1's rmse: 1.54502\n",
      "[700]\ttraining's rmse: 1.5141\tvalid_1's rmse: 1.54198\n",
      "[800]\ttraining's rmse: 1.50741\tvalid_1's rmse: 1.53998\n",
      "[900]\ttraining's rmse: 1.50131\tvalid_1's rmse: 1.53852\n",
      "[1000]\ttraining's rmse: 1.49568\tvalid_1's rmse: 1.53743\n",
      "[1100]\ttraining's rmse: 1.49046\tvalid_1's rmse: 1.53667\n",
      "[1200]\ttraining's rmse: 1.48557\tvalid_1's rmse: 1.5361\n",
      "[1300]\ttraining's rmse: 1.48095\tvalid_1's rmse: 1.53563\n",
      "[1400]\ttraining's rmse: 1.47652\tvalid_1's rmse: 1.53521\n",
      "[1500]\ttraining's rmse: 1.47236\tvalid_1's rmse: 1.53493\n",
      "[1600]\ttraining's rmse: 1.4683\tvalid_1's rmse: 1.53468\n",
      "[1700]\ttraining's rmse: 1.46432\tvalid_1's rmse: 1.53445\n",
      "[1800]\ttraining's rmse: 1.46042\tvalid_1's rmse: 1.53429\n",
      "[1900]\ttraining's rmse: 1.45669\tvalid_1's rmse: 1.53411\n",
      "[2000]\ttraining's rmse: 1.45299\tvalid_1's rmse: 1.53398\n",
      "[2100]\ttraining's rmse: 1.4494\tvalid_1's rmse: 1.53391\n",
      "[2200]\ttraining's rmse: 1.44587\tvalid_1's rmse: 1.5338\n",
      "[2300]\ttraining's rmse: 1.44243\tvalid_1's rmse: 1.53373\n",
      "[2400]\ttraining's rmse: 1.439\tvalid_1's rmse: 1.53368\n",
      "[2500]\ttraining's rmse: 1.43562\tvalid_1's rmse: 1.53367\n",
      "[2600]\ttraining's rmse: 1.43229\tvalid_1's rmse: 1.53362\n",
      "[2700]\ttraining's rmse: 1.42891\tvalid_1's rmse: 1.53356\n",
      "[2800]\ttraining's rmse: 1.42556\tvalid_1's rmse: 1.53353\n",
      "[2900]\ttraining's rmse: 1.42224\tvalid_1's rmse: 1.5335\n",
      "Early stopping, best iteration is:\n",
      "[2886]\ttraining's rmse: 1.42267\tvalid_1's rmse: 1.53349\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.62008\tvalid_1's rmse: 1.61809\n",
      "[200]\ttraining's rmse: 1.58043\tvalid_1's rmse: 1.58313\n",
      "[300]\ttraining's rmse: 1.5579\tvalid_1's rmse: 1.56545\n",
      "[400]\ttraining's rmse: 1.54274\tvalid_1's rmse: 1.55507\n",
      "[500]\ttraining's rmse: 1.53129\tvalid_1's rmse: 1.54843\n",
      "[600]\ttraining's rmse: 1.52217\tvalid_1's rmse: 1.54421\n",
      "[700]\ttraining's rmse: 1.51439\tvalid_1's rmse: 1.5413\n",
      "[800]\ttraining's rmse: 1.50758\tvalid_1's rmse: 1.53922\n",
      "[900]\ttraining's rmse: 1.50145\tvalid_1's rmse: 1.53766\n",
      "[1000]\ttraining's rmse: 1.49581\tvalid_1's rmse: 1.53666\n",
      "[1100]\ttraining's rmse: 1.49054\tvalid_1's rmse: 1.53589\n",
      "[1200]\ttraining's rmse: 1.48561\tvalid_1's rmse: 1.53528\n",
      "[1300]\ttraining's rmse: 1.48094\tvalid_1's rmse: 1.53488\n",
      "[1400]\ttraining's rmse: 1.47644\tvalid_1's rmse: 1.53453\n",
      "[1500]\ttraining's rmse: 1.47215\tvalid_1's rmse: 1.53424\n",
      "[1600]\ttraining's rmse: 1.46806\tvalid_1's rmse: 1.53408\n",
      "[1700]\ttraining's rmse: 1.46417\tvalid_1's rmse: 1.53394\n",
      "[1800]\ttraining's rmse: 1.46037\tvalid_1's rmse: 1.53386\n",
      "[1900]\ttraining's rmse: 1.4566\tvalid_1's rmse: 1.53377\n",
      "[2000]\ttraining's rmse: 1.45285\tvalid_1's rmse: 1.53375\n",
      "[2100]\ttraining's rmse: 1.44924\tvalid_1's rmse: 1.53369\n",
      "[2200]\ttraining's rmse: 1.44569\tvalid_1's rmse: 1.53368\n",
      "Early stopping, best iteration is:\n",
      "[2141]\ttraining's rmse: 1.44776\tvalid_1's rmse: 1.53366\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61631\tvalid_1's rmse: 1.63272\n",
      "[200]\ttraining's rmse: 1.57674\tvalid_1's rmse: 1.59729\n",
      "[300]\ttraining's rmse: 1.55435\tvalid_1's rmse: 1.57934\n",
      "[400]\ttraining's rmse: 1.53937\tvalid_1's rmse: 1.5688\n",
      "[500]\ttraining's rmse: 1.52819\tvalid_1's rmse: 1.562\n",
      "[600]\ttraining's rmse: 1.51918\tvalid_1's rmse: 1.55744\n",
      "[700]\ttraining's rmse: 1.51153\tvalid_1's rmse: 1.55423\n",
      "[800]\ttraining's rmse: 1.50483\tvalid_1's rmse: 1.55194\n",
      "[900]\ttraining's rmse: 1.4987\tvalid_1's rmse: 1.55028\n",
      "[1000]\ttraining's rmse: 1.49315\tvalid_1's rmse: 1.54902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\ttraining's rmse: 1.48799\tvalid_1's rmse: 1.5482\n",
      "[1200]\ttraining's rmse: 1.48309\tvalid_1's rmse: 1.54755\n",
      "[1300]\ttraining's rmse: 1.47851\tvalid_1's rmse: 1.54711\n",
      "[1400]\ttraining's rmse: 1.47406\tvalid_1's rmse: 1.54677\n",
      "[1500]\ttraining's rmse: 1.46984\tvalid_1's rmse: 1.54655\n",
      "[1600]\ttraining's rmse: 1.46576\tvalid_1's rmse: 1.54625\n",
      "[1700]\ttraining's rmse: 1.46165\tvalid_1's rmse: 1.54613\n",
      "[1800]\ttraining's rmse: 1.45778\tvalid_1's rmse: 1.546\n",
      "[1900]\ttraining's rmse: 1.45403\tvalid_1's rmse: 1.54594\n",
      "Early stopping, best iteration is:\n",
      "[1871]\ttraining's rmse: 1.45511\tvalid_1's rmse: 1.54591\n",
      "fold n°6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.6194\tvalid_1's rmse: 1.6167\n",
      "[200]\ttraining's rmse: 1.57947\tvalid_1's rmse: 1.58297\n",
      "[300]\ttraining's rmse: 1.55683\tvalid_1's rmse: 1.56615\n",
      "[400]\ttraining's rmse: 1.54162\tvalid_1's rmse: 1.55663\n",
      "[500]\ttraining's rmse: 1.53023\tvalid_1's rmse: 1.55052\n",
      "[600]\ttraining's rmse: 1.52111\tvalid_1's rmse: 1.54651\n",
      "[700]\ttraining's rmse: 1.51332\tvalid_1's rmse: 1.54372\n",
      "[800]\ttraining's rmse: 1.50655\tvalid_1's rmse: 1.54178\n",
      "[900]\ttraining's rmse: 1.50047\tvalid_1's rmse: 1.54039\n",
      "[1000]\ttraining's rmse: 1.49487\tvalid_1's rmse: 1.53948\n",
      "[1100]\ttraining's rmse: 1.48962\tvalid_1's rmse: 1.53878\n",
      "[1200]\ttraining's rmse: 1.48467\tvalid_1's rmse: 1.53821\n",
      "[1300]\ttraining's rmse: 1.48004\tvalid_1's rmse: 1.53787\n",
      "[1400]\ttraining's rmse: 1.47551\tvalid_1's rmse: 1.53754\n",
      "[1500]\ttraining's rmse: 1.47126\tvalid_1's rmse: 1.5372\n",
      "[1600]\ttraining's rmse: 1.4671\tvalid_1's rmse: 1.53698\n",
      "[1700]\ttraining's rmse: 1.46317\tvalid_1's rmse: 1.53679\n",
      "[1800]\ttraining's rmse: 1.45935\tvalid_1's rmse: 1.53659\n",
      "[1900]\ttraining's rmse: 1.45554\tvalid_1's rmse: 1.53651\n",
      "[2000]\ttraining's rmse: 1.45198\tvalid_1's rmse: 1.53648\n",
      "[2100]\ttraining's rmse: 1.44837\tvalid_1's rmse: 1.53645\n",
      "Early stopping, best iteration is:\n",
      "[2059]\ttraining's rmse: 1.44986\tvalid_1's rmse: 1.53644\n",
      "fold n°7\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61831\tvalid_1's rmse: 1.62418\n",
      "[200]\ttraining's rmse: 1.57868\tvalid_1's rmse: 1.58835\n",
      "[300]\ttraining's rmse: 1.55625\tvalid_1's rmse: 1.57007\n",
      "[400]\ttraining's rmse: 1.5411\tvalid_1's rmse: 1.55948\n",
      "[500]\ttraining's rmse: 1.52987\tvalid_1's rmse: 1.5531\n",
      "[600]\ttraining's rmse: 1.52079\tvalid_1's rmse: 1.54892\n",
      "[700]\ttraining's rmse: 1.51301\tvalid_1's rmse: 1.54601\n",
      "[800]\ttraining's rmse: 1.50633\tvalid_1's rmse: 1.54403\n",
      "[900]\ttraining's rmse: 1.50028\tvalid_1's rmse: 1.5426\n",
      "[1000]\ttraining's rmse: 1.49466\tvalid_1's rmse: 1.54158\n",
      "[1100]\ttraining's rmse: 1.48946\tvalid_1's rmse: 1.54078\n",
      "[1200]\ttraining's rmse: 1.48447\tvalid_1's rmse: 1.54025\n",
      "[1300]\ttraining's rmse: 1.4798\tvalid_1's rmse: 1.53982\n",
      "[1400]\ttraining's rmse: 1.47534\tvalid_1's rmse: 1.53946\n",
      "[1500]\ttraining's rmse: 1.47105\tvalid_1's rmse: 1.53924\n",
      "[1600]\ttraining's rmse: 1.46695\tvalid_1's rmse: 1.53907\n",
      "[1700]\ttraining's rmse: 1.463\tvalid_1's rmse: 1.53893\n",
      "[1800]\ttraining's rmse: 1.45922\tvalid_1's rmse: 1.53883\n",
      "[1900]\ttraining's rmse: 1.45553\tvalid_1's rmse: 1.5387\n",
      "[2000]\ttraining's rmse: 1.45189\tvalid_1's rmse: 1.53861\n",
      "[2100]\ttraining's rmse: 1.44831\tvalid_1's rmse: 1.5386\n",
      "[2200]\ttraining's rmse: 1.44477\tvalid_1's rmse: 1.53853\n",
      "[2300]\ttraining's rmse: 1.44132\tvalid_1's rmse: 1.53847\n",
      "[2400]\ttraining's rmse: 1.43788\tvalid_1's rmse: 1.53847\n",
      "[2500]\ttraining's rmse: 1.43441\tvalid_1's rmse: 1.53844\n",
      "Early stopping, best iteration is:\n",
      "[2437]\ttraining's rmse: 1.43661\tvalid_1's rmse: 1.53842\n",
      "fold n°8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61795\tvalid_1's rmse: 1.62397\n",
      "[200]\ttraining's rmse: 1.57818\tvalid_1's rmse: 1.58951\n",
      "[300]\ttraining's rmse: 1.55555\tvalid_1's rmse: 1.57212\n",
      "[400]\ttraining's rmse: 1.54058\tvalid_1's rmse: 1.56209\n",
      "[500]\ttraining's rmse: 1.52931\tvalid_1's rmse: 1.5558\n",
      "[600]\ttraining's rmse: 1.52029\tvalid_1's rmse: 1.55163\n",
      "[700]\ttraining's rmse: 1.51262\tvalid_1's rmse: 1.54864\n",
      "[800]\ttraining's rmse: 1.50593\tvalid_1's rmse: 1.54652\n",
      "[900]\ttraining's rmse: 1.49989\tvalid_1's rmse: 1.54506\n",
      "[1000]\ttraining's rmse: 1.49437\tvalid_1's rmse: 1.54395\n",
      "[1100]\ttraining's rmse: 1.48916\tvalid_1's rmse: 1.54311\n",
      "[1200]\ttraining's rmse: 1.48429\tvalid_1's rmse: 1.5425\n",
      "[1300]\ttraining's rmse: 1.47963\tvalid_1's rmse: 1.542\n",
      "[1400]\ttraining's rmse: 1.47519\tvalid_1's rmse: 1.5416\n",
      "[1500]\ttraining's rmse: 1.4709\tvalid_1's rmse: 1.54133\n",
      "[1600]\ttraining's rmse: 1.46685\tvalid_1's rmse: 1.54104\n",
      "[1700]\ttraining's rmse: 1.46291\tvalid_1's rmse: 1.54087\n",
      "[1800]\ttraining's rmse: 1.45911\tvalid_1's rmse: 1.54075\n",
      "[1900]\ttraining's rmse: 1.45533\tvalid_1's rmse: 1.54062\n",
      "[2000]\ttraining's rmse: 1.45163\tvalid_1's rmse: 1.54055\n",
      "[2100]\ttraining's rmse: 1.44799\tvalid_1's rmse: 1.54049\n",
      "[2200]\ttraining's rmse: 1.44439\tvalid_1's rmse: 1.54035\n",
      "[2300]\ttraining's rmse: 1.44085\tvalid_1's rmse: 1.54031\n",
      "Early stopping, best iteration is:\n",
      "[2261]\ttraining's rmse: 1.44221\tvalid_1's rmse: 1.54028\n",
      "fold n°9\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61914\tvalid_1's rmse: 1.62056\n",
      "[200]\ttraining's rmse: 1.57928\tvalid_1's rmse: 1.58655\n",
      "[300]\ttraining's rmse: 1.55664\tvalid_1's rmse: 1.56925\n",
      "[400]\ttraining's rmse: 1.54149\tvalid_1's rmse: 1.5591\n",
      "[500]\ttraining's rmse: 1.53011\tvalid_1's rmse: 1.55269\n",
      "[600]\ttraining's rmse: 1.52098\tvalid_1's rmse: 1.54829\n",
      "[700]\ttraining's rmse: 1.51319\tvalid_1's rmse: 1.54525\n",
      "[800]\ttraining's rmse: 1.50647\tvalid_1's rmse: 1.54314\n",
      "[900]\ttraining's rmse: 1.50036\tvalid_1's rmse: 1.54162\n",
      "[1000]\ttraining's rmse: 1.49472\tvalid_1's rmse: 1.54057\n",
      "[1100]\ttraining's rmse: 1.48948\tvalid_1's rmse: 1.53977\n",
      "[1200]\ttraining's rmse: 1.48451\tvalid_1's rmse: 1.53909\n",
      "[1300]\ttraining's rmse: 1.47981\tvalid_1's rmse: 1.53864\n",
      "[1400]\ttraining's rmse: 1.47539\tvalid_1's rmse: 1.53827\n",
      "[1500]\ttraining's rmse: 1.4711\tvalid_1's rmse: 1.53802\n",
      "[1600]\ttraining's rmse: 1.46696\tvalid_1's rmse: 1.53778\n",
      "[1700]\ttraining's rmse: 1.46291\tvalid_1's rmse: 1.53757\n",
      "[1800]\ttraining's rmse: 1.45909\tvalid_1's rmse: 1.53739\n",
      "[1900]\ttraining's rmse: 1.45532\tvalid_1's rmse: 1.5373\n",
      "[2000]\ttraining's rmse: 1.45166\tvalid_1's rmse: 1.5372\n",
      "[2100]\ttraining's rmse: 1.44799\tvalid_1's rmse: 1.5371\n",
      "[2200]\ttraining's rmse: 1.44448\tvalid_1's rmse: 1.53707\n",
      "Early stopping, best iteration is:\n",
      "[2179]\ttraining's rmse: 1.4452\tvalid_1's rmse: 1.53706\n",
      "CV score: 1.53962 \n"
     ]
    }
   ],
   "source": [
    "lgbparam = {'num_leaves': 80,\n",
    "            'min_data_in_leaf': 100, \n",
    "            'boosting_type': 'rf',\n",
    "             'objective':'regression',\n",
    "             'max_depth': -1,\n",
    "             'learning_rate': 0.005,\n",
    "             \"min_child_samples\": 20,\n",
    "             \"boosting\": \"gbdt\",\n",
    "             \"feature_fraction\": 0.9,\n",
    "             \"bagging_freq\": 1,\n",
    "             \"bagging_fraction\": 0.9 ,\n",
    "             \"bagging_seed\": 11,\n",
    "             \"metric\": 'rmse',\n",
    "             \"lambda_l1\": 0.1,\n",
    "             \"verbosity\": -1,\n",
    "             \"nthread\": -1,\n",
    "             \"random_state\": 4590}\n",
    "\n",
    "# lgbparam = {'num_leaves': 31,\n",
    "#             'boosting_type': 'rf',\n",
    "#              'min_data_in_leaf': 30, \n",
    "#              'objective':'regression',\n",
    "#              'max_depth': -1,\n",
    "#              'learning_rate': 0.005,\n",
    "#              \"min_child_samples\": 20,\n",
    "#              \"boosting\": \"gbdt\",\n",
    "#              \"feature_fraction\": 0.9,\n",
    "#              \"bagging_freq\": 1,\n",
    "#              \"bagging_fraction\": 0.9 ,\n",
    "#              \"bagging_seed\": 11,\n",
    "#              \"metric\": 'rmse',\n",
    "#              \"lambda_l1\": 0.1,\n",
    "#              \"verbosity\": -1,\n",
    "#              \"nthread\": 4,\n",
    "#              \"random_state\": 4590} # 1.54083\n",
    "\n",
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "\n",
    "df_train = train[train['outliers'] == 0]\n",
    "df_target = target[normal_idx]\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]\n",
    "    \n",
    "normal_predictions_n_repeats_2, oof_n_repeats_2 = lgbm_regression_train_n_repeats_2(df_train, \n",
    "                                                                                    df_target, \n",
    "                                                                                    test, \n",
    "                                                                                    lgbparam, \n",
    "                                                                                    features, \n",
    "                                                                                    categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers_n_repeats_2 = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "model_without_outliers_n_repeats_2[\"target\"] = normal_predictions_n_repeats_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Training Model For Outliers Classification for 5 fold (n_repeats = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_classification_train_n_repeats_2(df_train, target, df_test, param, features, categorical_feats):\n",
    "    folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=15)\n",
    "    oof = np.zeros(len(df_train))\n",
    "    predictions = np.zeros(len(df_test))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    start = time.time()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / (5 * 2)\n",
    "        \n",
    "    print(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))\n",
    "\n",
    "    return predictions, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:1158: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/frank/miniconda2/envs/python35/lib/python3.5/site-packages/lightgbm/basic.py:725: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0451371\tvalid_1's binary_logloss: 0.0481235\n",
      "[200]\ttraining's binary_logloss: 0.0451328\tvalid_1's binary_logloss: 0.0480976\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0450755\tvalid_1's binary_logloss: 0.0480271\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0457511\tvalid_1's binary_logloss: 0.0468768\n",
      "[200]\ttraining's binary_logloss: 0.045708\tvalid_1's binary_logloss: 0.0468697\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.0457617\tvalid_1's binary_logloss: 0.0468144\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0454322\tvalid_1's binary_logloss: 0.0466582\n",
      "[200]\ttraining's binary_logloss: 0.0454004\tvalid_1's binary_logloss: 0.0465773\n",
      "[300]\ttraining's binary_logloss: 0.0453823\tvalid_1's binary_logloss: 0.046593\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's binary_logloss: 0.0453943\tvalid_1's binary_logloss: 0.0465722\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0444724\tvalid_1's binary_logloss: 0.0512327\n",
      "[200]\ttraining's binary_logloss: 0.0444814\tvalid_1's binary_logloss: 0.0511999\n",
      "[300]\ttraining's binary_logloss: 0.0444737\tvalid_1's binary_logloss: 0.0512048\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's binary_logloss: 0.0444638\tvalid_1's binary_logloss: 0.0511865\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0452765\tvalid_1's binary_logloss: 0.0469945\n",
      "[200]\ttraining's binary_logloss: 0.0452428\tvalid_1's binary_logloss: 0.0469846\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.0452498\tvalid_1's binary_logloss: 0.0469227\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.044828\tvalid_1's binary_logloss: 0.04913\n",
      "[200]\ttraining's binary_logloss: 0.0448545\tvalid_1's binary_logloss: 0.0492084\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.0448177\tvalid_1's binary_logloss: 0.0490625\n",
      "fold n°6\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0452349\tvalid_1's binary_logloss: 0.0481599\n",
      "[200]\ttraining's binary_logloss: 0.0451994\tvalid_1's binary_logloss: 0.0481045\n",
      "[300]\ttraining's binary_logloss: 0.0452027\tvalid_1's binary_logloss: 0.0481032\n",
      "[400]\ttraining's binary_logloss: 0.0451942\tvalid_1's binary_logloss: 0.0481118\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's binary_logloss: 0.0451966\tvalid_1's binary_logloss: 0.0480704\n",
      "fold n°7\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0449669\tvalid_1's binary_logloss: 0.0485035\n",
      "[200]\ttraining's binary_logloss: 0.0449657\tvalid_1's binary_logloss: 0.0485141\n",
      "[300]\ttraining's binary_logloss: 0.0449571\tvalid_1's binary_logloss: 0.0485379\n",
      "Early stopping, best iteration is:\n",
      "[160]\ttraining's binary_logloss: 0.044939\tvalid_1's binary_logloss: 0.0484755\n",
      "fold n°8\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0455922\tvalid_1's binary_logloss: 0.0453539\n",
      "[200]\ttraining's binary_logloss: 0.0455518\tvalid_1's binary_logloss: 0.0453447\n",
      "[300]\ttraining's binary_logloss: 0.0455395\tvalid_1's binary_logloss: 0.0453496\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's binary_logloss: 0.0455619\tvalid_1's binary_logloss: 0.0453102\n",
      "fold n°9\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0450513\tvalid_1's binary_logloss: 0.0482252\n",
      "[200]\ttraining's binary_logloss: 0.0450544\tvalid_1's binary_logloss: 0.0482223\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.0449996\tvalid_1's binary_logloss: 0.0480766\n",
      "CV score: 0.04780 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 51,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.001,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333}\n",
    "\n",
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "\n",
    "target = train['outliers']\n",
    "del train['outliers']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]\n",
    "outlier_label_n_repeats_2, oof_class_n_repeats_2 = lgbm_classification_train_n_repeats_2(train, \n",
    "                                                                                         target, \n",
    "                                                                                         test, \n",
    "                                                                                         param, \n",
    "                                                                                         features, \n",
    "                                                                                         categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>0.099707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>0.000922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>0.010882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>0.000715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab  0.099707\n",
       "1  C_ID_130fd0cbdd  0.000922\n",
       "2  C_ID_b709037bc5  0.010882\n",
       "3  C_ID_d27d835a9f  0.000680\n",
       "4  C_ID_2b5e3df5c2  0.000715"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlier_prob_n_repeats_2 = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "df_outlier_prob_n_repeats_2[\"target\"] = outlier_label_n_repeats_2\n",
    "df_outlier_prob_n_repeats_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Combining Submission for 5 fold (n_repeats = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_id_n_repeats_2 = pd.DataFrame(\\\n",
    "                                      df_outlier_prob_n_repeats_2.sort_values(by='target',\n",
    "                                                                              ascending = False)\n",
    "                                      .head(25000)['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv('../result/Blend2_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.346967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.354020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.148607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.090599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.346967\n",
       "1  C_ID_130fd0cbdd -0.354020\n",
       "2  C_ID_b709037bc5 -0.932773\n",
       "3  C_ID_d27d835a9f -0.148607\n",
       "4  C_ID_2b5e3df5c2 -1.090599"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_submission.shape[0])\n",
    "best_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.346967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_6d8dba8475</td>\n",
       "      <td>-0.881375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_4859ac9ed5</td>\n",
       "      <td>-0.641561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_7f1041e8e1</td>\n",
       "      <td>-5.193301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_22e4a47c72</td>\n",
       "      <td>0.341024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.346967\n",
       "1  C_ID_6d8dba8475 -0.881375\n",
       "2  C_ID_4859ac9ed5 -0.641561\n",
       "3  C_ID_7f1041e8e1 -5.193301\n",
       "4  C_ID_22e4a47c72  0.341024"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outlier_id.shape[0])\n",
    "most_likely_liers_n_repeats_2 = best_submission.merge(outlier_id_n_repeats_2,how='right')\n",
    "most_likely_liers_n_repeats_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 28s, sys: 37.6 ms, total: 4min 28s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for card_id in most_likely_liers_n_repeats_2['card_id']:\n",
    "    model_without_outliers_n_repeats_2.loc[model_without_outliers_n_repeats_2['card_id']==card_id,'target']\\\n",
    "    = most_likely_liers_n_repeats_2.loc[most_likely_liers_n_repeats_2['card_id']==card_id,'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_without_outliers_n_repeats_2.to_csv(\"../result/Blend2_v6_n_repeats_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123623"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(model_without_outliers['target'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123623"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(model_without_outliers_n_repeats_2['target'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199644,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199644,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oof_n_repeats_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((201917,), 199644, 2273)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target.shape, len(normal_idx), len(outlier_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2dfa7a5fcabd78829678fa4283e99862f1c4a0d7"
   },
   "source": [
    "## Part 7: Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'oof_normal_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-87184e3c4188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_normal_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'oof_normal_final' is not defined"
     ]
    }
   ],
   "source": [
    "# print(type(target))\n",
    "# print(type(oof))\n",
    "# # print(type(oof_normal_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(outlier_idx), len(outlier_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_normal_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../input/train_test_target_with_target.pkl', 'rb') as f:\n",
    "    [train, target, test, normal_idx, outlier_idx] = pickle.load(f)\n",
    "    \n",
    "oof_normal_final = pd.Series(np.zeros(len(target)))\n",
    "oof_normal_final[normal_idx] = oof\n",
    "oof_normal_final[outlier_idx] = outlier_idx\n",
    "\n",
    "oof_n_repeats_2_final = pd.Series(np.zeros(len(target)))\n",
    "oof_n_repeats_2_final[normal_idx] = oof_n_repeats_2\n",
    "oof_n_repeats_2_final[outlier_idx] = outlier_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "8c9afce8b59b5f51024150a997a9d2eb702ab85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "----------Stacking 0----------\n",
      "fold n°1\n",
      "----------Stacking 1----------\n",
      "fold n°2\n",
      "----------Stacking 2----------\n",
      "fold n°3\n",
      "----------Stacking 3----------\n",
      "fold n°4\n",
      "----------Stacking 4----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.465078594147657"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack = np.vstack([oof_normal_final,oof_n_repeats_2_final]).transpose()\n",
    "test_stack = np.vstack([model_without_outliers['target'].values.tolist(),\n",
    "                        model_without_outliers_n_repeats_2['target'].values.tolist()]).transpose()\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5,n_repeats=1,random_state=4520)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions_stack = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_stack, target)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "\n",
    "    print(\"-\" * 10 + \"Stacking \" + str(fold_) + \"-\" * 10)\n",
    "#     cb_model = CatBoostRegressor(iterations=3000, learning_rate=0.1, depth=8, l2_leaf_reg=20, bootstrap_type='Bernoulli',  eval_metric='RMSE', metric_period=50, od_type='Iter', od_wait=45, random_seed=17, allow_writing_files=False)\n",
    "#     cb_model.fit(trn_data, trn_y, eval_set=(val_data, val_y), cat_features=[], use_best_model=True, verbose=True)\n",
    "    clf = BayesianRidge()\n",
    "    clf.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf.predict(val_data)\n",
    "    predictions_stack += clf.predict(test_stack) / 5\n",
    "\n",
    "\n",
    "np.sqrt(mean_squared_error(target.values, oof_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "e871862de58a3ce43c148f78f152c1d6385a0a08"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample_submission['target'] = predictions_stack\n",
    "sample_submission.to_csv('../result/Bayesian_Ridge_Stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "b65e47686b49b31f0dc47171ab2aece4a4d0a941"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample1 = pd.read_csv(\"../result/3.695.csv\")\n",
    "sample2 = pd.read_csv(\"../result/combining_submission (1).csv\")\n",
    "sample_submission['target'] = model_without_outliers['target'] * 0.5 + model_without_outliers_n_repeats_2['target'] * 0.5\n",
    "sample_submission.to_csv(\"../result/Blend1_v9.csv\", index = False)\n",
    "sample_submission['target'] = sample_submission['target'] * 0.2 + sample1['target'] * 0.2 + sample2['target'] * 0.6\n",
    "sample_submission.to_csv('../result/Blend2_v9.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Blend2_v9.csv` got the best submission score so far - 3.691."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "1259px",
    "right": "20px",
    "top": "14px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
